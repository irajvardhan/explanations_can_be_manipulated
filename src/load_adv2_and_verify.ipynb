{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no display found. Using non-interactive Agg backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from nn.enums import ExplainingMethod\n",
    "from nn.networks import ExplainableNet\n",
    "from nn.utils import get_expl, plot_overview, clamp, load_image, make_dir\n",
    "import keras\n",
    "from keras import datasets \n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beta(i, num_iter):\n",
    "    \"\"\"\n",
    "    Helper method for beta growth\n",
    "    \"\"\"\n",
    "    start_beta, end_beta = 10.0, 100.0\n",
    "    return start_beta * (end_beta / start_beta) ** (i / num_iter)\n",
    "\n",
    "# def np_img_to_tensor(grayscale_img):\n",
    "#     rgb_img = np.repeat(grayscale_img[..., np.newaxis], 3, -1)\n",
    "#     im = Image.fromarray(rgb_img)\n",
    "#     x = torchvision.transforms.Normalize(mean=data_mean, std=data_std)(torchvision.transforms.ToTensor()(torchvision.transforms.Resize(224)(im)))\n",
    "#     x = x.unsqueeze(0).to(device)\n",
    "#     return x\n",
    "\n",
    "def np_img_to_tensor(input_img,data_mean,data_std, device, num_ch=1):\n",
    "    if num_ch == 1:\n",
    "        rgb_img = np.repeat(input_img[..., np.newaxis], 3, -1)\n",
    "    else:\n",
    "        rgb_img = input_img\n",
    "    im = Image.fromarray(rgb_img)\n",
    "    x = torchvision.transforms.Normalize(mean=data_mean, std=data_std)(torchvision.transforms.ToTensor()(torchvision.transforms.Resize(224)(im)))\n",
    "    x = x.unsqueeze(0).to(device)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args\n",
    "args_cuda = True\n",
    "args_method = 'guided_backprop'\n",
    "args_beta_growth = None\n",
    "args_num_iter = 1500\n",
    "args_prefactors = [1e11, 1e6]\n",
    "args_lr = 1* (10**(-3))\n",
    "args_output_dir = '../output/'\n",
    "args_role = 'adversary'\n",
    "args_dataset = 'fmnist'\n",
    "target_class_idx = 0\n",
    "attack_method = 'cwl2/conf_0'\n",
    "args_adv_dir = '../../xai-adv/data/postndss/{}/{}/target_next/target_{}/{}/'\n",
    "num_ch = 1\n",
    "side = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation method ExplainingMethod.guided_backprop will be used\n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# options\n",
    "device = torch.device(\"cuda\" if args_cuda else \"cpu\")\n",
    "method = getattr(ExplainingMethod, args_method)\n",
    "print('Explanation method {} will be used'.format(method))\n",
    "\n",
    "# load model\n",
    "data_mean = np.array([0.0, 0.0, 0.0])\n",
    "data_std = np.array([1.0, 1.0, 1.0])\n",
    "\n",
    "vgg_model = torchvision.models.vgg16(pretrained=True)\n",
    "model = ExplainableNet(vgg_model, data_mean=data_mean, data_std=data_std, beta=1000 if args_beta_growth else None)\n",
    "if method == ExplainingMethod.pattern_attribution:\n",
    "    model.load_state_dict(torch.load('../models/model_vgg16_pattern_small.pth'), strict=False)\n",
    "model = model.eval().to(device)\n",
    "\n",
    "print(vgg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 10 adv2 samples from ../../xai-adv/data/postndss/adv2/adversary/fmnist/guided_backprop/cwl2/conf_0/target_next/target_0\n"
     ]
    }
   ],
   "source": [
    "adv2_dir = '../../xai-adv/data/postndss/adv2/adversary/' + args_dataset + '/' + args_method + '/' + attack_method + '/target_next/' + 'target_' + str(target_class_idx)\n",
    "adv2 = torch.load(adv2_dir + '/x_adv2.pt')\n",
    "print('loaded {} adv2 samples from {}'.format(adv2.shape[0], adv2_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = adv2[0].to(device)\n",
    "x_adv = x.clone().detach().requires_grad_()\n",
    "adv_expl, _, _ = get_expl(model,x_adv, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This should produce an explanation that looks like a normal explanation of the target class\n",
      "torch.Size([1, 224, 224])\n",
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbe1749b390>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('This should produce an explanation that looks like a normal explanation of the target class')\n",
    "print(adv_expl.shape)\n",
    "adv_expl = adv_expl.detach().cpu()\n",
    "adv_expl_np = adv_expl.numpy()\n",
    "adv_expl_np = adv_expl_np.reshape(224, 224)\n",
    "im2 = Image.fromarray(adv_expl_np)\n",
    "adv_expl2 = torchvision.transforms.ToTensor()(torchvision.transforms.Resize(side)(im2))\n",
    "adv_expl_np2 = adv_expl2.numpy()\n",
    "adv_expl_np2 = adv_expl_np2.reshape(side, side)\n",
    "print(adv_expl_np2.shape)\n",
    "plt.imshow(adv_expl_np2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
