{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no display found. Using non-interactive Agg backend\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from nn.enums import ExplainingMethod\n",
    "from nn.networks import ExplainableNet\n",
    "from nn.utils import get_expl, plot_overview, clamp, load_image, make_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beta(i, num_iter):\n",
    "    \"\"\"\n",
    "    Helper method for beta growth\n",
    "    \"\"\"\n",
    "    start_beta, end_beta = 10.0, 100.0\n",
    "    return start_beta * (end_beta / start_beta) ** (i / num_iter)\n",
    "\n",
    "def np_img_to_tensor(grayscale_img):\n",
    "    rgb_img = np.repeat(grayscale_img[..., np.newaxis], 3, -1)\n",
    "    im = Image.fromarray(rgb_img)\n",
    "    x = torchvision.transforms.Normalize(mean=data_mean, std=data_std)(torchvision.transforms.ToTensor()(torchvision.transforms.Resize(224)(im)))\n",
    "    x = x.unsqueeze(0).to(device)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_cuda = True\n",
    "\n",
    "# choices:['lrp', 'guided_backprop', 'gradient', 'integrated_grad','pattern_attribution', 'grad_times_input']\n",
    "args_method = 'lrp'\n",
    "args_beta_growth = None\n",
    "args_img = '../data/collie4.jpeg'\n",
    "args_target_img = '../data/tiger_cat.jpeg'\n",
    "args_num_iter = 1500\n",
    "args_prefactors = [1e11, 1e6]\n",
    "args_lr = 0.0002\n",
    "args_output_dir = '../output/'\n",
    "args_role = 'defender'\n",
    "args_dataset = 'fmnist'\n",
    "args_root_dir = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation method ExplainingMethod.lrp will be used\n"
     ]
    }
   ],
   "source": [
    "# options\n",
    "device = torch.device(\"cuda\" if args_cuda else \"cpu\")\n",
    "method = getattr(ExplainingMethod, args_method)\n",
    "print('Explanation method {} will be used'.format(method))\n",
    "\n",
    "# load model\n",
    "data_mean = np.array([0.0, 0.0, 0.0])\n",
    "data_std = np.array([1.0, 1.0, 1.0])\n",
    "\n",
    "vgg_model = torchvision.models.vgg16(pretrained=True)\n",
    "model = ExplainableNet(vgg_model, data_mean=data_mean, data_std=data_std, beta=1000 if args_beta_growth else None)\n",
    "if method == ExplainingMethod.pattern_attribution:\n",
    "    model.load_state_dict(torch.load('../models/model_vgg16_pattern_small.pth'), strict=False)\n",
    "model = model.eval().to(device)\n",
    "\n",
    "#print(vgg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import datasets \n",
    "(x_train, y_train) ,(x_test, y_test) = datasets.fashion_mnist.load_data()\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "\n",
    "args_class_idx = 6\n",
    "indices = np.where(y_train==args_class_idx)[0]\n",
    "num_samples = indices.shape[0]\n",
    "\n",
    "# expls will store explanations for all the samples\n",
    "expls = np.zeros((num_samples,28,28))\n",
    "\n",
    "for i,idx in enumerate(indices):\n",
    "    if (i+1)%100 == 0:\n",
    "        print('Running for sample {}/{}'.format(i+1,num_samples))\n",
    "    x = np_img_to_tensor(x_train[idx])\n",
    "    x_adv = x.clone().detach().requires_grad_()\n",
    "    # obtain the explanation\n",
    "    org_expl, org_acc, org_idx = get_expl(model, x, method)\n",
    "    org_expl = org_expl.detach().cpu()\n",
    "    \n",
    "    # convert explanation to numpy and subsequently downsize it to 28x28\n",
    "    org_expl_np = org_expl.numpy()\n",
    "    org_expl_np = org_expl_np.reshape(224, 224)\n",
    "    im2 = Image.fromarray(org_expl_np)\n",
    "    org_expl2 = torchvision.transforms.ToTensor()(torchvision.transforms.Resize(28)(im2))\n",
    "    org_expl_np2 = org_expl2.numpy()\n",
    "    org_expl_np2 = org_expl_np2.reshape(28,28)\n",
    "    \n",
    "    expls[i] = org_expl_np2\n",
    "\n",
    "    \n",
    "# store the results\n",
    "output_dir = args_root_dir + '/' + args_role + '/' + args_dataset + '/' + args_method + '/' + str(args_class_idx) + '/'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    print('creating directory ',output_dir)\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print('storing results in ',output_dir)\n",
    "np.save(output_dir+'expls.npy', expls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
