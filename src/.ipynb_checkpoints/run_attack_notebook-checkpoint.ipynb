{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no display found. Using non-interactive Agg backend\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from nn.enums import ExplainingMethod\n",
    "from nn.networks import ExplainableNet\n",
    "from nn.utils import get_expl, plot_overview, clamp, load_image, make_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beta(i, num_iter):\n",
    "    \"\"\"\n",
    "    Helper method for beta growth\n",
    "    \"\"\"\n",
    "    start_beta, end_beta = 10.0, 100.0\n",
    "    return start_beta * (end_beta / start_beta) ** (i / num_iter)\n",
    "\n",
    "def np_img_to_tensor(grayscale_img):\n",
    "    rgb_img = np.repeat(grayscale_img[..., np.newaxis], 3, -1)\n",
    "    im = Image.fromarray(rgb_img)\n",
    "    x = torchvision.transforms.Normalize(mean=data_mean, std=data_std)(torchvision.transforms.ToTensor()(torchvision.transforms.Resize(224)(im)))\n",
    "    x = x.unsqueeze(0).to(device)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args\n",
    "args_cuda = True\n",
    "args_method = 'lrp'\n",
    "args_beta_growth = None\n",
    "args_img = '../data/collie4.jpeg'\n",
    "args_target_img = '../data/tiger_cat.jpeg'\n",
    "args_num_iter = 1500\n",
    "args_prefactors = [1e11, 1e6]\n",
    "args_lr = 0.0002\n",
    "args_output_dir = '../output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation method ExplainingMethod.lrp will be used\n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# options\n",
    "device = torch.device(\"cuda\" if args_cuda else \"cpu\")\n",
    "method = getattr(ExplainingMethod, args_method)\n",
    "print('Explanation method {} will be used'.format(method))\n",
    "\n",
    "# load model\n",
    "data_mean = np.array([0.485, 0.456, 0.406])\n",
    "data_std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "vgg_model = torchvision.models.vgg16(pretrained=True)\n",
    "model = ExplainableNet(vgg_model, data_mean=data_mean, data_std=data_std, beta=1000 if args_beta_growth else None)\n",
    "if method == ExplainingMethod.pattern_attribution:\n",
    "    model.load_state_dict(torch.load('../models/model_vgg16_pattern_small.pth'), strict=False)\n",
    "model = model.eval().to(device)\n",
    "\n",
    "print(vgg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load images\n",
    "# x = load_image(data_mean, data_std, device, args_img)\n",
    "# x_target = load_image(data_mean, data_std, device, args_target_img)\n",
    "# x_adv = x.clone().detach().requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot handle this data type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2648\u001b[0m             \u001b[0mtypekey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"typestr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2649\u001b[0;31m             \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fromarray_typemap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtypekey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2650\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ((1, 1, 28, 3), '|u1')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5f0691a32b2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_img_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mx_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-214589c245da>\u001b[0m in \u001b[0;36mnp_img_to_tensor\u001b[0;34m(grayscale_img)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnp_img_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrayscale_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mrgb_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrayscale_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2649\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fromarray_typemap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtypekey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2651\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot handle this data type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2652\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m         \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot handle this data type"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import datasets \n",
    "(x_train, y_train) ,(x_test, y_test) = datasets.fashion_mnist.load_data()\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "\n",
    "x = np_img_to_tensor(x_train[0])\n",
    "x_adv = x.clone().detach().requires_grad_()\n",
    "print(x.shape)\n",
    "org_expl, org_acc, org_idx = get_expl(model, x, method)\n",
    "org_expl = org_expl.detach().cpu()\n",
    "\n",
    "# The class from which we will derive the target explanation\n",
    "source_class_idx = 6\n",
    "# pick index of x_train where the label is that of the source class\n",
    "idx = np.where(y_train == source_class_idx)[0][0]\n",
    "grayscale_img_src = x_train[idx]\n",
    "x_target = np_img_to_tensor(grayscale_img_src)\n",
    "target_expl, _, _ = get_expl(model, x_target, method)\n",
    "target_expl = target_expl.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f18ee658510>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f18ee577190>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#.data[0].cpu().numpy()\n",
    "org_expl_np = org_expl.cpu().numpy()\n",
    "plt.imshow(org_expl_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f18ee4f0210>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(grayscale_img_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f18ee4535d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_expl_np = target_expl.cpu().numpy()\n",
    "plt.imshow(target_expl_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Total Loss: 69.59967041015625, Expl Loss: 6.959967047137638e-10, Output Loss: 0.0\n",
      "Iteration 1: Total Loss: 68.33981323242188, Expl Loss: 6.824789067216841e-10, Output Loss: 9.192390137968687e-08\n",
      "Iteration 2: Total Loss: 67.28031921386719, Expl Loss: 6.711620148536213e-10, Output Loss: 1.6411884473654936e-07\n",
      "Iteration 3: Total Loss: 66.3698959350586, Expl Loss: 6.612758673973929e-10, Output Loss: 2.423105343041243e-07\n",
      "Iteration 4: Total Loss: 65.64676666259766, Expl Loss: 6.530831986317764e-10, Output Loss: 3.3845105917862384e-07\n",
      "Iteration 5: Total Loss: 64.8812255859375, Expl Loss: 6.447010147958565e-10, Output Loss: 4.111278997243062e-07\n",
      "Iteration 6: Total Loss: 64.17689514160156, Expl Loss: 6.371694838414044e-10, Output Loss: 4.599488363510318e-07\n",
      "Iteration 7: Total Loss: 63.5027961730957, Expl Loss: 6.300958088623076e-10, Output Loss: 4.932161914439348e-07\n",
      "Iteration 8: Total Loss: 62.87495040893555, Expl Loss: 6.236831051609215e-10, Output Loss: 5.066411290499673e-07\n",
      "Iteration 9: Total Loss: 62.33081817626953, Expl Loss: 6.182555023492853e-10, Output Loss: 5.05267848893709e-07\n",
      "Iteration 10: Total Loss: 61.709903717041016, Expl Loss: 6.122715112688581e-10, Output Loss: 4.827529096473882e-07\n",
      "Iteration 11: Total Loss: 61.13801574707031, Expl Loss: 6.068986424523359e-10, Output Loss: 4.4815271849074634e-07\n",
      "Iteration 12: Total Loss: 60.59714889526367, Expl Loss: 6.018067710833463e-10, Output Loss: 4.1647354009910487e-07\n",
      "Iteration 13: Total Loss: 60.14185333251953, Expl Loss: 5.975136496694233e-10, Output Loss: 3.9049294286996883e-07\n",
      "Iteration 14: Total Loss: 59.709815979003906, Expl Loss: 5.933773472577286e-10, Output Loss: 3.720819847785606e-07\n",
      "Iteration 15: Total Loss: 59.29532241821289, Expl Loss: 5.893585064420392e-10, Output Loss: 3.594727218114713e-07\n",
      "Iteration 16: Total Loss: 58.92390060424805, Expl Loss: 5.857094809158525e-10, Output Loss: 3.529542027536081e-07\n",
      "Iteration 17: Total Loss: 58.510223388671875, Expl Loss: 5.815730674818553e-10, Output Loss: 3.5291714084451087e-07\n",
      "Iteration 18: Total Loss: 58.120155334472656, Expl Loss: 5.776787936895289e-10, Output Loss: 3.5227574812779494e-07\n",
      "Iteration 19: Total Loss: 57.72053527832031, Expl Loss: 5.736819352897271e-10, Output Loss: 3.5234398865213734e-07\n",
      "Iteration 20: Total Loss: 57.337989807128906, Expl Loss: 5.698323479741418e-10, Output Loss: 3.547564801920089e-07\n",
      "Iteration 21: Total Loss: 56.95126724243164, Expl Loss: 5.659194224350017e-10, Output Loss: 3.593271173940593e-07\n",
      "Iteration 22: Total Loss: 56.599937438964844, Expl Loss: 5.623382870467708e-10, Output Loss: 3.6611118048313074e-07\n",
      "Iteration 23: Total Loss: 56.25151062011719, Expl Loss: 5.587847962118531e-10, Output Loss: 3.730312130301172e-07\n",
      "Iteration 24: Total Loss: 55.91637420654297, Expl Loss: 5.553742465913558e-10, Output Loss: 3.78952620394557e-07\n",
      "Iteration 25: Total Loss: 55.57339859008789, Expl Loss: 5.519204537840494e-10, Output Loss: 3.813554201315128e-07\n",
      "Iteration 26: Total Loss: 55.223838806152344, Expl Loss: 5.483982157272749e-10, Output Loss: 3.840186764136888e-07\n",
      "Iteration 27: Total Loss: 54.87628173828125, Expl Loss: 5.449081186270632e-10, Output Loss: 3.8547128156096733e-07\n",
      "Iteration 28: Total Loss: 54.558467864990234, Expl Loss: 5.417283843733856e-10, Output Loss: 3.8563169368899253e-07\n",
      "Iteration 29: Total Loss: 54.21233367919922, Expl Loss: 5.382633228023792e-10, Output Loss: 3.8600254015364044e-07\n",
      "Iteration 30: Total Loss: 53.87095260620117, Expl Loss: 5.348476661559687e-10, Output Loss: 3.8619006659246224e-07\n",
      "Iteration 31: Total Loss: 53.5199089050293, Expl Loss: 5.313488538050137e-10, Output Loss: 3.850260270610306e-07\n",
      "Iteration 32: Total Loss: 53.18120193481445, Expl Loss: 5.279793269252764e-10, Output Loss: 3.8327104334712203e-07\n",
      "Iteration 33: Total Loss: 52.826568603515625, Expl Loss: 5.244433221029965e-10, Output Loss: 3.822365499672742e-07\n",
      "Iteration 34: Total Loss: 52.45771408081055, Expl Loss: 5.207392295147883e-10, Output Loss: 3.8379110378627956e-07\n",
      "Iteration 35: Total Loss: 52.115264892578125, Expl Loss: 5.17275611233714e-10, Output Loss: 3.877016752085183e-07\n",
      "Iteration 36: Total Loss: 51.727760314941406, Expl Loss: 5.133425351466769e-10, Output Loss: 3.935081167583121e-07\n",
      "Iteration 37: Total Loss: 51.34309768676758, Expl Loss: 5.094149546636118e-10, Output Loss: 4.016052628230682e-07\n",
      "Iteration 38: Total Loss: 50.99711990356445, Expl Loss: 5.058692909010176e-10, Output Loss: 4.101887043361785e-07\n",
      "Iteration 39: Total Loss: 50.68932342529297, Expl Loss: 5.026625227166903e-10, Output Loss: 4.230726062814938e-07\n",
      "Iteration 40: Total Loss: 50.37019729614258, Expl Loss: 4.993297997302193e-10, Output Loss: 4.3721649944927776e-07\n",
      "Iteration 41: Total Loss: 50.03264617919922, Expl Loss: 4.957618204848302e-10, Output Loss: 4.564682001273468e-07\n",
      "Iteration 42: Total Loss: 49.66172409057617, Expl Loss: 4.918492835237487e-10, Output Loss: 4.767933887706022e-07\n",
      "Iteration 43: Total Loss: 49.315467834472656, Expl Loss: 4.881929305255994e-10, Output Loss: 4.961791546520544e-07\n",
      "Iteration 44: Total Loss: 48.967384338378906, Expl Loss: 4.845250867191453e-10, Output Loss: 5.148776835994795e-07\n",
      "Iteration 45: Total Loss: 48.63398361206055, Expl Loss: 4.809898590529826e-10, Output Loss: 5.350009359972319e-07\n",
      "Iteration 46: Total Loss: 48.27256393432617, Expl Loss: 4.771854023033484e-10, Output Loss: 5.54022449250624e-07\n",
      "Iteration 47: Total Loss: 47.9376106262207, Expl Loss: 4.736802616811531e-10, Output Loss: 5.695855520571058e-07\n",
      "Iteration 48: Total Loss: 47.583866119384766, Expl Loss: 4.699939881724902e-10, Output Loss: 5.84470171816065e-07\n",
      "Iteration 49: Total Loss: 47.21866989135742, Expl Loss: 4.662030206326051e-10, Output Loss: 5.983711730550567e-07\n",
      "Iteration 50: Total Loss: 46.88036346435547, Expl Loss: 4.6269374442964306e-10, Output Loss: 6.109879109317262e-07\n",
      "Iteration 51: Total Loss: 46.544471740722656, Expl Loss: 4.592396185554293e-10, Output Loss: 6.205095246514247e-07\n",
      "Iteration 52: Total Loss: 46.18695068359375, Expl Loss: 4.555942845207994e-10, Output Loss: 6.275220130191883e-07\n",
      "Iteration 53: Total Loss: 45.8481330871582, Expl Loss: 4.5216591582075694e-10, Output Loss: 6.315415248536738e-07\n",
      "Iteration 54: Total Loss: 45.50871658325195, Expl Loss: 4.4876183324937813e-10, Output Loss: 6.325351478153607e-07\n",
      "Iteration 55: Total Loss: 45.14805221557617, Expl Loss: 4.451442825459395e-10, Output Loss: 6.336247224680847e-07\n",
      "Iteration 56: Total Loss: 44.766944885253906, Expl Loss: 4.4129738752118897e-10, Output Loss: 6.37205289422127e-07\n",
      "Iteration 57: Total Loss: 44.42771911621094, Expl Loss: 4.3784140202340893e-10, Output Loss: 6.435804493776232e-07\n",
      "Iteration 58: Total Loss: 44.080501556396484, Expl Loss: 4.3428372009657323e-10, Output Loss: 6.521289606098435e-07\n",
      "Iteration 59: Total Loss: 43.770469665527344, Expl Loss: 4.311040413540468e-10, Output Loss: 6.600635629183671e-07\n",
      "Iteration 60: Total Loss: 43.433380126953125, Expl Loss: 4.276508036582527e-10, Output Loss: 6.683004585283925e-07\n",
      "Iteration 61: Total Loss: 43.06207275390625, Expl Loss: 4.238711603932188e-10, Output Loss: 6.749563681296422e-07\n",
      "Iteration 62: Total Loss: 42.725563049316406, Expl Loss: 4.204482595415726e-10, Output Loss: 6.80735865898896e-07\n",
      "Iteration 63: Total Loss: 42.41572570800781, Expl Loss: 4.172720224904225e-10, Output Loss: 6.885271091050527e-07\n",
      "Iteration 64: Total Loss: 42.11567687988281, Expl Loss: 4.1418152241234907e-10, Output Loss: 6.975267865527712e-07\n",
      "Iteration 65: Total Loss: 41.74773406982422, Expl Loss: 4.1044301291037755e-10, Output Loss: 7.034335567368544e-07\n",
      "Iteration 66: Total Loss: 41.390403747558594, Expl Loss: 4.068416992186741e-10, Output Loss: 7.062337772367755e-07\n",
      "Iteration 67: Total Loss: 41.045772552490234, Expl Loss: 4.033895162347534e-10, Output Loss: 7.068213676575397e-07\n",
      "Iteration 68: Total Loss: 40.70431900024414, Expl Loss: 3.9996495004857024e-10, Output Loss: 7.078241424096632e-07\n",
      "Iteration 69: Total Loss: 40.374454498291016, Expl Loss: 3.966467432281462e-10, Output Loss: 7.097810339473654e-07\n",
      "Iteration 70: Total Loss: 40.050662994384766, Expl Loss: 3.933734171734926e-10, Output Loss: 7.133216399779485e-07\n",
      "Iteration 71: Total Loss: 39.71845626831055, Expl Loss: 3.8999981022413976e-10, Output Loss: 7.184758601397334e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 72: Total Loss: 39.40676498413086, Expl Loss: 3.8685640801894294e-10, Output Loss: 7.211275487861712e-07\n",
      "Iteration 73: Total Loss: 39.08746337890625, Expl Loss: 3.8363384691209035e-10, Output Loss: 7.240783475026547e-07\n",
      "Iteration 74: Total Loss: 38.736454010009766, Expl Loss: 3.8008257652322186e-10, Output Loss: 7.282001774910896e-07\n",
      "Iteration 75: Total Loss: 38.36217498779297, Expl Loss: 3.762875566692969e-10, Output Loss: 7.334205065490096e-07\n",
      "Iteration 76: Total Loss: 37.99911880493164, Expl Loss: 3.7259192953165154e-10, Output Loss: 7.39925837933697e-07\n",
      "Iteration 77: Total Loss: 37.69294357299805, Expl Loss: 3.694540229304266e-10, Output Loss: 7.475415486624115e-07\n",
      "Iteration 78: Total Loss: 37.370567321777344, Expl Loss: 3.6616776277753615e-10, Output Loss: 7.537916530964139e-07\n",
      "Iteration 79: Total Loss: 37.07906723022461, Expl Loss: 3.6318845153537893e-10, Output Loss: 7.60222803819488e-07\n",
      "Iteration 80: Total Loss: 36.77580261230469, Expl Loss: 3.60135393728811e-10, Output Loss: 7.622627435921459e-07\n",
      "Iteration 81: Total Loss: 36.45744705200195, Expl Loss: 3.56945140111975e-10, Output Loss: 7.629373044437671e-07\n",
      "Iteration 82: Total Loss: 36.101539611816406, Expl Loss: 3.5338776349647105e-10, Output Loss: 7.627646141372679e-07\n",
      "Iteration 83: Total Loss: 35.78554916381836, Expl Loss: 3.502476364491969e-10, Output Loss: 7.607885095239908e-07\n",
      "Iteration 84: Total Loss: 35.49106216430664, Expl Loss: 3.473192011771431e-10, Output Loss: 7.591434041387402e-07\n",
      "Iteration 85: Total Loss: 35.1998176574707, Expl Loss: 3.4441213769831336e-10, Output Loss: 7.586077117593959e-07\n",
      "Iteration 86: Total Loss: 34.90324401855469, Expl Loss: 3.414224458708759e-10, Output Loss: 7.610016155013e-07\n",
      "Iteration 87: Total Loss: 34.62865447998047, Expl Loss: 3.3866778825775157e-10, Output Loss: 7.618765494044055e-07\n",
      "Iteration 88: Total Loss: 34.342830657958984, Expl Loss: 3.3578828606550815e-10, Output Loss: 7.640043691026221e-07\n",
      "Iteration 89: Total Loss: 34.08169937133789, Expl Loss: 3.331335485246001e-10, Output Loss: 7.683456715312786e-07\n",
      "Iteration 90: Total Loss: 33.800872802734375, Expl Loss: 3.3027747203817626e-10, Output Loss: 7.731237019470427e-07\n",
      "Iteration 91: Total Loss: 33.524818420410156, Expl Loss: 3.2749106204654765e-10, Output Loss: 7.757093385407643e-07\n",
      "Iteration 92: Total Loss: 33.272823333740234, Expl Loss: 3.2497959878696747e-10, Output Loss: 7.748628263470891e-07\n",
      "Iteration 93: Total Loss: 33.01399612426758, Expl Loss: 3.2239380609588864e-10, Output Loss: 7.746161259092332e-07\n",
      "Iteration 94: Total Loss: 32.75059509277344, Expl Loss: 3.1979180414865027e-10, Output Loss: 7.714161824878829e-07\n",
      "Iteration 95: Total Loss: 32.477882385253906, Expl Loss: 3.170974594013387e-10, Output Loss: 7.681359193156823e-07\n",
      "Iteration 96: Total Loss: 32.22770690917969, Expl Loss: 3.1461905303231674e-10, Output Loss: 7.658035201529856e-07\n",
      "Iteration 97: Total Loss: 31.979368209838867, Expl Loss: 3.1217614604450716e-10, Output Loss: 7.617543928972736e-07\n",
      "Iteration 98: Total Loss: 31.72418975830078, Expl Loss: 3.096751743925097e-10, Output Loss: 7.566730459984683e-07\n",
      "Iteration 99: Total Loss: 31.47506332397461, Expl Loss: 3.072034848727867e-10, Output Loss: 7.547143923147814e-07\n",
      "Iteration 100: Total Loss: 31.23078155517578, Expl Loss: 3.0476626777797833e-10, Output Loss: 7.541557351942174e-07\n",
      "Iteration 101: Total Loss: 30.98171043395996, Expl Loss: 3.023191974538264e-10, Output Loss: 7.497922638322052e-07\n",
      "Iteration 102: Total Loss: 30.721982955932617, Expl Loss: 2.9973926118920247e-10, Output Loss: 7.480576300622488e-07\n",
      "Iteration 103: Total Loss: 30.469280242919922, Expl Loss: 2.972283530411346e-10, Output Loss: 7.464444138349791e-07\n",
      "Iteration 104: Total Loss: 30.227005004882812, Expl Loss: 2.94826607571963e-10, Output Loss: 7.443449021593551e-07\n",
      "Iteration 105: Total Loss: 29.990262985229492, Expl Loss: 2.924467612519521e-10, Output Loss: 7.455879540430033e-07\n",
      "Iteration 106: Total Loss: 29.749807357788086, Expl Loss: 2.9001823165231144e-10, Output Loss: 7.479847567992692e-07\n",
      "Iteration 107: Total Loss: 29.49138641357422, Expl Loss: 2.8746002800339454e-10, Output Loss: 7.453851367245079e-07\n",
      "Iteration 108: Total Loss: 29.24142837524414, Expl Loss: 2.849719071829071e-10, Output Loss: 7.442374680977082e-07\n",
      "Iteration 109: Total Loss: 28.97219467163086, Expl Loss: 2.8224828030332105e-10, Output Loss: 7.473683467651426e-07\n",
      "Iteration 110: Total Loss: 28.702003479003906, Expl Loss: 2.795049192094723e-10, Output Loss: 7.515115498790692e-07\n",
      "Iteration 111: Total Loss: 28.474544525146484, Expl Loss: 2.7715119088611573e-10, Output Loss: 7.59425233809452e-07\n",
      "Iteration 112: Total Loss: 28.244359970092773, Expl Loss: 2.7478758157784e-10, Output Loss: 7.65602010233124e-07\n",
      "Iteration 113: Total Loss: 28.0025577545166, Expl Loss: 2.723387626524243e-10, Output Loss: 7.68681616136746e-07\n",
      "Iteration 114: Total Loss: 27.790224075317383, Expl Loss: 2.70189010054267e-10, Output Loss: 7.713242098361661e-07\n",
      "Iteration 115: Total Loss: 27.509403228759766, Expl Loss: 2.673800625352385e-10, Output Loss: 7.713959462307685e-07\n",
      "Iteration 116: Total Loss: 27.239778518676758, Expl Loss: 2.647117247622788e-10, Output Loss: 7.686056164857291e-07\n",
      "Iteration 117: Total Loss: 26.998605728149414, Expl Loss: 2.622855266309898e-10, Output Loss: 7.70053361520695e-07\n",
      "Iteration 118: Total Loss: 26.76000213623047, Expl Loss: 2.5984528417843933e-10, Output Loss: 7.754740067866805e-07\n",
      "Iteration 119: Total Loss: 26.51031494140625, Expl Loss: 2.5733343234080053e-10, Output Loss: 7.769708645355422e-07\n",
      "Iteration 120: Total Loss: 26.258838653564453, Expl Loss: 2.5475435649902067e-10, Output Loss: 7.834028679098992e-07\n",
      "Iteration 121: Total Loss: 25.99093246459961, Expl Loss: 2.519935926592609e-10, Output Loss: 7.915737683106272e-07\n",
      "Iteration 122: Total Loss: 25.72809600830078, Expl Loss: 2.4932550468648174e-10, Output Loss: 7.955451337693376e-07\n",
      "Iteration 123: Total Loss: 25.464988708496094, Expl Loss: 2.4658780573005856e-10, Output Loss: 8.062104939199344e-07\n",
      "Iteration 124: Total Loss: 25.211570739746094, Expl Loss: 2.439609625426442e-10, Output Loss: 8.154755732903141e-07\n",
      "Iteration 125: Total Loss: 24.951488494873047, Expl Loss: 2.41288544700069e-10, Output Loss: 8.226339787142933e-07\n",
      "Iteration 126: Total Loss: 24.708518981933594, Expl Loss: 2.3878746202576906e-10, Output Loss: 8.297727163153468e-07\n",
      "Iteration 127: Total Loss: 24.473119735717773, Expl Loss: 2.364153040002037e-10, Output Loss: 8.31590739380772e-07\n",
      "Iteration 128: Total Loss: 24.214733123779297, Expl Loss: 2.3377921820610936e-10, Output Loss: 8.368101021005714e-07\n",
      "Iteration 129: Total Loss: 24.00320816040039, Expl Loss: 2.3156210282593293e-10, Output Loss: 8.469976933156431e-07\n",
      "Iteration 130: Total Loss: 23.833148956298828, Expl Loss: 2.2979709801695947e-10, Output Loss: 8.534386211067613e-07\n",
      "Iteration 131: Total Loss: 23.636693954467773, Expl Loss: 2.2776507069277585e-10, Output Loss: 8.601879812886182e-07\n",
      "Iteration 132: Total Loss: 23.419282913208008, Expl Loss: 2.2549373479563428e-10, Output Loss: 8.699090585650993e-07\n",
      "Iteration 133: Total Loss: 23.213972091674805, Expl Loss: 2.234807894296864e-10, Output Loss: 8.658936963001906e-07\n",
      "Iteration 134: Total Loss: 23.018117904663086, Expl Loss: 2.2152556178323124e-10, Output Loss: 8.655621286379755e-07\n",
      "Iteration 135: Total Loss: 22.819459915161133, Expl Loss: 2.195045256669914e-10, Output Loss: 8.690067261341028e-07\n",
      "Iteration 136: Total Loss: 22.604101181030273, Expl Loss: 2.173607821509549e-10, Output Loss: 8.680223686496902e-07\n",
      "Iteration 137: Total Loss: 22.389629364013672, Expl Loss: 2.1515911274860855e-10, Output Loss: 8.737181929063809e-07\n",
      "Iteration 138: Total Loss: 22.20488166809082, Expl Loss: 2.1329191191021835e-10, Output Loss: 8.756907732276886e-07\n",
      "Iteration 139: Total Loss: 22.022499084472656, Expl Loss: 2.1147272821764318e-10, Output Loss: 8.75226703556109e-07\n",
      "Iteration 140: Total Loss: 21.81429672241211, Expl Loss: 2.093755724352775e-10, Output Loss: 8.767385679675499e-07\n",
      "Iteration 141: Total Loss: 21.606809616088867, Expl Loss: 2.07417985564895e-10, Output Loss: 8.650105769447691e-07\n",
      "Iteration 142: Total Loss: 21.4158878326416, Expl Loss: 2.0556496782564437e-10, Output Loss: 8.593913776167028e-07\n",
      "Iteration 143: Total Loss: 21.202484130859375, Expl Loss: 2.034174217957485e-10, Output Loss: 8.607432278040505e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 144: Total Loss: 21.024911880493164, Expl Loss: 2.0168648695584324e-10, Output Loss: 8.562645916754263e-07\n",
      "Iteration 145: Total Loss: 20.849388122558594, Expl Loss: 1.9996330979932253e-10, Output Loss: 8.530586796950956e-07\n",
      "Iteration 146: Total Loss: 20.641143798828125, Expl Loss: 1.9795473593653412e-10, Output Loss: 8.456697173642169e-07\n",
      "Iteration 147: Total Loss: 20.466014862060547, Expl Loss: 1.9633485115466698e-10, Output Loss: 8.3253041793796e-07\n",
      "Iteration 148: Total Loss: 20.28186798095703, Expl Loss: 1.9459368838514735e-10, Output Loss: 8.224998850892007e-07\n",
      "Iteration 149: Total Loss: 20.123336791992188, Expl Loss: 1.9312940136018142e-10, Output Loss: 8.103971254058706e-07\n",
      "Iteration 150: Total Loss: 19.94682502746582, Expl Loss: 1.9144251461877815e-10, Output Loss: 8.025738793548953e-07\n",
      "Iteration 151: Total Loss: 19.77733039855957, Expl Loss: 1.898004253764185e-10, Output Loss: 7.972880098350288e-07\n",
      "Iteration 152: Total Loss: 19.6105899810791, Expl Loss: 1.88223964192602e-10, Output Loss: 7.881944270593522e-07\n",
      "Iteration 153: Total Loss: 19.454761505126953, Expl Loss: 1.8672306756339907e-10, Output Loss: 7.824548902135575e-07\n",
      "Iteration 154: Total Loss: 19.280149459838867, Expl Loss: 1.850761488508823e-10, Output Loss: 7.725360546828597e-07\n",
      "Iteration 155: Total Loss: 19.122709274291992, Expl Loss: 1.8352500075202727e-10, Output Loss: 7.702094535488868e-07\n",
      "Iteration 156: Total Loss: 18.956249237060547, Expl Loss: 1.818624695282267e-10, Output Loss: 7.700030550950032e-07\n",
      "Iteration 157: Total Loss: 18.799814224243164, Expl Loss: 1.802769045156083e-10, Output Loss: 7.721227461843228e-07\n",
      "Iteration 158: Total Loss: 18.642166137695312, Expl Loss: 1.7868610757698633e-10, Output Loss: 7.735553140264528e-07\n",
      "Iteration 159: Total Loss: 18.503341674804688, Expl Loss: 1.7730238111024477e-10, Output Loss: 7.731032951596717e-07\n",
      "Iteration 160: Total Loss: 18.342899322509766, Expl Loss: 1.7569941335171535e-10, Output Loss: 7.729579465376446e-07\n",
      "Iteration 161: Total Loss: 18.20533561706543, Expl Loss: 1.743441363499798e-10, Output Loss: 7.709213605266996e-07\n",
      "Iteration 162: Total Loss: 18.06667709350586, Expl Loss: 1.7297288601447747e-10, Output Loss: 7.69387725085835e-07\n",
      "Iteration 163: Total Loss: 17.94440460205078, Expl Loss: 1.7181206457550502e-10, Output Loss: 7.631987273271079e-07\n",
      "Iteration 164: Total Loss: 17.77916145324707, Expl Loss: 1.7020475306939176e-10, Output Loss: 7.586854167129786e-07\n",
      "Iteration 165: Total Loss: 17.633451461791992, Expl Loss: 1.6884312004084023e-10, Output Loss: 7.491390761060757e-07\n",
      "Iteration 166: Total Loss: 17.495176315307617, Expl Loss: 1.6751153242289263e-10, Output Loss: 7.44023566312535e-07\n",
      "Iteration 167: Total Loss: 17.35345458984375, Expl Loss: 1.6616789888512784e-10, Output Loss: 7.366666068264749e-07\n",
      "Iteration 168: Total Loss: 17.227027893066406, Expl Loss: 1.6493741095136016e-10, Output Loss: 7.332887435040902e-07\n",
      "Iteration 169: Total Loss: 17.106807708740234, Expl Loss: 1.6381371259477362e-10, Output Loss: 7.254365073094959e-07\n",
      "Iteration 170: Total Loss: 16.990327835083008, Expl Loss: 1.6264156688095e-10, Output Loss: 7.261722316798114e-07\n",
      "Iteration 171: Total Loss: 16.8763427734375, Expl Loss: 1.6156434523573182e-10, Output Loss: 7.199080300779315e-07\n",
      "Iteration 172: Total Loss: 16.761314392089844, Expl Loss: 1.603756710766291e-10, Output Loss: 7.237475756483036e-07\n",
      "Iteration 173: Total Loss: 16.626750946044922, Expl Loss: 1.5916730433662707e-10, Output Loss: 7.1002131107889e-07\n",
      "Iteration 174: Total Loss: 16.52156639099121, Expl Loss: 1.581374892145604e-10, Output Loss: 7.078186285980337e-07\n",
      "Iteration 175: Total Loss: 16.408344268798828, Expl Loss: 1.5712918466359582e-10, Output Loss: 6.954258537916758e-07\n",
      "Iteration 176: Total Loss: 16.28301429748535, Expl Loss: 1.559012641205726e-10, Output Loss: 6.928874540790275e-07\n",
      "Iteration 177: Total Loss: 16.156795501708984, Expl Loss: 1.5468953895592108e-10, Output Loss: 6.878427711853874e-07\n",
      "Iteration 178: Total Loss: 16.03655242919922, Expl Loss: 1.534990190510399e-10, Output Loss: 6.86650878378714e-07\n",
      "Iteration 179: Total Loss: 15.925492286682129, Expl Loss: 1.5237487660524351e-10, Output Loss: 6.880044907120464e-07\n",
      "Iteration 180: Total Loss: 15.82470417022705, Expl Loss: 1.5139624276461205e-10, Output Loss: 6.850803515590087e-07\n",
      "Iteration 181: Total Loss: 15.726701736450195, Expl Loss: 1.5033126132824037e-10, Output Loss: 6.935760552551073e-07\n",
      "Iteration 182: Total Loss: 15.642951965332031, Expl Loss: 1.4947010296140206e-10, Output Loss: 6.959414236007433e-07\n",
      "Iteration 183: Total Loss: 15.558998107910156, Expl Loss: 1.4851268825832875e-10, Output Loss: 7.077296118040977e-07\n",
      "Iteration 184: Total Loss: 15.463754653930664, Expl Loss: 1.4770230871707923e-10, Output Loss: 6.935241003702686e-07\n",
      "Iteration 185: Total Loss: 15.353300094604492, Expl Loss: 1.467613808259216e-10, Output Loss: 6.771622906853736e-07\n",
      "Iteration 186: Total Loss: 15.258842468261719, Expl Loss: 1.4598508513152808e-10, Output Loss: 6.603349334000086e-07\n",
      "Iteration 187: Total Loss: 15.179938316345215, Expl Loss: 1.4517734236996205e-10, Output Loss: 6.62204342916084e-07\n",
      "Iteration 188: Total Loss: 15.089900970458984, Expl Loss: 1.4419380967023443e-10, Output Loss: 6.705198529743939e-07\n",
      "Iteration 189: Total Loss: 14.986113548278809, Expl Loss: 1.4330554798380746e-10, Output Loss: 6.555583809131349e-07\n",
      "Iteration 190: Total Loss: 14.901046752929688, Expl Loss: 1.4250677027316527e-10, Output Loss: 6.503695431092638e-07\n",
      "Iteration 191: Total Loss: 14.800141334533691, Expl Loss: 1.4142979842812764e-10, Output Loss: 6.571614790118474e-07\n",
      "Iteration 192: Total Loss: 14.725603103637695, Expl Loss: 1.407044342149888e-10, Output Loss: 6.551603064508527e-07\n",
      "Iteration 193: Total Loss: 14.632713317871094, Expl Loss: 1.3981439617172242e-10, Output Loss: 6.512732966257317e-07\n",
      "Iteration 194: Total Loss: 14.5364408493042, Expl Loss: 1.3893308725698716e-10, Output Loss: 6.431323527067434e-07\n",
      "Iteration 195: Total Loss: 14.47772216796875, Expl Loss: 1.3835962930919266e-10, Output Loss: 6.417598115149303e-07\n",
      "Iteration 196: Total Loss: 14.396992683410645, Expl Loss: 1.3752145255896409e-10, Output Loss: 6.44847716557706e-07\n",
      "Iteration 197: Total Loss: 14.317391395568848, Expl Loss: 1.3681747401683708e-10, Output Loss: 6.356436870191828e-07\n",
      "Iteration 198: Total Loss: 14.234822273254395, Expl Loss: 1.3606708815228075e-10, Output Loss: 6.28113468792435e-07\n",
      "Iteration 199: Total Loss: 14.156671524047852, Expl Loss: 1.3534026677142208e-10, Output Loss: 6.226450182111876e-07\n",
      "Iteration 200: Total Loss: 14.080976486206055, Expl Loss: 1.3462642112216372e-10, Output Loss: 6.183344112287159e-07\n",
      "Iteration 201: Total Loss: 14.00439453125, Expl Loss: 1.3388661013191694e-10, Output Loss: 6.157342795631848e-07\n",
      "Iteration 202: Total Loss: 13.92702865600586, Expl Loss: 1.3317905112053552e-10, Output Loss: 6.091242994443746e-07\n",
      "Iteration 203: Total Loss: 13.854626655578613, Expl Loss: 1.3248555030820341e-10, Output Loss: 6.060711257305229e-07\n",
      "Iteration 204: Total Loss: 13.786203384399414, Expl Loss: 1.3180288804814921e-10, Output Loss: 6.059152042325877e-07\n",
      "Iteration 205: Total Loss: 13.714533805847168, Expl Loss: 1.3113729546709862e-10, Output Loss: 6.008042987559747e-07\n",
      "Iteration 206: Total Loss: 13.645584106445312, Expl Loss: 1.3047522784415122e-10, Output Loss: 5.980619448564539e-07\n",
      "Iteration 207: Total Loss: 13.58626651763916, Expl Loss: 1.2990450382055485e-10, Output Loss: 5.958169708719652e-07\n",
      "Iteration 208: Total Loss: 13.52143669128418, Expl Loss: 1.2928824677516104e-10, Output Loss: 5.926124231336871e-07\n",
      "Iteration 209: Total Loss: 13.464548110961914, Expl Loss: 1.287447648490314e-10, Output Loss: 5.900721475882165e-07\n",
      "Iteration 210: Total Loss: 13.399837493896484, Expl Loss: 1.2814548033812656e-10, Output Loss: 5.852898539160378e-07\n",
      "Iteration 211: Total Loss: 13.330364227294922, Expl Loss: 1.2748216371427645e-10, Output Loss: 5.821488571200462e-07\n",
      "Iteration 212: Total Loss: 13.281551361083984, Expl Loss: 1.270093197280886e-10, Output Loss: 5.806194280921773e-07\n",
      "Iteration 213: Total Loss: 13.228711128234863, Expl Loss: 1.2651336922520073e-10, Output Loss: 5.773742373094137e-07\n",
      "Iteration 214: Total Loss: 13.156944274902344, Expl Loss: 1.2582233865909842e-10, Output Loss: 5.747108957621094e-07\n",
      "Iteration 215: Total Loss: 13.087963104248047, Expl Loss: 1.2516204739299042e-10, Output Loss: 5.717579938391282e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 216: Total Loss: 13.029374122619629, Expl Loss: 1.246040076674504e-10, Output Loss: 5.689732347491372e-07\n",
      "Iteration 217: Total Loss: 12.963231086730957, Expl Loss: 1.2396372817136125e-10, Output Loss: 5.668579774464888e-07\n",
      "Iteration 218: Total Loss: 12.894694328308105, Expl Loss: 1.2330646226299535e-10, Output Loss: 5.640489462166443e-07\n",
      "Iteration 219: Total Loss: 12.836092948913574, Expl Loss: 1.2274513350174487e-10, Output Loss: 5.615794975710742e-07\n",
      "Iteration 220: Total Loss: 12.77898120880127, Expl Loss: 1.2219486533737722e-10, Output Loss: 5.594945946540975e-07\n",
      "Iteration 221: Total Loss: 12.731959342956543, Expl Loss: 1.217556333532599e-10, Output Loss: 5.563962872656703e-07\n",
      "Iteration 222: Total Loss: 12.67374038696289, Expl Loss: 1.21199605906952e-10, Output Loss: 5.537796710086695e-07\n",
      "Iteration 223: Total Loss: 12.612310409545898, Expl Loss: 1.2061626697423833e-10, Output Loss: 5.506838647306722e-07\n",
      "Iteration 224: Total Loss: 12.554084777832031, Expl Loss: 1.200605448392622e-10, Output Loss: 5.480307549987629e-07\n",
      "Iteration 225: Total Loss: 12.495346069335938, Expl Loss: 1.1949838341074326e-10, Output Loss: 5.455083851302334e-07\n",
      "Iteration 226: Total Loss: 12.448150634765625, Expl Loss: 1.1905690322500107e-10, Output Loss: 5.424606683845923e-07\n",
      "Iteration 227: Total Loss: 12.398046493530273, Expl Loss: 1.1857838322359981e-10, Output Loss: 5.402092142503534e-07\n",
      "Iteration 228: Total Loss: 12.362205505371094, Expl Loss: 1.182546283118313e-10, Output Loss: 5.367432436287345e-07\n",
      "Iteration 229: Total Loss: 12.310332298278809, Expl Loss: 1.1775888597576056e-10, Output Loss: 5.344438704923959e-07\n",
      "Iteration 230: Total Loss: 12.246455192565918, Expl Loss: 1.1715980963167283e-10, Output Loss: 5.304748924572777e-07\n",
      "Iteration 231: Total Loss: 12.194068908691406, Expl Loss: 1.1666866084336647e-10, Output Loss: 5.272029284242308e-07\n",
      "Iteration 232: Total Loss: 12.148868560791016, Expl Loss: 1.1625178597540753e-10, Output Loss: 5.236906304162403e-07\n",
      "Iteration 233: Total Loss: 12.090555191040039, Expl Loss: 1.1570276681194258e-10, Output Loss: 5.202789452596335e-07\n",
      "Iteration 234: Total Loss: 12.03402328491211, Expl Loss: 1.1516661235777548e-10, Output Loss: 5.173625368115609e-07\n",
      "Iteration 235: Total Loss: 11.98437786102295, Expl Loss: 1.1470123462142823e-10, Output Loss: 5.142543955116707e-07\n",
      "Iteration 236: Total Loss: 11.92665958404541, Expl Loss: 1.1414696271527802e-10, Output Loss: 5.119634352013236e-07\n",
      "Iteration 237: Total Loss: 11.88643741607666, Expl Loss: 1.1377159631065226e-10, Output Loss: 5.092780952509202e-07\n",
      "Iteration 238: Total Loss: 11.838033676147461, Expl Loss: 1.1330729410286011e-10, Output Loss: 5.073042075309786e-07\n",
      "Iteration 239: Total Loss: 11.780035018920898, Expl Loss: 1.1275504835372985e-10, Output Loss: 5.045298507866391e-07\n",
      "Iteration 240: Total Loss: 11.723478317260742, Expl Loss: 1.1221468892985698e-10, Output Loss: 5.020096409680264e-07\n",
      "Iteration 241: Total Loss: 11.656176567077637, Expl Loss: 1.1157495760638625e-10, Output Loss: 4.986811745766317e-07\n",
      "Iteration 242: Total Loss: 11.606239318847656, Expl Loss: 1.1110520836687954e-10, Output Loss: 4.957186092724442e-07\n",
      "Iteration 243: Total Loss: 11.553576469421387, Expl Loss: 1.1061077054286272e-10, Output Loss: 4.924994527755189e-07\n",
      "Iteration 244: Total Loss: 11.50216293334961, Expl Loss: 1.1012950273947553e-10, Output Loss: 4.892132778877567e-07\n",
      "Iteration 245: Total Loss: 11.457415580749512, Expl Loss: 1.0971978187113152e-10, Output Loss: 4.854377380070218e-07\n",
      "Iteration 246: Total Loss: 11.413372039794922, Expl Loss: 1.0931702765226703e-10, Output Loss: 4.816692467102257e-07\n",
      "Iteration 247: Total Loss: 11.371200561523438, Expl Loss: 1.0893318191929069e-10, Output Loss: 4.778822813022998e-07\n",
      "Iteration 248: Total Loss: 11.322248458862305, Expl Loss: 1.0848021786413753e-10, Output Loss: 4.74227391578097e-07\n",
      "Iteration 249: Total Loss: 11.281194686889648, Expl Loss: 1.0810507350411669e-10, Output Loss: 4.706881497895665e-07\n",
      "Iteration 250: Total Loss: 11.238959312438965, Expl Loss: 1.0771415703825227e-10, Output Loss: 4.675433444845112e-07\n",
      "Iteration 251: Total Loss: 11.197393417358398, Expl Loss: 1.073297214992941e-10, Output Loss: 4.6442107759503415e-07\n",
      "Iteration 252: Total Loss: 11.152541160583496, Expl Loss: 1.0691140334140314e-10, Output Loss: 4.6140053200360853e-07\n",
      "Iteration 253: Total Loss: 11.113460540771484, Expl Loss: 1.0654926940745213e-10, Output Loss: 4.5853406049900514e-07\n",
      "Iteration 254: Total Loss: 11.06486988067627, Expl Loss: 1.0608645906184933e-10, Output Loss: 4.562243134387245e-07\n",
      "Iteration 255: Total Loss: 11.023948669433594, Expl Loss: 1.0570093411654824e-10, Output Loss: 4.5385527869257203e-07\n",
      "Iteration 256: Total Loss: 10.983183860778809, Expl Loss: 1.0530824129384442e-10, Output Loss: 4.523598420291819e-07\n",
      "Iteration 257: Total Loss: 10.949085235595703, Expl Loss: 1.0498861502394874e-10, Output Loss: 4.5022417793916247e-07\n",
      "Iteration 258: Total Loss: 10.911979675292969, Expl Loss: 1.046179046171325e-10, Output Loss: 4.5018975924904225e-07\n",
      "Iteration 259: Total Loss: 10.87244987487793, Expl Loss: 1.0421322138576272e-10, Output Loss: 4.511279598773399e-07\n",
      "Iteration 260: Total Loss: 10.844881057739258, Expl Loss: 1.0383041648687197e-10, Output Loss: 4.6183998847482144e-07\n",
      "Iteration 261: Total Loss: 10.829150199890137, Expl Loss: 1.0348137624571763e-10, Output Loss: 4.810127052223834e-07\n",
      "Iteration 262: Total Loss: 10.822452545166016, Expl Loss: 1.0308617154342059e-10, Output Loss: 5.138355163580854e-07\n",
      "Iteration 263: Total Loss: 10.764074325561523, Expl Loss: 1.0265977651302549e-10, Output Loss: 4.980960284228786e-07\n",
      "Iteration 264: Total Loss: 10.673192977905273, Expl Loss: 1.022749523960087e-10, Output Loss: 4.4569765123014804e-07\n",
      "Iteration 265: Total Loss: 10.63357925415039, Expl Loss: 1.0188981602876623e-10, Output Loss: 4.4459778791861027e-07\n",
      "Iteration 266: Total Loss: 10.624513626098633, Expl Loss: 1.0154730528677547e-10, Output Loss: 4.6978280465737043e-07\n",
      "Iteration 267: Total Loss: 10.555052757263184, Expl Loss: 1.0108574394207537e-10, Output Loss: 4.4647859454016725e-07\n",
      "Iteration 268: Total Loss: 10.507769584655762, Expl Loss: 1.0077660234086849e-10, Output Loss: 4.3010973627133353e-07\n",
      "Iteration 269: Total Loss: 10.4917573928833, Expl Loss: 1.004145169791748e-10, Output Loss: 4.503062598359975e-07\n",
      "Iteration 270: Total Loss: 10.44541072845459, Expl Loss: 1.0006016848418398e-10, Output Loss: 4.3939363081335614e-07\n",
      "Iteration 271: Total Loss: 10.402970314025879, Expl Loss: 9.977299542107687e-11, Output Loss: 4.256704073668516e-07\n",
      "Iteration 272: Total Loss: 10.388855934143066, Expl Loss: 9.947920959207934e-11, Output Loss: 4.409351959111518e-07\n",
      "Iteration 273: Total Loss: 10.345088958740234, Expl Loss: 9.914676718514315e-11, Output Loss: 4.304118590425787e-07\n",
      "Iteration 274: Total Loss: 10.299609184265137, Expl Loss: 9.877859641349573e-11, Output Loss: 4.2175011571998766e-07\n",
      "Iteration 275: Total Loss: 10.277581214904785, Expl Loss: 9.844016574112047e-11, Output Loss: 4.3356479295653116e-07\n",
      "Iteration 276: Total Loss: 10.231121063232422, Expl Loss: 9.81035114255846e-11, Output Loss: 4.2076942463609157e-07\n",
      "Iteration 277: Total Loss: 10.198267936706543, Expl Loss: 9.779350246263974e-11, Output Loss: 4.1891721025422157e-07\n",
      "Iteration 278: Total Loss: 10.168961524963379, Expl Loss: 9.746201762306228e-11, Output Loss: 4.2275968326066504e-07\n",
      "Iteration 279: Total Loss: 10.122779846191406, Expl Loss: 9.711467047202049e-11, Output Loss: 4.1131349348688673e-07\n",
      "Iteration 280: Total Loss: 10.087828636169434, Expl Loss: 9.675053813662515e-11, Output Loss: 4.127748525206698e-07\n",
      "Iteration 281: Total Loss: 10.052794456481934, Expl Loss: 9.641559078898965e-11, Output Loss: 4.112362432806549e-07\n",
      "Iteration 282: Total Loss: 10.018754959106445, Expl Loss: 9.614560536608252e-11, Output Loss: 4.04194480552178e-07\n",
      "Iteration 283: Total Loss: 9.983885765075684, Expl Loss: 9.579087523192698e-11, Output Loss: 4.0479841345586465e-07\n",
      "Iteration 284: Total Loss: 9.954219818115234, Expl Loss: 9.55215143094712e-11, Output Loss: 4.020681956262706e-07\n",
      "Iteration 285: Total Loss: 9.923891067504883, Expl Loss: 9.525625427331263e-11, Output Loss: 3.982657688084146e-07\n",
      "Iteration 286: Total Loss: 9.896281242370605, Expl Loss: 9.499077913144305e-11, Output Loss: 3.972034789967438e-07\n",
      "Iteration 287: Total Loss: 9.859518051147461, Expl Loss: 9.463822087107943e-11, Output Loss: 3.9569607679368346e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 288: Total Loss: 9.821053504943848, Expl Loss: 9.427033459408207e-11, Output Loss: 3.940205033359234e-07\n",
      "Iteration 289: Total Loss: 9.788514137268066, Expl Loss: 9.397217032303118e-11, Output Loss: 3.9129727724684926e-07\n",
      "Iteration 290: Total Loss: 9.752819061279297, Expl Loss: 9.362542685575903e-11, Output Loss: 3.902769663000072e-07\n",
      "Iteration 291: Total Loss: 9.713903427124023, Expl Loss: 9.324008232169945e-11, Output Loss: 3.898950353686814e-07\n",
      "Iteration 292: Total Loss: 9.680285453796387, Expl Loss: 9.293470160098849e-11, Output Loss: 3.8681469050061423e-07\n",
      "Iteration 293: Total Loss: 9.648759841918945, Expl Loss: 9.263072947574003e-11, Output Loss: 3.856867181184498e-07\n",
      "Iteration 294: Total Loss: 9.61782455444336, Expl Loss: 9.232632713906952e-11, Output Loss: 3.851922087960702e-07\n",
      "Iteration 295: Total Loss: 9.590929985046387, Expl Loss: 9.208472873112328e-11, Output Loss: 3.824576424449333e-07\n",
      "Iteration 296: Total Loss: 9.558265686035156, Expl Loss: 9.177737736454361e-11, Output Loss: 3.805282915436692e-07\n",
      "Iteration 297: Total Loss: 9.536049842834473, Expl Loss: 9.157151426020249e-11, Output Loss: 3.7889833492954494e-07\n",
      "Iteration 298: Total Loss: 9.493804931640625, Expl Loss: 9.116814941867446e-11, Output Loss: 3.7698984556300275e-07\n",
      "Iteration 299: Total Loss: 9.459681510925293, Expl Loss: 9.084113322677112e-11, Output Loss: 3.7556810639216565e-07\n",
      "Iteration 300: Total Loss: 9.430561065673828, Expl Loss: 9.057065514239682e-11, Output Loss: 3.7349602166614204e-07\n",
      "Iteration 301: Total Loss: 9.389440536499023, Expl Loss: 9.017536023447903e-11, Output Loss: 3.7190423540778283e-07\n",
      "Iteration 302: Total Loss: 9.359644889831543, Expl Loss: 8.988489813566147e-11, Output Loss: 3.7115464124326536e-07\n",
      "Iteration 303: Total Loss: 9.33233642578125, Expl Loss: 8.962789538324856e-11, Output Loss: 3.695469104059157e-07\n",
      "Iteration 304: Total Loss: 9.307498931884766, Expl Loss: 8.939136930674607e-11, Output Loss: 3.6836257777395076e-07\n",
      "Iteration 305: Total Loss: 9.278310775756836, Expl Loss: 8.910628485070404e-11, Output Loss: 3.6768230415873404e-07\n",
      "Iteration 306: Total Loss: 9.246967315673828, Expl Loss: 8.880308988157282e-11, Output Loss: 3.6665832681137545e-07\n",
      "Iteration 307: Total Loss: 9.218759536743164, Expl Loss: 8.852932970038196e-11, Output Loss: 3.658268781236984e-07\n",
      "Iteration 308: Total Loss: 9.190571784973145, Expl Loss: 8.825550013025207e-11, Output Loss: 3.650215489869879e-07\n",
      "Iteration 309: Total Loss: 9.165535926818848, Expl Loss: 8.801353396092892e-11, Output Loss: 3.6418205695554207e-07\n",
      "Iteration 310: Total Loss: 9.134682655334473, Expl Loss: 8.771296883258728e-11, Output Loss: 3.63385936452687e-07\n",
      "Iteration 311: Total Loss: 9.106792449951172, Expl Loss: 8.744292095963502e-11, Output Loss: 3.625006570473488e-07\n",
      "Iteration 312: Total Loss: 9.080095291137695, Expl Loss: 8.718640392979538e-11, Output Loss: 3.614550792008231e-07\n",
      "Iteration 313: Total Loss: 9.047136306762695, Expl Loss: 8.686935198953805e-11, Output Loss: 3.6020071547682164e-07\n",
      "Iteration 314: Total Loss: 9.020210266113281, Expl Loss: 8.661089900829921e-11, Output Loss: 3.5912046314479085e-07\n",
      "Iteration 315: Total Loss: 8.996133804321289, Expl Loss: 8.637991016913205e-11, Output Loss: 3.581425005450001e-07\n",
      "Iteration 316: Total Loss: 8.966623306274414, Expl Loss: 8.609394447356422e-11, Output Loss: 3.5722936786442006e-07\n",
      "Iteration 317: Total Loss: 8.949070930480957, Expl Loss: 8.592675182494958e-11, Output Loss: 3.563955601748603e-07\n",
      "Iteration 318: Total Loss: 8.912742614746094, Expl Loss: 8.557293762478935e-11, Output Loss: 3.554484067080921e-07\n",
      "Iteration 319: Total Loss: 8.885505676269531, Expl Loss: 8.530846862253583e-11, Output Loss: 3.5465885162011546e-07\n",
      "Iteration 320: Total Loss: 8.861747741699219, Expl Loss: 8.507885368436163e-11, Output Loss: 3.5386287322580756e-07\n",
      "Iteration 321: Total Loss: 8.838897705078125, Expl Loss: 8.485685765169393e-11, Output Loss: 3.532123002969456e-07\n",
      "Iteration 322: Total Loss: 8.80984115600586, Expl Loss: 8.45705241947492e-11, Output Loss: 3.5278904420010804e-07\n",
      "Iteration 323: Total Loss: 8.7853422164917, Expl Loss: 8.433163195542548e-11, Output Loss: 3.5217965432821075e-07\n",
      "Iteration 324: Total Loss: 8.752594947814941, Expl Loss: 8.401097179033812e-11, Output Loss: 3.5149798804923194e-07\n",
      "Iteration 325: Total Loss: 8.730833053588867, Expl Loss: 8.380052901602042e-11, Output Loss: 3.507805672597897e-07\n",
      "Iteration 326: Total Loss: 8.7034330368042, Expl Loss: 8.35332081283724e-11, Output Loss: 3.5011197496714885e-07\n",
      "Iteration 327: Total Loss: 8.681802749633789, Expl Loss: 8.332452783310629e-11, Output Loss: 3.4934961945509713e-07\n",
      "Iteration 328: Total Loss: 8.653164863586426, Expl Loss: 8.304723575491835e-11, Output Loss: 3.48441432151958e-07\n",
      "Iteration 329: Total Loss: 8.632955551147461, Expl Loss: 8.285421654319336e-11, Output Loss: 3.475337564395886e-07\n",
      "Iteration 330: Total Loss: 8.608875274658203, Expl Loss: 8.262312362061763e-11, Output Loss: 3.465636098098912e-07\n",
      "Iteration 331: Total Loss: 8.58993148803711, Expl Loss: 8.24429899348722e-11, Output Loss: 3.456327135609172e-07\n",
      "Iteration 332: Total Loss: 8.561989784240723, Expl Loss: 8.217372615693108e-11, Output Loss: 3.4461692166587454e-07\n",
      "Iteration 333: Total Loss: 8.54056167602539, Expl Loss: 8.196931328141588e-11, Output Loss: 3.4363063150522066e-07\n",
      "Iteration 334: Total Loss: 8.517305374145508, Expl Loss: 8.174808746597151e-11, Output Loss: 3.424966621423664e-07\n",
      "Iteration 335: Total Loss: 8.495731353759766, Expl Loss: 8.154363295709288e-11, Output Loss: 3.413683771213982e-07\n",
      "Iteration 336: Total Loss: 8.469616889953613, Expl Loss: 8.129348583185703e-11, Output Loss: 3.402678032671247e-07\n",
      "Iteration 337: Total Loss: 8.44548511505127, Expl Loss: 8.106205290348001e-11, Output Loss: 3.3927986464732385e-07\n",
      "Iteration 338: Total Loss: 8.42940902709961, Expl Loss: 8.09116107447494e-11, Output Loss: 3.38247815534487e-07\n",
      "Iteration 339: Total Loss: 8.410286903381348, Expl Loss: 8.07301170357988e-11, Output Loss: 3.3727584991538606e-07\n",
      "Iteration 340: Total Loss: 8.389909744262695, Expl Loss: 8.053658434592492e-11, Output Loss: 3.362517304594803e-07\n",
      "Iteration 341: Total Loss: 8.369588851928711, Expl Loss: 8.034230225550942e-11, Output Loss: 3.3535829402353556e-07\n",
      "Iteration 342: Total Loss: 8.344953536987305, Expl Loss: 8.01046382004067e-11, Output Loss: 3.3449020975240273e-07\n",
      "Iteration 343: Total Loss: 8.322897911071777, Expl Loss: 7.98908300625456e-11, Output Loss: 3.338153646836872e-07\n",
      "Iteration 344: Total Loss: 8.300811767578125, Expl Loss: 7.967724396928944e-11, Output Loss: 3.330872289097897e-07\n",
      "Iteration 345: Total Loss: 8.282514572143555, Expl Loss: 7.949965685760674e-11, Output Loss: 3.325489785765967e-07\n",
      "Iteration 346: Total Loss: 8.264425277709961, Expl Loss: 7.932565021517846e-11, Output Loss: 3.3186023529196973e-07\n",
      "Iteration 347: Total Loss: 8.236355781555176, Expl Loss: 7.904741444741958e-11, Output Loss: 3.3161441592710617e-07\n",
      "Iteration 348: Total Loss: 8.212162971496582, Expl Loss: 7.880860547482271e-11, Output Loss: 3.3130228871414147e-07\n",
      "Iteration 349: Total Loss: 8.190982818603516, Expl Loss: 7.858933642745924e-11, Output Loss: 3.320496091419045e-07\n",
      "Iteration 350: Total Loss: 8.176918029785156, Expl Loss: 7.843927590789335e-11, Output Loss: 3.3299082247140177e-07\n",
      "Iteration 351: Total Loss: 8.155797958374023, Expl Loss: 7.820436659367047e-11, Output Loss: 3.3536181831550493e-07\n",
      "Iteration 352: Total Loss: 8.142599105834961, Expl Loss: 7.804283608248141e-11, Output Loss: 3.3831514656412764e-07\n",
      "Iteration 353: Total Loss: 8.12021541595459, Expl Loss: 7.780431854342851e-11, Output Loss: 3.3978344049501175e-07\n",
      "Iteration 354: Total Loss: 8.093157768249512, Expl Loss: 7.755242281692887e-11, Output Loss: 3.379155657512456e-07\n",
      "Iteration 355: Total Loss: 8.066576957702637, Expl Loss: 7.734826668048811e-11, Output Loss: 3.3175030011989293e-07\n",
      "Iteration 356: Total Loss: 8.040412902832031, Expl Loss: 7.715587890810838e-11, Output Loss: 3.2482529377375613e-07\n",
      "Iteration 357: Total Loss: 8.017464637756348, Expl Loss: 7.694479775555152e-11, Output Loss: 3.229855849440355e-07\n",
      "Iteration 358: Total Loss: 8.006546020507812, Expl Loss: 7.680978075796929e-11, Output Loss: 3.255681519931386e-07\n",
      "Iteration 359: Total Loss: 7.985599517822266, Expl Loss: 7.658450956737894e-11, Output Loss: 3.2714902431507653e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 360: Total Loss: 7.970362186431885, Expl Loss: 7.644616883961675e-11, Output Loss: 3.257454750382749e-07\n",
      "Iteration 361: Total Loss: 7.941849231719971, Expl Loss: 7.620180875189675e-11, Output Loss: 3.2166849450732116e-07\n",
      "Iteration 362: Total Loss: 7.922190189361572, Expl Loss: 7.603182666793273e-11, Output Loss: 3.19007739335575e-07\n",
      "Iteration 363: Total Loss: 7.8974785804748535, Expl Loss: 7.578682820197358e-11, Output Loss: 3.1879554285296763e-07\n",
      "Iteration 364: Total Loss: 7.882198810577393, Expl Loss: 7.562762222024233e-11, Output Loss: 3.1943665135258925e-07\n",
      "Iteration 365: Total Loss: 7.8641204833984375, Expl Loss: 7.544753016786032e-11, Output Loss: 3.1936727395986964e-07\n",
      "Iteration 366: Total Loss: 7.8459553718566895, Expl Loss: 7.528333512141216e-11, Output Loss: 3.176223515310994e-07\n",
      "Iteration 367: Total Loss: 7.827396869659424, Expl Loss: 7.511488653300091e-11, Output Loss: 3.1590840876560833e-07\n",
      "Iteration 368: Total Loss: 7.798454284667969, Expl Loss: 7.483701852661895e-11, Output Loss: 3.1475281048187753e-07\n",
      "Iteration 369: Total Loss: 7.7802910804748535, Expl Loss: 7.466015999879616e-11, Output Loss: 3.142753826068656e-07\n",
      "Iteration 370: Total Loss: 7.765838146209717, Expl Loss: 7.452369277238802e-11, Output Loss: 3.1346914397545333e-07\n",
      "Iteration 371: Total Loss: 7.744348526000977, Expl Loss: 7.432685716901588e-11, Output Loss: 3.1166291591944173e-07\n",
      "Iteration 372: Total Loss: 7.724329948425293, Expl Loss: 7.413888947205294e-11, Output Loss: 3.1044123716128524e-07\n",
      "Iteration 373: Total Loss: 7.70577335357666, Expl Loss: 7.395811046917444e-11, Output Loss: 3.099621039837075e-07\n",
      "Iteration 374: Total Loss: 7.686957836151123, Expl Loss: 7.376882438236976e-11, Output Loss: 3.1007573397801025e-07\n",
      "Iteration 375: Total Loss: 7.666561126708984, Expl Loss: 7.35669858364929e-11, Output Loss: 3.098626564224105e-07\n",
      "Iteration 376: Total Loss: 7.643555641174316, Expl Loss: 7.334683554960364e-11, Output Loss: 3.088722451138892e-07\n",
      "Iteration 377: Total Loss: 7.635763645172119, Expl Loss: 7.328068013512379e-11, Output Loss: 3.076959842474025e-07\n",
      "Iteration 378: Total Loss: 7.616806507110596, Expl Loss: 7.310359262380217e-11, Output Loss: 3.064476175040909e-07\n",
      "Iteration 379: Total Loss: 7.596193313598633, Expl Loss: 7.290499454137844e-11, Output Loss: 3.05694101143672e-07\n",
      "Iteration 380: Total Loss: 7.575843811035156, Expl Loss: 7.270506419132516e-11, Output Loss: 3.0533732342519215e-07\n",
      "Iteration 381: Total Loss: 7.559140682220459, Expl Loss: 7.254213896246142e-11, Output Loss: 3.0492705604956427e-07\n",
      "Iteration 382: Total Loss: 7.5398173332214355, Expl Loss: 7.235461535470833e-11, Output Loss: 3.043560070636886e-07\n",
      "Iteration 383: Total Loss: 7.521839618682861, Expl Loss: 7.21853202212408e-11, Output Loss: 3.0330750178109156e-07\n",
      "Iteration 384: Total Loss: 7.5025739669799805, Expl Loss: 7.200180035527026e-11, Output Loss: 3.0239411330512667e-07\n",
      "Iteration 385: Total Loss: 7.483585834503174, Expl Loss: 7.182135441929915e-11, Output Loss: 3.014508536125504e-07\n",
      "Iteration 386: Total Loss: 7.444157123565674, Expl Loss: 7.143267227727179e-11, Output Loss: 3.008900364420697e-07\n",
      "Iteration 387: Total Loss: 7.426021099090576, Expl Loss: 7.125769418969696e-11, Output Loss: 3.002518838002288e-07\n",
      "Iteration 388: Total Loss: 7.3989996910095215, Expl Loss: 7.099174720304191e-11, Output Loss: 2.998253876285162e-07\n",
      "Iteration 389: Total Loss: 7.380009651184082, Expl Loss: 7.080856734287266e-11, Output Loss: 2.991526457662985e-07\n",
      "Iteration 390: Total Loss: 7.364110946655273, Expl Loss: 7.065300428044097e-11, Output Loss: 2.988105904933036e-07\n",
      "Iteration 391: Total Loss: 7.347259521484375, Expl Loss: 7.049034966843948e-11, Output Loss: 2.98224819061943e-07\n",
      "Iteration 392: Total Loss: 7.319095134735107, Expl Loss: 7.020772851973334e-11, Output Loss: 2.9832219183845154e-07\n",
      "Iteration 393: Total Loss: 7.307187080383301, Expl Loss: 7.009092611864887e-11, Output Loss: 2.9809493184984603e-07\n",
      "Iteration 394: Total Loss: 7.284109592437744, Expl Loss: 6.985510780932458e-11, Output Loss: 2.985986498060811e-07\n",
      "Iteration 395: Total Loss: 7.269268989562988, Expl Loss: 6.9712895178764e-11, Output Loss: 2.979799091917812e-07\n",
      "Iteration 396: Total Loss: 7.251005172729492, Expl Loss: 6.953630726780347e-11, Output Loss: 2.973747257328796e-07\n",
      "Iteration 397: Total Loss: 7.237029075622559, Expl Loss: 6.941158758877464e-11, Output Loss: 2.9587019412247173e-07\n",
      "Iteration 398: Total Loss: 7.212617874145508, Expl Loss: 6.918043221615378e-11, Output Loss: 2.9457476102834335e-07\n",
      "Iteration 399: Total Loss: 7.198458671569824, Expl Loss: 6.905437333060149e-11, Output Loss: 2.9302185566848493e-07\n",
      "Iteration 400: Total Loss: 7.177330493927002, Expl Loss: 6.885475523077389e-11, Output Loss: 2.918553718700423e-07\n",
      "Iteration 401: Total Loss: 7.162496089935303, Expl Loss: 6.871418017917463e-11, Output Loss: 2.9107812338224903e-07\n",
      "Iteration 402: Total Loss: 7.147272109985352, Expl Loss: 6.85665343946873e-11, Output Loss: 2.9061868644930655e-07\n",
      "Iteration 403: Total Loss: 7.131678581237793, Expl Loss: 6.840922966988572e-11, Output Loss: 2.907558496190177e-07\n",
      "Iteration 404: Total Loss: 7.111134052276611, Expl Loss: 6.820649600669526e-11, Output Loss: 2.9048445071566675e-07\n",
      "Iteration 405: Total Loss: 7.099660396575928, Expl Loss: 6.809217079073449e-11, Output Loss: 2.9044323923699267e-07\n",
      "Iteration 406: Total Loss: 7.084582805633545, Expl Loss: 6.794740464721727e-11, Output Loss: 2.8984260325159994e-07\n",
      "Iteration 407: Total Loss: 7.06636905670166, Expl Loss: 6.77707473473177e-11, Output Loss: 2.892942347898497e-07\n",
      "Iteration 408: Total Loss: 7.049427509307861, Expl Loss: 6.76139352839833e-11, Output Loss: 2.880340161937056e-07\n",
      "Iteration 409: Total Loss: 7.0323076248168945, Expl Loss: 6.745153047216235e-11, Output Loss: 2.8715447797367233e-07\n",
      "Iteration 410: Total Loss: 7.009071350097656, Expl Loss: 6.722923606705677e-11, Output Loss: 2.861480368210323e-07\n",
      "Iteration 411: Total Loss: 6.995403289794922, Expl Loss: 6.709791749992533e-11, Output Loss: 2.8561160547724285e-07\n",
      "Iteration 412: Total Loss: 6.983283996582031, Expl Loss: 6.69802893704663e-11, Output Loss: 2.8525562356662704e-07\n",
      "Iteration 413: Total Loss: 6.968811511993408, Expl Loss: 6.683925635186938e-11, Output Loss: 2.848859708137752e-07\n",
      "Iteration 414: Total Loss: 6.956692695617676, Expl Loss: 6.671957430981479e-11, Output Loss: 2.847351936452469e-07\n",
      "Iteration 415: Total Loss: 6.942983627319336, Expl Loss: 6.658738838094536e-11, Output Loss: 2.842448054707347e-07\n",
      "Iteration 416: Total Loss: 6.9309186935424805, Expl Loss: 6.646946881794236e-11, Output Loss: 2.8397158757798024e-07\n",
      "Iteration 417: Total Loss: 6.916811943054199, Expl Loss: 6.633586041582262e-11, Output Loss: 2.8322580192252644e-07\n",
      "Iteration 418: Total Loss: 6.904456615447998, Expl Loss: 6.621721920785362e-11, Output Loss: 2.8273467478356906e-07\n",
      "Iteration 419: Total Loss: 6.888720512390137, Expl Loss: 6.606935137876135e-11, Output Loss: 2.8178573074910673e-07\n",
      "Iteration 420: Total Loss: 6.873043060302734, Expl Loss: 6.591913126463567e-11, Output Loss: 2.8112970085203415e-07\n",
      "Iteration 421: Total Loss: 6.857898235321045, Expl Loss: 6.577496186599419e-11, Output Loss: 2.804023608860007e-07\n",
      "Iteration 422: Total Loss: 6.845118045806885, Expl Loss: 6.565287896664884e-11, Output Loss: 2.798302602968761e-07\n",
      "Iteration 423: Total Loss: 6.824580192565918, Expl Loss: 6.545255309964304e-11, Output Loss: 2.793250359900412e-07\n",
      "Iteration 424: Total Loss: 6.811735153198242, Expl Loss: 6.532974855533169e-11, Output Loss: 2.7876018293682137e-07\n",
      "Iteration 425: Total Loss: 6.79934549331665, Expl Loss: 6.520978201862704e-11, Output Loss: 2.7836765070787806e-07\n",
      "Iteration 426: Total Loss: 6.776631832122803, Expl Loss: 6.498858395875828e-11, Output Loss: 2.7777326749856e-07\n",
      "Iteration 427: Total Loss: 6.758512496948242, Expl Loss: 6.481041397998766e-11, Output Loss: 2.7747097419705824e-07\n",
      "Iteration 428: Total Loss: 6.743415355682373, Expl Loss: 6.466530783066915e-11, Output Loss: 2.7688449222296185e-07\n",
      "Iteration 429: Total Loss: 6.724033355712891, Expl Loss: 6.447281597488086e-11, Output Loss: 2.7675210390043503e-07\n",
      "Iteration 430: Total Loss: 6.709101676940918, Expl Loss: 6.432742533091229e-11, Output Loss: 2.7635883270704653e-07\n",
      "Iteration 431: Total Loss: 6.69130277633667, Expl Loss: 6.414481446004316e-11, Output Loss: 2.7682159497999237e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 432: Total Loss: 6.683438301086426, Expl Loss: 6.40598130097203e-11, Output Loss: 2.774571896679845e-07\n",
      "Iteration 433: Total Loss: 6.666543960571289, Expl Loss: 6.386371986799588e-11, Output Loss: 2.801720597744861e-07\n",
      "Iteration 434: Total Loss: 6.661230087280273, Expl Loss: 6.376721373158034e-11, Output Loss: 2.845088715730526e-07\n",
      "Iteration 435: Total Loss: 6.645684242248535, Expl Loss: 6.353995107843957e-11, Output Loss: 2.91689275400131e-07\n",
      "Iteration 436: Total Loss: 6.642791271209717, Expl Loss: 6.34535202159725e-11, Output Loss: 2.9743938512183377e-07\n",
      "Iteration 437: Total Loss: 6.619593143463135, Expl Loss: 6.324575585470171e-11, Output Loss: 2.950176281046879e-07\n",
      "Iteration 438: Total Loss: 6.5947957038879395, Expl Loss: 6.312164679833643e-11, Output Loss: 2.826311344961141e-07\n",
      "Iteration 439: Total Loss: 6.570788860321045, Expl Loss: 6.298687960093474e-11, Output Loss: 2.7210091957385885e-07\n",
      "Iteration 440: Total Loss: 6.557070255279541, Expl Loss: 6.281544728814481e-11, Output Loss: 2.7552567871680367e-07\n",
      "Iteration 441: Total Loss: 6.548644065856934, Expl Loss: 6.266061280957302e-11, Output Loss: 2.825826186381164e-07\n",
      "Iteration 442: Total Loss: 6.53291130065918, Expl Loss: 6.254031320596098e-11, Output Loss: 2.7888020781574596e-07\n",
      "Iteration 443: Total Loss: 6.510994911193848, Expl Loss: 6.240183370032071e-11, Output Loss: 2.70811796099224e-07\n",
      "Iteration 444: Total Loss: 6.486722946166992, Expl Loss: 6.216325371122267e-11, Output Loss: 2.703977486362419e-07\n",
      "Iteration 445: Total Loss: 6.478633403778076, Expl Loss: 6.204316921332165e-11, Output Loss: 2.7431676130618143e-07\n",
      "Iteration 446: Total Loss: 6.4628682136535645, Expl Loss: 6.189381646093395e-11, Output Loss: 2.734864494868816e-07\n",
      "Iteration 447: Total Loss: 6.443538665771484, Expl Loss: 6.174605965414415e-11, Output Loss: 2.6893297899732715e-07\n",
      "Iteration 448: Total Loss: 6.426929950714111, Expl Loss: 6.158778348419602e-11, Output Loss: 2.6815155251824763e-07\n",
      "Iteration 449: Total Loss: 6.420700550079346, Expl Loss: 6.150351061773307e-11, Output Loss: 2.703496022604668e-07\n",
      "Iteration 450: Total Loss: 6.399397373199463, Expl Loss: 6.129924345898985e-11, Output Loss: 2.6947299147650483e-07\n",
      "Iteration 451: Total Loss: 6.384524345397949, Expl Loss: 6.117843731612282e-11, Output Loss: 2.6668095642889966e-07\n",
      "Iteration 452: Total Loss: 6.363643646240234, Expl Loss: 6.096947252620666e-11, Output Loss: 2.666966736342147e-07\n",
      "Iteration 453: Total Loss: 6.350388526916504, Expl Loss: 6.08299591253747e-11, Output Loss: 2.673926644547464e-07\n",
      "Iteration 454: Total Loss: 6.333691120147705, Expl Loss: 6.067880226057198e-11, Output Loss: 2.658109963249444e-07\n",
      "Iteration 455: Total Loss: 6.320852279663086, Expl Loss: 6.056246476537908e-11, Output Loss: 2.64606029531933e-07\n",
      "Iteration 456: Total Loss: 6.306694984436035, Expl Loss: 6.04161651263091e-11, Output Loss: 2.6507879624659836e-07\n",
      "Iteration 457: Total Loss: 6.294555187225342, Expl Loss: 6.029352711545144e-11, Output Loss: 2.6520257279116777e-07\n",
      "Iteration 458: Total Loss: 6.279415130615234, Expl Loss: 6.015626885513825e-11, Output Loss: 2.6378799589110713e-07\n",
      "Iteration 459: Total Loss: 6.266228675842285, Expl Loss: 6.004011177118684e-11, Output Loss: 2.622174974931113e-07\n",
      "Iteration 460: Total Loss: 6.250533580780029, Expl Loss: 5.988352869135127e-11, Output Loss: 2.6218060611427063e-07\n",
      "Iteration 461: Total Loss: 6.237464904785156, Expl Loss: 5.974722105950292e-11, Output Loss: 2.627432138524455e-07\n",
      "Iteration 462: Total Loss: 6.228307247161865, Expl Loss: 5.96617616421824e-11, Output Loss: 2.6213126602669945e-07\n",
      "Iteration 463: Total Loss: 6.21259069442749, Expl Loss: 5.951512893620503e-11, Output Loss: 2.610778722100804e-07\n",
      "Iteration 464: Total Loss: 6.19951057434082, Expl Loss: 5.939151254130692e-11, Output Loss: 2.6035937139567977e-07\n",
      "Iteration 465: Total Loss: 6.188379764556885, Expl Loss: 5.927998369958942e-11, Output Loss: 2.603817392810015e-07\n",
      "Iteration 466: Total Loss: 6.176323413848877, Expl Loss: 5.915658934929624e-11, Output Loss: 2.606645068681246e-07\n",
      "Iteration 467: Total Loss: 6.164068222045898, Expl Loss: 5.903798977469066e-11, Output Loss: 2.602691040465288e-07\n",
      "Iteration 468: Total Loss: 6.149028301239014, Expl Loss: 5.889535387160194e-11, Output Loss: 2.594929355836939e-07\n",
      "Iteration 469: Total Loss: 6.135001182556152, Expl Loss: 5.876419489903029e-11, Output Loss: 2.5858173557935515e-07\n",
      "Iteration 470: Total Loss: 6.118943214416504, Expl Loss: 5.860949225944267e-11, Output Loss: 2.579939746283344e-07\n",
      "Iteration 471: Total Loss: 6.106106758117676, Expl Loss: 5.848165701705099e-11, Output Loss: 2.5794139446588815e-07\n",
      "Iteration 472: Total Loss: 6.094720840454102, Expl Loss: 5.836934408032235e-11, Output Loss: 2.5778669510145846e-07\n",
      "Iteration 473: Total Loss: 6.082261085510254, Expl Loss: 5.824472848470208e-11, Output Loss: 2.5778808776522055e-07\n",
      "Iteration 474: Total Loss: 6.073611259460449, Expl Loss: 5.816162135241498e-11, Output Loss: 2.5744938625393843e-07\n",
      "Iteration 475: Total Loss: 6.0613322257995605, Expl Loss: 5.8037897404661365e-11, Output Loss: 2.57542467352323e-07\n",
      "Iteration 476: Total Loss: 6.0485124588012695, Expl Loss: 5.7907918044053375e-11, Output Loss: 2.577208420007082e-07\n",
      "Iteration 477: Total Loss: 6.039533615112305, Expl Loss: 5.7800722541578864e-11, Output Loss: 2.594611601125507e-07\n",
      "Iteration 478: Total Loss: 6.027754306793213, Expl Loss: 5.765645252897578e-11, Output Loss: 2.621093528887286e-07\n",
      "Iteration 479: Total Loss: 6.020362854003906, Expl Loss: 5.7503914824286184e-11, Output Loss: 2.699713945730764e-07\n",
      "Iteration 480: Total Loss: 6.020548343658447, Expl Loss: 5.743478609376851e-11, Output Loss: 2.770698870335764e-07\n",
      "Iteration 481: Total Loss: 6.01911735534668, Expl Loss: 5.7338560982556075e-11, Output Loss: 2.852611089565471e-07\n",
      "Iteration 482: Total Loss: 5.998350620269775, Expl Loss: 5.7206666487230606e-11, Output Loss: 2.7768410859607684e-07\n",
      "Iteration 483: Total Loss: 5.968653678894043, Expl Loss: 5.705536390565591e-11, Output Loss: 2.6311718670513073e-07\n",
      "Iteration 484: Total Loss: 5.946800231933594, Expl Loss: 5.696241742181307e-11, Output Loss: 2.505585712242464e-07\n",
      "Iteration 485: Total Loss: 5.940451145172119, Expl Loss: 5.6848921403673813e-11, Output Loss: 2.5555894467288454e-07\n",
      "Iteration 486: Total Loss: 5.938520908355713, Expl Loss: 5.674494901741767e-11, Output Loss: 2.640263403463905e-07\n",
      "Iteration 487: Total Loss: 5.920826435089111, Expl Loss: 5.665028168788666e-11, Output Loss: 2.5579825546628854e-07\n",
      "Iteration 488: Total Loss: 5.89848518371582, Expl Loss: 5.650380510702213e-11, Output Loss: 2.481047260971536e-07\n",
      "Iteration 489: Total Loss: 5.887263774871826, Expl Loss: 5.635009819870973e-11, Output Loss: 2.5225406830031716e-07\n",
      "Iteration 490: Total Loss: 5.882115840911865, Expl Loss: 5.6269818665688476e-11, Output Loss: 2.551342106471566e-07\n",
      "Iteration 491: Total Loss: 5.863232135772705, Expl Loss: 5.613015607863758e-11, Output Loss: 2.5021657279467036e-07\n",
      "Iteration 492: Total Loss: 5.8495869636535645, Expl Loss: 5.603242175800105e-11, Output Loss: 2.4634488227093243e-07\n",
      "Iteration 493: Total Loss: 5.840683937072754, Expl Loss: 5.5914047697447344e-11, Output Loss: 2.492794521913311e-07\n",
      "Iteration 494: Total Loss: 5.831636428833008, Expl Loss: 5.581011347510767e-11, Output Loss: 2.506251348677324e-07\n",
      "Iteration 495: Total Loss: 5.814709186553955, Expl Loss: 5.56845229648939e-11, Output Loss: 2.4625683181511704e-07\n",
      "Iteration 496: Total Loss: 5.802541255950928, Expl Loss: 5.5579377905567995e-11, Output Loss: 2.4460362624267873e-07\n",
      "Iteration 497: Total Loss: 5.795577049255371, Expl Loss: 5.548760409479492e-11, Output Loss: 2.4681642685209226e-07\n",
      "Iteration 498: Total Loss: 5.781943321228027, Expl Loss: 5.535193137173877e-11, Output Loss: 2.4675011900399113e-07\n",
      "Iteration 499: Total Loss: 5.7676825523376465, Expl Loss: 5.5232349943645787e-11, Output Loss: 2.44447932118419e-07\n",
      "Iteration 500: Total Loss: 5.754263401031494, Expl Loss: 5.511405914981893e-11, Output Loss: 2.42857680632369e-07\n",
      "Iteration 501: Total Loss: 5.745049476623535, Expl Loss: 5.501329947144029e-11, Output Loss: 2.437196542359743e-07\n",
      "Iteration 502: Total Loss: 5.733325958251953, Expl Loss: 5.488356991101284e-11, Output Loss: 2.4496887363056885e-07\n",
      "Iteration 503: Total Loss: 5.719384670257568, Expl Loss: 5.476067169163379e-11, Output Loss: 2.433174017824058e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 504: Total Loss: 5.705412864685059, Expl Loss: 5.463769714442179e-11, Output Loss: 2.4164361889233987e-07\n",
      "Iteration 505: Total Loss: 5.695330619812012, Expl Loss: 5.454223878098574e-11, Output Loss: 2.411069885965844e-07\n",
      "Iteration 506: Total Loss: 5.683882236480713, Expl Loss: 5.442182815507124e-11, Output Loss: 2.4169989387701207e-07\n",
      "Iteration 507: Total Loss: 5.67196798324585, Expl Loss: 5.4299138102509303e-11, Output Loss: 2.4205436943702807e-07\n",
      "Iteration 508: Total Loss: 5.657704830169678, Expl Loss: 5.416775014643882e-11, Output Loss: 2.40930120298799e-07\n",
      "Iteration 509: Total Loss: 5.649165630340576, Expl Loss: 5.409351785945482e-11, Output Loss: 2.3981363028724445e-07\n",
      "Iteration 510: Total Loss: 5.638529300689697, Expl Loss: 5.399213368062483e-11, Output Loss: 2.393161651070841e-07\n",
      "Iteration 511: Total Loss: 5.628779888153076, Expl Loss: 5.3894493035056e-11, Output Loss: 2.393307738657313e-07\n",
      "Iteration 512: Total Loss: 5.6210408210754395, Expl Loss: 5.3816198025691264e-11, Output Loss: 2.3942089910633513e-07\n",
      "Iteration 513: Total Loss: 5.604423522949219, Expl Loss: 5.3657966958553516e-11, Output Loss: 2.386267681231402e-07\n",
      "Iteration 514: Total Loss: 5.595107555389404, Expl Loss: 5.357292734431418e-11, Output Loss: 2.3781484514984186e-07\n",
      "Iteration 515: Total Loss: 5.587929725646973, Expl Loss: 5.3508718289574375e-11, Output Loss: 2.3705828766651393e-07\n",
      "Iteration 516: Total Loss: 5.575178146362305, Expl Loss: 5.338169489776945e-11, Output Loss: 2.3700835072304471e-07\n",
      "Iteration 517: Total Loss: 5.5633111000061035, Expl Loss: 5.3263324306662696e-11, Output Loss: 2.369787921452371e-07\n",
      "Iteration 518: Total Loss: 5.555161476135254, Expl Loss: 5.3183690090774505e-11, Output Loss: 2.3679243099650193e-07\n",
      "Iteration 519: Total Loss: 5.54127836227417, Expl Loss: 5.3051528448033736e-11, Output Loss: 2.3612540189787978e-07\n",
      "Iteration 520: Total Loss: 5.528812885284424, Expl Loss: 5.293045515775141e-11, Output Loss: 2.3576733099162084e-07\n",
      "Iteration 521: Total Loss: 5.51970100402832, Expl Loss: 5.28434136726208e-11, Output Loss: 2.3535947946129454e-07\n",
      "Iteration 522: Total Loss: 5.511218070983887, Expl Loss: 5.275791956083076e-11, Output Loss: 2.3542632732187485e-07\n",
      "Iteration 523: Total Loss: 5.496848106384277, Expl Loss: 5.2618135543136546e-11, Output Loss: 2.3503466195506917e-07\n",
      "Iteration 524: Total Loss: 5.485414505004883, Expl Loss: 5.2507956316283355e-11, Output Loss: 2.346190797197778e-07\n",
      "Iteration 525: Total Loss: 5.4727702140808105, Expl Loss: 5.239134126533429e-11, Output Loss: 2.3363637069451215e-07\n",
      "Iteration 526: Total Loss: 5.4600043296813965, Expl Loss: 5.227037899735443e-11, Output Loss: 2.3296657047922054e-07\n",
      "Iteration 527: Total Loss: 5.446196556091309, Expl Loss: 5.213839429640821e-11, Output Loss: 2.3235716639646853e-07\n",
      "Iteration 528: Total Loss: 5.437803745269775, Expl Loss: 5.205816680509123e-11, Output Loss: 2.3198683152259036e-07\n",
      "Iteration 529: Total Loss: 5.429419994354248, Expl Loss: 5.197775196363885e-11, Output Loss: 2.3164524520780105e-07\n",
      "Iteration 530: Total Loss: 5.421219825744629, Expl Loss: 5.1900383296610286e-11, Output Loss: 2.311815308075893e-07\n",
      "Iteration 531: Total Loss: 5.411679744720459, Expl Loss: 5.1808498463534747e-11, Output Loss: 2.3083001110535406e-07\n",
      "Iteration 532: Total Loss: 5.40536642074585, Expl Loss: 5.175059339390664e-11, Output Loss: 2.3030713691696292e-07\n",
      "Iteration 533: Total Loss: 5.394927024841309, Expl Loss: 5.165004188234512e-11, Output Loss: 2.2992266224264313e-07\n",
      "Iteration 534: Total Loss: 5.383543968200684, Expl Loss: 5.1540369194746916e-11, Output Loss: 2.2950703737478761e-07\n",
      "Iteration 535: Total Loss: 5.370887756347656, Expl Loss: 5.141583686585349e-11, Output Loss: 2.2930450427338656e-07\n",
      "Iteration 536: Total Loss: 5.363717555999756, Expl Loss: 5.13471209995231e-11, Output Loss: 2.2900553631188814e-07\n",
      "Iteration 537: Total Loss: 5.348299980163574, Expl Loss: 5.1194739419946345e-11, Output Loss: 2.28826110060254e-07\n",
      "Iteration 538: Total Loss: 5.339231014251709, Expl Loss: 5.1107579973619366e-11, Output Loss: 2.284732261159661e-07\n",
      "Iteration 539: Total Loss: 5.331165313720703, Expl Loss: 5.1029420272685755e-11, Output Loss: 2.2822332823579927e-07\n",
      "Iteration 540: Total Loss: 5.32180643081665, Expl Loss: 5.093910709907945e-11, Output Loss: 2.2789558329350257e-07\n",
      "Iteration 541: Total Loss: 5.312473773956299, Expl Loss: 5.0847315941071614e-11, Output Loss: 2.2774216290599725e-07\n",
      "Iteration 542: Total Loss: 5.298670291900635, Expl Loss: 5.0710113191909656e-11, Output Loss: 2.276591999361699e-07\n",
      "Iteration 543: Total Loss: 5.292026042938232, Expl Loss: 5.0644155535906066e-11, Output Loss: 2.2761057039133448e-07\n",
      "Iteration 544: Total Loss: 5.283807754516602, Expl Loss: 5.05606632950073e-11, Output Loss: 2.2774182184548408e-07\n",
      "Iteration 545: Total Loss: 5.269282341003418, Expl Loss: 5.0415289998273494e-11, Output Loss: 2.2775364527660713e-07\n",
      "Iteration 546: Total Loss: 5.258605480194092, Expl Loss: 5.0305523635607585e-11, Output Loss: 2.2805286903349042e-07\n",
      "Iteration 547: Total Loss: 5.2508955001831055, Expl Loss: 5.0231256654154066e-11, Output Loss: 2.2776994512696547e-07\n",
      "Iteration 548: Total Loss: 5.242286682128906, Expl Loss: 5.014566886729632e-11, Output Loss: 2.277197665989661e-07\n",
      "Iteration 549: Total Loss: 5.231376647949219, Expl Loss: 5.004317099599476e-11, Output Loss: 2.2705967239744496e-07\n",
      "Iteration 550: Total Loss: 5.221703052520752, Expl Loss: 4.994928776147489e-11, Output Loss: 2.267741336936524e-07\n",
      "Iteration 551: Total Loss: 5.210781574249268, Expl Loss: 4.9850571587350956e-11, Output Loss: 2.257249178683196e-07\n",
      "Iteration 552: Total Loss: 5.199558258056641, Expl Loss: 4.9739875412901924e-11, Output Loss: 2.255704885101295e-07\n",
      "Iteration 553: Total Loss: 5.191195011138916, Expl Loss: 4.966261429872887e-11, Output Loss: 2.2493361484521301e-07\n",
      "Iteration 554: Total Loss: 5.177572727203369, Expl Loss: 4.951912838113692e-11, Output Loss: 2.2565967583432212e-07\n",
      "Iteration 555: Total Loss: 5.168257236480713, Expl Loss: 4.9416217645648075e-11, Output Loss: 2.2663535048650374e-07\n",
      "Iteration 556: Total Loss: 5.161703109741211, Expl Loss: 4.933818978369864e-11, Output Loss: 2.2788424303143984e-07\n",
      "Iteration 557: Total Loss: 5.151732444763184, Expl Loss: 4.9238127464157344e-11, Output Loss: 2.279197417465184e-07\n",
      "Iteration 558: Total Loss: 5.1331610679626465, Expl Loss: 4.905292838586206e-11, Output Loss: 2.278684121392871e-07\n",
      "Iteration 559: Total Loss: 5.126117706298828, Expl Loss: 4.8991241619056325e-11, Output Loss: 2.2699379087498528e-07\n",
      "Iteration 560: Total Loss: 5.113396167755127, Expl Loss: 4.8862879020727945e-11, Output Loss: 2.2710862879193883e-07\n",
      "Iteration 561: Total Loss: 5.104008197784424, Expl Loss: 4.874475129090783e-11, Output Loss: 2.2953304323891643e-07\n",
      "Iteration 562: Total Loss: 5.09261417388916, Expl Loss: 4.8638672950351847e-11, Output Loss: 2.2874699823205447e-07\n",
      "Iteration 563: Total Loss: 5.084945201873779, Expl Loss: 4.857828375670614e-11, Output Loss: 2.271172121481868e-07\n",
      "Iteration 564: Total Loss: 5.0673651695251465, Expl Loss: 4.846153339732595e-11, Output Loss: 2.212116925193186e-07\n",
      "Iteration 565: Total Loss: 5.05411434173584, Expl Loss: 4.8360704330008275e-11, Output Loss: 2.180437377319322e-07\n",
      "Iteration 566: Total Loss: 5.045421600341797, Expl Loss: 4.8260916096776185e-11, Output Loss: 2.1933051641553902e-07\n",
      "Iteration 567: Total Loss: 5.0389084815979, Expl Loss: 4.81740168589706e-11, Output Loss: 2.215068946043175e-07\n",
      "Iteration 568: Total Loss: 5.0333662033081055, Expl Loss: 4.811627832279619e-11, Output Loss: 2.2173820468651684e-07\n",
      "Iteration 569: Total Loss: 5.023176193237305, Expl Loss: 4.804718081730108e-11, Output Loss: 2.1845798414688034e-07\n",
      "Iteration 570: Total Loss: 5.0097222328186035, Expl Loss: 4.793480889997426e-11, Output Loss: 2.1624151713695028e-07\n",
      "Iteration 571: Total Loss: 5.003520488739014, Expl Loss: 4.7868525115957183e-11, Output Loss: 2.1666825489319308e-07\n",
      "Iteration 572: Total Loss: 4.995594024658203, Expl Loss: 4.777220632967705e-11, Output Loss: 2.1837313113337586e-07\n",
      "Iteration 573: Total Loss: 4.986766338348389, Expl Loss: 4.767589101284386e-11, Output Loss: 2.1917726655829028e-07\n",
      "Iteration 574: Total Loss: 4.977766513824463, Expl Loss: 4.760310548523883e-11, Output Loss: 2.1745579203980014e-07\n",
      "Iteration 575: Total Loss: 4.968446731567383, Expl Loss: 4.753217611175309e-11, Output Loss: 2.1522885162994498e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 576: Total Loss: 4.960244655609131, Expl Loss: 4.745948772866271e-11, Output Loss: 2.142959232287467e-07\n",
      "Iteration 577: Total Loss: 4.950003147125244, Expl Loss: 4.7351438742238017e-11, Output Loss: 2.1485955414846103e-07\n",
      "Iteration 578: Total Loss: 4.946174621582031, Expl Loss: 4.7302276678928834e-11, Output Loss: 2.159472529683626e-07\n",
      "Iteration 579: Total Loss: 4.936148166656494, Expl Loss: 4.7209691017569e-11, Output Loss: 2.151787583670739e-07\n",
      "Iteration 580: Total Loss: 4.923797130584717, Expl Loss: 4.709821768700273e-11, Output Loss: 2.1397526950295287e-07\n",
      "Iteration 581: Total Loss: 4.915775299072266, Expl Loss: 4.703144471096543e-11, Output Loss: 2.1263088001433061e-07\n",
      "Iteration 582: Total Loss: 4.909265518188477, Expl Loss: 4.696820710137217e-11, Output Loss: 2.124450162455105e-07\n",
      "Iteration 583: Total Loss: 4.902553081512451, Expl Loss: 4.68968613942522e-11, Output Loss: 2.12867277582518e-07\n",
      "Iteration 584: Total Loss: 4.898192882537842, Expl Loss: 4.685388535485835e-11, Output Loss: 2.1280432349612965e-07\n",
      "Iteration 585: Total Loss: 4.890769958496094, Expl Loss: 4.678277557013111e-11, Output Loss: 2.1249246628940455e-07\n",
      "Iteration 586: Total Loss: 4.878257751464844, Expl Loss: 4.666727421165362e-11, Output Loss: 2.1153002194296278e-07\n",
      "Iteration 587: Total Loss: 4.86956787109375, Expl Loss: 4.658748734009954e-11, Output Loss: 2.1081916656839894e-07\n",
      "Iteration 588: Total Loss: 4.860589504241943, Expl Loss: 4.6500119726955447e-11, Output Loss: 2.1057753940567636e-07\n",
      "Iteration 589: Total Loss: 4.855246067047119, Expl Loss: 4.6448331292303635e-11, Output Loss: 2.1041300612978375e-07\n",
      "Iteration 590: Total Loss: 4.844638824462891, Expl Loss: 4.63391373883848e-11, Output Loss: 2.1072520439702203e-07\n",
      "Iteration 591: Total Loss: 4.838468074798584, Expl Loss: 4.628117333815851e-11, Output Loss: 2.1035101838151604e-07\n",
      "Iteration 592: Total Loss: 4.833341121673584, Expl Loss: 4.623009614013185e-11, Output Loss: 2.1033152108884678e-07\n",
      "Iteration 593: Total Loss: 4.822226047515869, Expl Loss: 4.612272369586279e-11, Output Loss: 2.0995395288991858e-07\n",
      "Iteration 594: Total Loss: 4.813293933868408, Expl Loss: 4.602940251174914e-11, Output Loss: 2.1035390318502323e-07\n",
      "Iteration 595: Total Loss: 4.80874490737915, Expl Loss: 4.597754815760524e-11, Output Loss: 2.1098986735523795e-07\n",
      "Iteration 596: Total Loss: 4.802197456359863, Expl Loss: 4.5899326006626495e-11, Output Loss: 2.122647941860123e-07\n",
      "Iteration 597: Total Loss: 4.796934127807617, Expl Loss: 4.582987808698924e-11, Output Loss: 2.1394647831129987e-07\n",
      "Iteration 598: Total Loss: 4.7943925857543945, Expl Loss: 4.5787994923385256e-11, Output Loss: 2.1559341689680878e-07\n",
      "Iteration 599: Total Loss: 4.788336753845215, Expl Loss: 4.571472367320695e-11, Output Loss: 2.1686444995339116e-07\n",
      "Iteration 600: Total Loss: 4.7833404541015625, Expl Loss: 4.5659327013725104e-11, Output Loss: 2.1740756039889675e-07\n",
      "Iteration 601: Total Loss: 4.773256778717041, Expl Loss: 4.558186814107579e-11, Output Loss: 2.1507011638277618e-07\n",
      "Iteration 602: Total Loss: 4.761269569396973, Expl Loss: 4.549084026139738e-11, Output Loss: 2.1218586709892406e-07\n",
      "Iteration 603: Total Loss: 4.752593040466309, Expl Loss: 4.543887141550407e-11, Output Loss: 2.087060977373767e-07\n",
      "Iteration 604: Total Loss: 4.743515491485596, Expl Loss: 4.535108052983183e-11, Output Loss: 2.0840718661929714e-07\n",
      "Iteration 605: Total Loss: 4.732189655303955, Expl Loss: 4.523617244678313e-11, Output Loss: 2.0857237359450664e-07\n",
      "Iteration 606: Total Loss: 4.726341247558594, Expl Loss: 4.516851129232613e-11, Output Loss: 2.0949033796568983e-07\n",
      "Iteration 607: Total Loss: 4.7184834480285645, Expl Loss: 4.5113641988780984e-11, Output Loss: 2.0711959791697154e-07\n",
      "Iteration 608: Total Loss: 4.707766056060791, Expl Loss: 4.503080894280309e-11, Output Loss: 2.0468529271511215e-07\n",
      "Iteration 609: Total Loss: 4.6999192237854, Expl Loss: 4.495620542499523e-11, Output Loss: 2.0429891378626053e-07\n",
      "Iteration 610: Total Loss: 4.690253734588623, Expl Loss: 4.485101526285895e-11, Output Loss: 2.0515258825071214e-07\n",
      "Iteration 611: Total Loss: 4.686164379119873, Expl Loss: 4.4795386150431327e-11, Output Loss: 2.0662582755903713e-07\n",
      "Iteration 612: Total Loss: 4.6772379875183105, Expl Loss: 4.471877729228524e-11, Output Loss: 2.0536020883810124e-07\n",
      "Iteration 613: Total Loss: 4.667126655578613, Expl Loss: 4.463504565954679e-11, Output Loss: 2.0362220709557732e-07\n",
      "Iteration 614: Total Loss: 4.657886981964111, Expl Loss: 4.455956784110704e-11, Output Loss: 2.019306606371174e-07\n",
      "Iteration 615: Total Loss: 4.653276443481445, Expl Loss: 4.451557525375627e-11, Output Loss: 2.0171904679955333e-07\n",
      "Iteration 616: Total Loss: 4.645928859710693, Expl Loss: 4.443525755681854e-11, Output Loss: 2.0240318576725258e-07\n",
      "Iteration 617: Total Loss: 4.636306285858154, Expl Loss: 4.433570177653223e-11, Output Loss: 2.027362739909222e-07\n",
      "Iteration 618: Total Loss: 4.630878925323486, Expl Loss: 4.428062083672302e-11, Output Loss: 2.0281709112168755e-07\n",
      "Iteration 619: Total Loss: 4.624363899230957, Expl Loss: 4.422387109292991e-11, Output Loss: 2.019765616978475e-07\n",
      "Iteration 620: Total Loss: 4.6170854568481445, Expl Loss: 4.4154867262502506e-11, Output Loss: 2.0159875191438914e-07\n",
      "Iteration 621: Total Loss: 4.6134819984436035, Expl Loss: 4.412552268018288e-11, Output Loss: 2.009294917115767e-07\n",
      "Iteration 622: Total Loss: 4.6086578369140625, Expl Loss: 4.407055276267613e-11, Output Loss: 2.016022762063585e-07\n",
      "Iteration 623: Total Loss: 4.605503559112549, Expl Loss: 4.4023201750675867e-11, Output Loss: 2.0318380222761334e-07\n",
      "Iteration 624: Total Loss: 4.59961462020874, Expl Loss: 4.392959607191216e-11, Output Loss: 2.0665493138949387e-07\n",
      "Iteration 625: Total Loss: 4.599069595336914, Expl Loss: 4.387864377397577e-11, Output Loss: 2.1120560234066943e-07\n",
      "Iteration 626: Total Loss: 4.594610214233398, Expl Loss: 4.3789916137626506e-11, Output Loss: 2.1561855589879997e-07\n",
      "Iteration 627: Total Loss: 4.588781833648682, Expl Loss: 4.371606548980722e-11, Output Loss: 2.1717548293054278e-07\n",
      "Iteration 628: Total Loss: 4.578938007354736, Expl Loss: 4.369497125233934e-11, Output Loss: 2.0944111156495637e-07\n",
      "Iteration 629: Total Loss: 4.5619354248046875, Expl Loss: 4.362042671512967e-11, Output Loss: 1.998930798663423e-07\n",
      "Iteration 630: Total Loss: 4.5496063232421875, Expl Loss: 4.3517987824426285e-11, Output Loss: 1.9780767956945056e-07\n",
      "Iteration 631: Total Loss: 4.551390647888184, Expl Loss: 4.3485187672942516e-11, Output Loss: 2.0287174606892222e-07\n",
      "Iteration 632: Total Loss: 4.547235488891602, Expl Loss: 4.342953774383318e-11, Output Loss: 2.04281676019491e-07\n",
      "Iteration 633: Total Loss: 4.534408092498779, Expl Loss: 4.334712103148952e-11, Output Loss: 1.9969598952229717e-07\n",
      "Iteration 634: Total Loss: 4.529287338256836, Expl Loss: 4.3333451410498824e-11, Output Loss: 1.959423343578237e-07\n",
      "Iteration 635: Total Loss: 4.521908283233643, Expl Loss: 4.324068533789749e-11, Output Loss: 1.9783963978170505e-07\n",
      "Iteration 636: Total Loss: 4.5166192054748535, Expl Loss: 4.316862492470541e-11, Output Loss: 1.997566982936405e-07\n",
      "Iteration 637: Total Loss: 4.505853176116943, Expl Loss: 4.3089299489595945e-11, Output Loss: 1.969233096588141e-07\n",
      "Iteration 638: Total Loss: 4.502942085266113, Expl Loss: 4.3081344047735115e-11, Output Loss: 1.9480809498872986e-07\n",
      "Iteration 639: Total Loss: 4.498927593231201, Expl Loss: 4.3026485152530825e-11, Output Loss: 1.962788473974797e-07\n",
      "Iteration 640: Total Loss: 4.496315002441406, Expl Loss: 4.2993577448191544e-11, Output Loss: 1.969568756976514e-07\n",
      "Iteration 641: Total Loss: 4.484373092651367, Expl Loss: 4.289264776691226e-11, Output Loss: 1.9510865456595639e-07\n",
      "Iteration 642: Total Loss: 4.4753289222717285, Expl Loss: 4.2814762152287855e-11, Output Loss: 1.9385281291306455e-07\n",
      "Iteration 643: Total Loss: 4.468227386474609, Expl Loss: 4.2735148753081376e-11, Output Loss: 1.947126975210267e-07\n",
      "Iteration 644: Total Loss: 4.462846279144287, Expl Loss: 4.2676612244108014e-11, Output Loss: 1.9518502369919588e-07\n",
      "Iteration 645: Total Loss: 4.4580841064453125, Expl Loss: 4.2637171571158206e-11, Output Loss: 1.9436691900409642e-07\n",
      "Iteration 646: Total Loss: 4.449836730957031, Expl Loss: 4.256493421617158e-11, Output Loss: 1.9334299850015668e-07\n",
      "Iteration 647: Total Loss: 4.443891525268555, Expl Loss: 4.249775184539395e-11, Output Loss: 1.9411641005717684e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 648: Total Loss: 4.441283702850342, Expl Loss: 4.245730156338112e-11, Output Loss: 1.955537243247818e-07\n",
      "Iteration 649: Total Loss: 4.436002254486084, Expl Loss: 4.238618483975998e-11, Output Loss: 1.9738403977953567e-07\n",
      "Iteration 650: Total Loss: 4.428578853607178, Expl Loss: 4.2296496166605024e-11, Output Loss: 1.989294844406686e-07\n",
      "Iteration 651: Total Loss: 4.424558162689209, Expl Loss: 4.222080324245425e-11, Output Loss: 2.024777074893791e-07\n",
      "Iteration 652: Total Loss: 4.42165470123291, Expl Loss: 4.218221258400767e-11, Output Loss: 2.0343374274034431e-07\n",
      "Iteration 653: Total Loss: 4.417660713195801, Expl Loss: 4.210780335522912e-11, Output Loss: 2.0688048607553355e-07\n",
      "Iteration 654: Total Loss: 4.407282829284668, Expl Loss: 4.207194315153373e-11, Output Loss: 2.0008828016671032e-07\n",
      "Iteration 655: Total Loss: 4.386147975921631, Expl Loss: 4.193315139566778e-11, Output Loss: 1.9283282881588093e-07\n",
      "Iteration 656: Total Loss: 4.375277042388916, Expl Loss: 4.1859373606234485e-11, Output Loss: 1.8933960177491826e-07\n",
      "Iteration 657: Total Loss: 4.372898578643799, Expl Loss: 4.180054913316411e-11, Output Loss: 1.928437285414475e-07\n",
      "Iteration 658: Total Loss: 4.370604515075684, Expl Loss: 4.173697498721651e-11, Output Loss: 1.969069387541822e-07\n",
      "Iteration 659: Total Loss: 4.3631744384765625, Expl Loss: 4.169958822686226e-11, Output Loss: 1.9321593924814806e-07\n",
      "Iteration 660: Total Loss: 4.358658313751221, Expl Loss: 4.1697995750711314e-11, Output Loss: 1.8885903330101428e-07\n",
      "Iteration 661: Total Loss: 4.353965759277344, Expl Loss: 4.1654579091554567e-11, Output Loss: 1.8850825256322423e-07\n",
      "Iteration 662: Total Loss: 4.353640556335449, Expl Loss: 4.162620248493454e-11, Output Loss: 1.910203053512305e-07\n",
      "Iteration 663: Total Loss: 4.343554973602295, Expl Loss: 4.1516554083464996e-11, Output Loss: 1.9189991462553735e-07\n",
      "Iteration 664: Total Loss: 4.331305503845215, Expl Loss: 4.142701459652898e-11, Output Loss: 1.8860457373648387e-07\n",
      "Iteration 665: Total Loss: 4.323819637298584, Expl Loss: 4.136969586343575e-11, Output Loss: 1.868499737156526e-07\n",
      "Iteration 666: Total Loss: 4.317174911499023, Expl Loss: 4.1294849484341256e-11, Output Loss: 1.8769004839214176e-07\n",
      "Iteration 667: Total Loss: 4.31428861618042, Expl Loss: 4.1257781913106584e-11, Output Loss: 1.8851021366117493e-07\n",
      "Iteration 668: Total Loss: 4.309742450714111, Expl Loss: 4.12151042461506e-11, Output Loss: 1.8823183722815884e-07\n",
      "Iteration 669: Total Loss: 4.3016228675842285, Expl Loss: 4.115214766176045e-11, Output Loss: 1.864079024471721e-07\n",
      "Iteration 670: Total Loss: 4.296999454498291, Expl Loss: 4.111316842525525e-11, Output Loss: 1.8568283621789305e-07\n",
      "Iteration 671: Total Loss: 4.292056560516357, Expl Loss: 4.106114406821071e-11, Output Loss: 1.8594224115986435e-07\n",
      "Iteration 672: Total Loss: 4.283623218536377, Expl Loss: 4.0974543202842995e-11, Output Loss: 1.8616896113599068e-07\n",
      "Iteration 673: Total Loss: 4.277036666870117, Expl Loss: 4.0913009091703145e-11, Output Loss: 1.857358711276902e-07\n",
      "Iteration 674: Total Loss: 4.269082069396973, Expl Loss: 4.084539650950347e-11, Output Loss: 1.8454248618127167e-07\n",
      "Iteration 675: Total Loss: 4.26314640045166, Expl Loss: 4.079090190622914e-11, Output Loss: 1.840565033717212e-07\n",
      "Iteration 676: Total Loss: 4.258410930633545, Expl Loss: 4.0743158846723304e-11, Output Loss: 1.8409491531201638e-07\n",
      "Iteration 677: Total Loss: 4.252894401550293, Expl Loss: 4.068745340646274e-11, Output Loss: 1.8414948499412276e-07\n",
      "Iteration 678: Total Loss: 4.250375747680664, Expl Loss: 4.0666581213599784e-11, Output Loss: 1.837177308061655e-07\n",
      "Iteration 679: Total Loss: 4.243373394012451, Expl Loss: 4.060497077462699e-11, Output Loss: 1.828764197853161e-07\n",
      "Iteration 680: Total Loss: 4.231466293334961, Expl Loss: 4.0491141689580346e-11, Output Loss: 1.8235185450521385e-07\n",
      "Iteration 681: Total Loss: 4.225979804992676, Expl Loss: 4.0437792003800155e-11, Output Loss: 1.8220090680642897e-07\n",
      "Iteration 682: Total Loss: 4.219898223876953, Expl Loss: 4.037624748431945e-11, Output Loss: 1.8227322584607464e-07\n",
      "Iteration 683: Total Loss: 4.213921546936035, Expl Loss: 4.03178254670955e-11, Output Loss: 1.8213893326901598e-07\n",
      "Iteration 684: Total Loss: 4.211052417755127, Expl Loss: 4.029283851014753e-11, Output Loss: 1.8176861260599253e-07\n",
      "Iteration 685: Total Loss: 4.202064037322998, Expl Loss: 4.020720215103246e-11, Output Loss: 1.81343907001974e-07\n",
      "Iteration 686: Total Loss: 4.1928629875183105, Expl Loss: 4.011778756418671e-11, Output Loss: 1.8108426047547255e-07\n",
      "Iteration 687: Total Loss: 4.191819190979004, Expl Loss: 4.010860046865794e-11, Output Loss: 1.809594181167995e-07\n",
      "Iteration 688: Total Loss: 4.185977458953857, Expl Loss: 4.005033457654683e-11, Output Loss: 1.8094416986969009e-07\n",
      "Iteration 689: Total Loss: 4.183435440063477, Expl Loss: 4.0025729258763576e-11, Output Loss: 1.808626564070437e-07\n",
      "Iteration 690: Total Loss: 4.177938938140869, Expl Loss: 3.9972591209247454e-11, Output Loss: 1.806798195502779e-07\n",
      "Iteration 691: Total Loss: 4.171669960021973, Expl Loss: 3.991360367217034e-11, Output Loss: 1.8030966941751103e-07\n",
      "Iteration 692: Total Loss: 4.166922092437744, Expl Loss: 3.987007599071113e-11, Output Loss: 1.7991435186104354e-07\n",
      "Iteration 693: Total Loss: 4.166133403778076, Expl Loss: 3.9866287354639596e-11, Output Loss: 1.7950443975678354e-07\n",
      "Iteration 694: Total Loss: 4.1564764976501465, Expl Loss: 3.977160267787383e-11, Output Loss: 1.79316501203175e-07\n",
      "Iteration 695: Total Loss: 4.151040077209473, Expl Loss: 3.9718867084204135e-11, Output Loss: 1.7915354533215577e-07\n",
      "Iteration 696: Total Loss: 4.140937328338623, Expl Loss: 3.961477326730467e-11, Output Loss: 1.7946011610092683e-07\n",
      "Iteration 697: Total Loss: 4.14469051361084, Expl Loss: 3.964830200264835e-11, Output Loss: 1.7986023692628805e-07\n",
      "Iteration 698: Total Loss: 4.1389875411987305, Expl Loss: 3.95771714012394e-11, Output Loss: 1.812707921544643e-07\n",
      "Iteration 699: Total Loss: 4.1355719566345215, Expl Loss: 3.952094554393604e-11, Output Loss: 1.8347718366840127e-07\n",
      "Iteration 700: Total Loss: 4.133054733276367, Expl Loss: 3.944533588651211e-11, Output Loss: 1.885213123387075e-07\n",
      "Iteration 701: Total Loss: 4.138772964477539, Expl Loss: 3.9413052682624183e-11, Output Loss: 1.974679264549195e-07\n",
      "Iteration 702: Total Loss: 4.14621639251709, Expl Loss: 3.933746384188197e-11, Output Loss: 2.1247004156066396e-07\n",
      "Iteration 703: Total Loss: 4.16021728515625, Expl Loss: 3.931454120587041e-11, Output Loss: 2.2876344019095995e-07\n",
      "Iteration 704: Total Loss: 4.154244422912598, Expl Loss: 3.9217826902637754e-11, Output Loss: 2.3246214198024973e-07\n",
      "Iteration 705: Total Loss: 4.127119541168213, Expl Loss: 3.92074324395697e-11, Output Loss: 2.063761996851099e-07\n",
      "Iteration 706: Total Loss: 4.099740505218506, Expl Loss: 3.915846466528983e-11, Output Loss: 1.8389421541087358e-07\n",
      "Iteration 707: Total Loss: 4.104616165161133, Expl Loss: 3.911789295263368e-11, Output Loss: 1.9282711605228542e-07\n",
      "Iteration 708: Total Loss: 4.116100311279297, Expl Loss: 3.9082365815845677e-11, Output Loss: 2.078637493241331e-07\n",
      "Iteration 709: Total Loss: 4.087644100189209, Expl Loss: 3.901085357527201e-11, Output Loss: 1.8655875066997396e-07\n",
      "Iteration 710: Total Loss: 4.076389789581299, Expl Loss: 3.8986907452409625e-11, Output Loss: 1.7769916382803785e-07\n",
      "Iteration 711: Total Loss: 4.0916876792907715, Expl Loss: 3.8991865292103967e-11, Output Loss: 1.9250114746682812e-07\n",
      "Iteration 712: Total Loss: 4.078805923461914, Expl Loss: 3.892163327745557e-11, Output Loss: 1.8664262313450308e-07\n",
      "Iteration 713: Total Loss: 4.0618367195129395, Expl Loss: 3.885752483667737e-11, Output Loss: 1.7608419966563815e-07\n",
      "Iteration 714: Total Loss: 4.063000202178955, Expl Loss: 3.881149221451885e-11, Output Loss: 1.81851120828469e-07\n",
      "Iteration 715: Total Loss: 4.059953689575195, Expl Loss: 3.876551163406461e-11, Output Loss: 1.8340236351832573e-07\n",
      "Iteration 716: Total Loss: 4.044659614562988, Expl Loss: 3.869143547219345e-11, Output Loss: 1.755158933747225e-07\n",
      "Iteration 717: Total Loss: 4.04149866104126, Expl Loss: 3.8642523209064805e-11, Output Loss: 1.772464770510851e-07\n",
      "Iteration 718: Total Loss: 4.039709091186523, Expl Loss: 3.8585287742698426e-11, Output Loss: 1.8118029743163788e-07\n",
      "Iteration 719: Total Loss: 4.034497261047363, Expl Loss: 3.858156849556593e-11, Output Loss: 1.7634069138239283e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 720: Total Loss: 4.024497985839844, Expl Loss: 3.849372556818942e-11, Output Loss: 1.7512546435227705e-07\n",
      "Iteration 721: Total Loss: 4.020092010498047, Expl Loss: 3.8413820735438975e-11, Output Loss: 1.7870988244794717e-07\n",
      "Iteration 722: Total Loss: 4.014837741851807, Expl Loss: 3.837768991488133e-11, Output Loss: 1.7706888399970921e-07\n",
      "Iteration 723: Total Loss: 4.007394313812256, Expl Loss: 3.8334297541853246e-11, Output Loss: 1.7396465068486577e-07\n",
      "Iteration 724: Total Loss: 4.001435279846191, Expl Loss: 3.825657152178863e-11, Output Loss: 1.7577796995738026e-07\n",
      "Iteration 725: Total Loss: 3.998352289199829, Expl Loss: 3.8214775094358444e-11, Output Loss: 1.7687486320028256e-07\n",
      "Iteration 726: Total Loss: 3.9912943840026855, Expl Loss: 3.816742755180513e-11, Output Loss: 1.745516442497319e-07\n",
      "Iteration 727: Total Loss: 3.985868215560913, Expl Loss: 3.812487131549247e-11, Output Loss: 1.7338112456855015e-07\n",
      "Iteration 728: Total Loss: 3.983882427215576, Expl Loss: 3.80904752184108e-11, Output Loss: 1.748348807950606e-07\n",
      "Iteration 729: Total Loss: 3.9771475791931152, Expl Loss: 3.802007667030871e-11, Output Loss: 1.751398031046847e-07\n",
      "Iteration 730: Total Loss: 3.9729385375976562, Expl Loss: 3.799719566766058e-11, Output Loss: 1.732190781922327e-07\n",
      "Iteration 731: Total Loss: 3.967867851257324, Expl Loss: 3.7953716558458694e-11, Output Loss: 1.7249642780825525e-07\n",
      "Iteration 732: Total Loss: 3.964064359664917, Expl Loss: 3.790716351925738e-11, Output Loss: 1.7334829749415803e-07\n",
      "Iteration 733: Total Loss: 3.963655471801758, Expl Loss: 3.7904134692068325e-11, Output Loss: 1.7324218504199962e-07\n",
      "Iteration 734: Total Loss: 3.956700563430786, Expl Loss: 3.7844054279201345e-11, Output Loss: 1.7229538684659929e-07\n",
      "Iteration 735: Total Loss: 3.948399543762207, Expl Loss: 3.7769325861303216e-11, Output Loss: 1.7146713560123317e-07\n",
      "Iteration 736: Total Loss: 3.946270227432251, Expl Loss: 3.774537626899388e-11, Output Loss: 1.7173270805415086e-07\n",
      "Iteration 737: Total Loss: 3.945010185241699, Expl Loss: 3.7726079205047114e-11, Output Loss: 1.7240246563687833e-07\n",
      "Iteration 738: Total Loss: 3.9382519721984863, Expl Loss: 3.7661668922384095e-11, Output Loss: 1.7208500935339544e-07\n",
      "Iteration 739: Total Loss: 3.9343068599700928, Expl Loss: 3.762689118613771e-11, Output Loss: 1.7161779908292374e-07\n",
      "Iteration 740: Total Loss: 3.929766893386841, Expl Loss: 3.758316921564919e-11, Output Loss: 1.714500683647202e-07\n",
      "Iteration 741: Total Loss: 3.924304962158203, Expl Loss: 3.7525635376844946e-11, Output Loss: 1.7174160404920258e-07\n",
      "Iteration 742: Total Loss: 3.919275999069214, Expl Loss: 3.746735213749908e-11, Output Loss: 1.7254093620522326e-07\n",
      "Iteration 743: Total Loss: 3.9147984981536865, Expl Loss: 3.7423588533647134e-11, Output Loss: 1.7243981176306988e-07\n",
      "Iteration 744: Total Loss: 3.910001754760742, Expl Loss: 3.737353829191825e-11, Output Loss: 1.7264805762806645e-07\n",
      "Iteration 745: Total Loss: 3.905048370361328, Expl Loss: 3.73286922206173e-11, Output Loss: 1.721790994224648e-07\n",
      "Iteration 746: Total Loss: 3.9068655967712402, Expl Loss: 3.7345841696900806e-11, Output Loss: 1.7228154547410668e-07\n",
      "Iteration 747: Total Loss: 3.902283191680908, Expl Loss: 3.730106501453889e-11, Output Loss: 1.7217671199887263e-07\n",
      "Iteration 748: Total Loss: 3.900608539581299, Expl Loss: 3.7289612370150493e-11, Output Loss: 1.7164728660645778e-07\n",
      "Iteration 749: Total Loss: 3.8940980434417725, Expl Loss: 3.723231098429203e-11, Output Loss: 1.7086689751977246e-07\n",
      "Iteration 750: Total Loss: 3.8880269527435303, Expl Loss: 3.7183700563048205e-11, Output Loss: 1.696570990361579e-07\n",
      "Iteration 751: Total Loss: 3.882427930831909, Expl Loss: 3.713585342013381e-11, Output Loss: 1.6884246178960893e-07\n",
      "Iteration 752: Total Loss: 3.87868070602417, Expl Loss: 3.710091955877459e-11, Output Loss: 1.685889969849086e-07\n",
      "Iteration 753: Total Loss: 3.87442684173584, Expl Loss: 3.705719064939217e-11, Output Loss: 1.687078281520371e-07\n",
      "Iteration 754: Total Loss: 3.8713927268981934, Expl Loss: 3.702425518947727e-11, Output Loss: 1.6896736099170084e-07\n",
      "Iteration 755: Total Loss: 3.8645033836364746, Expl Loss: 3.69579783443541e-11, Output Loss: 1.6870581021066755e-07\n",
      "Iteration 756: Total Loss: 3.8568577766418457, Expl Loss: 3.68850679166588e-11, Output Loss: 1.683512778072327e-07\n",
      "Iteration 757: Total Loss: 3.851928472518921, Expl Loss: 3.684140145732151e-11, Output Loss: 1.677885421713654e-07\n",
      "Iteration 758: Total Loss: 3.8460373878479004, Expl Loss: 3.6787229512613706e-11, Output Loss: 1.6731445384721155e-07\n",
      "Iteration 759: Total Loss: 3.8420000076293945, Expl Loss: 3.674879150983301e-11, Output Loss: 1.6712085937342636e-07\n",
      "Iteration 760: Total Loss: 3.8391504287719727, Expl Loss: 3.6722267587885327e-11, Output Loss: 1.669237548185265e-07\n",
      "Iteration 761: Total Loss: 3.8319506645202637, Expl Loss: 3.6649117768350337e-11, Output Loss: 1.6703890537428379e-07\n",
      "Iteration 762: Total Loss: 3.8266806602478027, Expl Loss: 3.659959488255815e-11, Output Loss: 1.6672132119310845e-07\n",
      "Iteration 763: Total Loss: 3.822598457336426, Expl Loss: 3.6560299926380324e-11, Output Loss: 1.6656858292662946e-07\n",
      "Iteration 764: Total Loss: 3.818389654159546, Expl Loss: 3.65242038002922e-11, Output Loss: 1.659693253941441e-07\n",
      "Iteration 765: Total Loss: 3.813477039337158, Expl Loss: 3.6478039339149504e-11, Output Loss: 1.6567315697102458e-07\n",
      "Iteration 766: Total Loss: 3.8111743927001953, Expl Loss: 3.6458596558430756e-11, Output Loss: 1.6531478763681662e-07\n",
      "Iteration 767: Total Loss: 3.8084819316864014, Expl Loss: 3.64322148838081e-11, Output Loss: 1.652606442803517e-07\n",
      "Iteration 768: Total Loss: 3.8007869720458984, Expl Loss: 3.635542214497356e-11, Output Loss: 1.6524491286418197e-07\n",
      "Iteration 769: Total Loss: 3.7988083362579346, Expl Loss: 3.6336073039322514e-11, Output Loss: 1.65201200275078e-07\n",
      "Iteration 770: Total Loss: 3.796886682510376, Expl Loss: 3.6318351104291935e-11, Output Loss: 1.650516168183458e-07\n",
      "Iteration 771: Total Loss: 3.786564826965332, Expl Loss: 3.621720284785468e-11, Output Loss: 1.6484463571941887e-07\n",
      "Iteration 772: Total Loss: 3.782374620437622, Expl Loss: 3.6178407492037934e-11, Output Loss: 1.6453388695936155e-07\n",
      "Iteration 773: Total Loss: 3.7792913913726807, Expl Loss: 3.614899352077927e-11, Output Loss: 1.6439210526186798e-07\n",
      "Iteration 774: Total Loss: 3.771608829498291, Expl Loss: 3.607548981765518e-11, Output Loss: 1.640599975871737e-07\n",
      "Iteration 775: Total Loss: 3.773016929626465, Expl Loss: 3.608853493819453e-11, Output Loss: 1.6416370840488526e-07\n",
      "Iteration 776: Total Loss: 3.7680602073669434, Expl Loss: 3.6040760653666126e-11, Output Loss: 1.6398433899666998e-07\n",
      "Iteration 777: Total Loss: 3.7618508338928223, Expl Loss: 3.597612832639818e-11, Output Loss: 1.642378748556439e-07\n",
      "Iteration 778: Total Loss: 3.7547247409820557, Expl Loss: 3.5906798367957293e-11, Output Loss: 1.6404510461143218e-07\n",
      "Iteration 779: Total Loss: 3.752845287322998, Expl Loss: 3.588674149512805e-11, Output Loss: 1.6417133963386732e-07\n",
      "Iteration 780: Total Loss: 3.747253179550171, Expl Loss: 3.583452631850115e-11, Output Loss: 1.6380074896460428e-07\n",
      "Iteration 781: Total Loss: 3.7425286769866943, Expl Loss: 3.5788382674040164e-11, Output Loss: 1.636906432622709e-07\n",
      "Iteration 782: Total Loss: 3.7364284992218018, Expl Loss: 3.5733367653723036e-11, Output Loss: 1.6309182626628171e-07\n",
      "Iteration 783: Total Loss: 3.7341806888580322, Expl Loss: 3.571412263148055e-11, Output Loss: 1.6276868564091274e-07\n",
      "Iteration 784: Total Loss: 3.7273459434509277, Expl Loss: 3.5650964819167186e-11, Output Loss: 1.6224947785303812e-07\n",
      "Iteration 785: Total Loss: 3.72550630569458, Expl Loss: 3.563446066001674e-11, Output Loss: 1.620601608465222e-07\n",
      "Iteration 786: Total Loss: 3.7206192016601562, Expl Loss: 3.558762312616537e-11, Output Loss: 1.6185691720238538e-07\n",
      "Iteration 787: Total Loss: 3.7149102687835693, Expl Loss: 3.5530169084641017e-11, Output Loss: 1.6189333962302044e-07\n",
      "Iteration 788: Total Loss: 3.711660146713257, Expl Loss: 3.5496564021464394e-11, Output Loss: 1.6200384322928585e-07\n",
      "Iteration 789: Total Loss: 3.708287477493286, Expl Loss: 3.54608842290105e-11, Output Loss: 1.6219912879478215e-07\n",
      "Iteration 790: Total Loss: 3.7039968967437744, Expl Loss: 3.5414889770768454e-11, Output Loss: 1.6250810119800008e-07\n",
      "Iteration 791: Total Loss: 3.7005746364593506, Expl Loss: 3.537648299301033e-11, Output Loss: 1.6292642612825148e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 792: Total Loss: 3.695819616317749, Expl Loss: 3.532267534023248e-11, Output Loss: 1.6355214427221654e-07\n",
      "Iteration 793: Total Loss: 3.6939873695373535, Expl Loss: 3.5298708400688383e-11, Output Loss: 1.6411649994552135e-07\n",
      "Iteration 794: Total Loss: 3.6920018196105957, Expl Loss: 3.5272729181912155e-11, Output Loss: 1.647288456751994e-07\n",
      "Iteration 795: Total Loss: 3.689100503921509, Expl Loss: 3.524278091582289e-11, Output Loss: 1.6482252362948202e-07\n",
      "Iteration 796: Total Loss: 3.6819281578063965, Expl Loss: 3.517725000179439e-11, Output Loss: 1.642031861592841e-07\n",
      "Iteration 797: Total Loss: 3.6737191677093506, Expl Loss: 3.510998089484296e-11, Output Loss: 1.6272112191018095e-07\n",
      "Iteration 798: Total Loss: 3.671142101287842, Expl Loss: 3.5102736689607283e-11, Output Loss: 1.6086836751583178e-07\n",
      "Iteration 799: Total Loss: 3.667100667953491, Expl Loss: 3.5075834597941835e-11, Output Loss: 1.595173273472028e-07\n",
      "Iteration 800: Total Loss: 3.6628451347351074, Expl Loss: 3.503369816471036e-11, Output Loss: 1.5947540532579296e-07\n",
      "Iteration 801: Total Loss: 3.659834146499634, Expl Loss: 3.499660283790007e-11, Output Loss: 1.6017381199162628e-07\n",
      "Iteration 802: Total Loss: 3.649623155593872, Expl Loss: 3.488313804478338e-11, Output Loss: 1.613095150787558e-07\n",
      "Iteration 803: Total Loss: 3.6447665691375732, Expl Loss: 3.482748117678014e-11, Output Loss: 1.6201860830733494e-07\n",
      "Iteration 804: Total Loss: 3.6430013179779053, Expl Loss: 3.4796287379235125e-11, Output Loss: 1.6337264696630882e-07\n",
      "Iteration 805: Total Loss: 3.6417417526245117, Expl Loss: 3.477515844729773e-11, Output Loss: 1.6422602300281142e-07\n",
      "Iteration 806: Total Loss: 3.6418981552124023, Expl Loss: 3.4743527499436766e-11, Output Loss: 1.675455791882996e-07\n",
      "Iteration 807: Total Loss: 3.6416215896606445, Expl Loss: 3.470021492368858e-11, Output Loss: 1.716001776230769e-07\n",
      "Iteration 808: Total Loss: 3.6456573009490967, Expl Loss: 3.465537579128153e-11, Output Loss: 1.8011971292253293e-07\n",
      "Iteration 809: Total Loss: 3.6504409313201904, Expl Loss: 3.460804906540993e-11, Output Loss: 1.8963594072829437e-07\n",
      "Iteration 810: Total Loss: 3.6518263816833496, Expl Loss: 3.459268982375363e-11, Output Loss: 1.9255753613833804e-07\n",
      "Iteration 811: Total Loss: 3.64536452293396, Expl Loss: 3.455812372377132e-11, Output Loss: 1.8955226721573126e-07\n",
      "Iteration 812: Total Loss: 3.6269984245300293, Expl Loss: 3.4536651316585676e-11, Output Loss: 1.7333344715098065e-07\n",
      "Iteration 813: Total Loss: 3.620366334915161, Expl Loss: 3.45196440876272e-11, Output Loss: 1.684018542391641e-07\n",
      "Iteration 814: Total Loss: 3.621145725250244, Expl Loss: 3.446837260057123e-11, Output Loss: 1.7430845389299066e-07\n",
      "Iteration 815: Total Loss: 3.6246747970581055, Expl Loss: 3.445936591628396e-11, Output Loss: 1.78738233103104e-07\n",
      "Iteration 816: Total Loss: 3.6054909229278564, Expl Loss: 3.441076937282794e-11, Output Loss: 1.6441407524325768e-07\n",
      "Iteration 817: Total Loss: 3.5908288955688477, Expl Loss: 3.4341918198066423e-11, Output Loss: 1.5663731289805582e-07\n",
      "Iteration 818: Total Loss: 3.597376823425293, Expl Loss: 3.431906148154695e-11, Output Loss: 1.6547082282158954e-07\n",
      "Iteration 819: Total Loss: 3.5966734886169434, Expl Loss: 3.4297221312984405e-11, Output Loss: 1.669513380875287e-07\n",
      "Iteration 820: Total Loss: 3.584033250808716, Expl Loss: 3.424708086563477e-11, Output Loss: 1.5932516816974385e-07\n",
      "Iteration 821: Total Loss: 3.5766513347625732, Expl Loss: 3.420070476822801e-11, Output Loss: 1.5658095264825533e-07\n",
      "Iteration 822: Total Loss: 3.5771758556365967, Expl Loss: 3.4156372175075944e-11, Output Loss: 1.6153870774360257e-07\n",
      "Iteration 823: Total Loss: 3.5709266662597656, Expl Loss: 3.410196430797541e-11, Output Loss: 1.607303232731283e-07\n",
      "Iteration 824: Total Loss: 3.560256242752075, Expl Loss: 3.4043712293652106e-11, Output Loss: 1.558850470928519e-07\n",
      "Iteration 825: Total Loss: 3.563167095184326, Expl Loss: 3.405181345228492e-11, Output Loss: 1.5798586616710963e-07\n",
      "Iteration 826: Total Loss: 3.5601625442504883, Expl Loss: 3.400374773421255e-11, Output Loss: 1.597879446535444e-07\n",
      "Iteration 827: Total Loss: 3.55391001701355, Expl Loss: 3.397807729621505e-11, Output Loss: 1.5610251580255863e-07\n",
      "Iteration 828: Total Loss: 3.5457332134246826, Expl Loss: 3.3904816454377595e-11, Output Loss: 1.5525179719588778e-07\n",
      "Iteration 829: Total Loss: 3.543487310409546, Expl Loss: 3.3856015213551416e-11, Output Loss: 1.5788577911735047e-07\n",
      "Iteration 830: Total Loss: 3.5397770404815674, Expl Loss: 3.382547367203337e-11, Output Loss: 1.5722974922027788e-07\n",
      "Iteration 831: Total Loss: 3.5338294506073, Expl Loss: 3.378894386507625e-11, Output Loss: 1.5493503724428592e-07\n",
      "Iteration 832: Total Loss: 3.5308027267456055, Expl Loss: 3.3753010802994865e-11, Output Loss: 1.5550172349776403e-07\n",
      "Iteration 833: Total Loss: 3.527434825897217, Expl Loss: 3.370821677339819e-11, Output Loss: 1.5661302654734754e-07\n",
      "Iteration 834: Total Loss: 3.5210444927215576, Expl Loss: 3.365189724102713e-11, Output Loss: 1.5585500534598395e-07\n",
      "Iteration 835: Total Loss: 3.519655704498291, Expl Loss: 3.365422177048494e-11, Output Loss: 1.542337315640907e-07\n",
      "Iteration 836: Total Loss: 3.511835813522339, Expl Loss: 3.357148933846865e-11, Output Loss: 1.546869157209585e-07\n",
      "Iteration 837: Total Loss: 3.512018918991089, Expl Loss: 3.35615354951635e-11, Output Loss: 1.558654219024902e-07\n",
      "Iteration 838: Total Loss: 3.5076968669891357, Expl Loss: 3.3527059600801934e-11, Output Loss: 1.549908290598978e-07\n",
      "Iteration 839: Total Loss: 3.5026907920837402, Expl Loss: 3.348679666892451e-11, Output Loss: 1.5401121800096007e-07\n",
      "Iteration 840: Total Loss: 3.4976654052734375, Expl Loss: 3.3436812346687717e-11, Output Loss: 1.5398426000956533e-07\n",
      "Iteration 841: Total Loss: 3.4944541454315186, Expl Loss: 3.3399921717247594e-11, Output Loss: 1.54462000523381e-07\n",
      "Iteration 842: Total Loss: 3.492671489715576, Expl Loss: 3.338071485892158e-11, Output Loss: 1.5460024371805048e-07\n",
      "Iteration 843: Total Loss: 3.489090919494629, Expl Loss: 3.335368786716586e-11, Output Loss: 1.5372241080058302e-07\n",
      "Iteration 844: Total Loss: 3.4861884117126465, Expl Loss: 3.332992215554498e-11, Output Loss: 1.5319639601329982e-07\n",
      "Iteration 845: Total Loss: 3.488313913345337, Expl Loss: 3.334942738630886e-11, Output Loss: 1.5337140268911753e-07\n",
      "Iteration 846: Total Loss: 3.4841766357421875, Expl Loss: 3.330533418499648e-11, Output Loss: 1.536434837134948e-07\n",
      "Iteration 847: Total Loss: 3.4833638668060303, Expl Loss: 3.329561279463711e-11, Output Loss: 1.5380254581032204e-07\n",
      "Iteration 848: Total Loss: 3.4799013137817383, Expl Loss: 3.326627862065834e-11, Output Loss: 1.532736888520958e-07\n",
      "Iteration 849: Total Loss: 3.475745439529419, Expl Loss: 3.322648406411943e-11, Output Loss: 1.5309711898225942e-07\n",
      "Iteration 850: Total Loss: 3.4694504737854004, Expl Loss: 3.3162521340113216e-11, Output Loss: 1.5319854185236181e-07\n",
      "Iteration 851: Total Loss: 3.4681973457336426, Expl Loss: 3.314090321615559e-11, Output Loss: 1.5410708442686882e-07\n",
      "Iteration 852: Total Loss: 3.467914342880249, Expl Loss: 3.3118317116498375e-11, Output Loss: 1.5608272008194035e-07\n",
      "Iteration 853: Total Loss: 3.4681477546691895, Expl Loss: 3.308804619184258e-11, Output Loss: 1.5934318753352272e-07\n",
      "Iteration 854: Total Loss: 3.468554735183716, Expl Loss: 3.3037905744492946e-11, Output Loss: 1.647641738600214e-07\n",
      "Iteration 855: Total Loss: 3.474419593811035, Expl Loss: 3.300708317777179e-11, Output Loss: 1.73711256934439e-07\n",
      "Iteration 856: Total Loss: 3.476055145263672, Expl Loss: 3.294999342817739e-11, Output Loss: 1.8105575350091385e-07\n",
      "Iteration 857: Total Loss: 3.481135845184326, Expl Loss: 3.293997366538015e-11, Output Loss: 1.8713868144004664e-07\n",
      "Iteration 858: Total Loss: 3.466404676437378, Expl Loss: 3.291571182284514e-11, Output Loss: 1.7483344549873436e-07\n",
      "Iteration 859: Total Loss: 3.4462039470672607, Expl Loss: 3.285964209065462e-11, Output Loss: 1.6023966509237653e-07\n",
      "Iteration 860: Total Loss: 3.434174060821533, Expl Loss: 3.281211066741285e-11, Output Loss: 1.5296326694169693e-07\n",
      "Iteration 861: Total Loss: 3.440159559249878, Expl Loss: 3.278877169776706e-11, Output Loss: 1.6128262814163463e-07\n",
      "Iteration 862: Total Loss: 3.44130277633667, Expl Loss: 3.2745955252933e-11, Output Loss: 1.6670732350121398e-07\n",
      "Iteration 863: Total Loss: 3.429300546646118, Expl Loss: 3.271917112246392e-11, Output Loss: 1.5738341119231336e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 864: Total Loss: 3.4204037189483643, Expl Loss: 3.2696876456350665e-11, Output Loss: 1.5071614711814618e-07\n",
      "Iteration 865: Total Loss: 3.4206137657165527, Expl Loss: 3.265331754986889e-11, Output Loss: 1.5528195262959343e-07\n",
      "Iteration 866: Total Loss: 3.41927170753479, Expl Loss: 3.261289849287863e-11, Output Loss: 1.579819155494988e-07\n",
      "Iteration 867: Total Loss: 3.4137051105499268, Expl Loss: 3.2603461597169314e-11, Output Loss: 1.5335891134782287e-07\n",
      "Iteration 868: Total Loss: 3.407418727874756, Expl Loss: 3.257221228847307e-11, Output Loss: 1.5019759302958846e-07\n",
      "Iteration 869: Total Loss: 3.405961036682129, Expl Loss: 3.252767152850389e-11, Output Loss: 1.5319402280056238e-07\n",
      "Iteration 870: Total Loss: 3.4039146900177, Expl Loss: 3.2493976259706514e-11, Output Loss: 1.5451728074822313e-07\n",
      "Iteration 871: Total Loss: 3.3976972103118896, Expl Loss: 3.247178220755487e-11, Output Loss: 1.5051922730435763e-07\n",
      "Iteration 872: Total Loss: 3.395460367202759, Expl Loss: 3.245869892309905e-11, Output Loss: 1.4959042005102674e-07\n",
      "Iteration 873: Total Loss: 3.3959696292877197, Expl Loss: 3.243552648690695e-11, Output Loss: 1.5241698747558985e-07\n",
      "Iteration 874: Total Loss: 3.391641139984131, Expl Loss: 3.2396606230999936e-11, Output Loss: 1.5198052949472185e-07\n",
      "Iteration 875: Total Loss: 3.384608745574951, Expl Loss: 3.2348120709846384e-11, Output Loss: 1.497966906072179e-07\n",
      "Iteration 876: Total Loss: 3.3821115493774414, Expl Loss: 3.2330627758314634e-11, Output Loss: 1.4904880174526625e-07\n",
      "Iteration 877: Total Loss: 3.379985809326172, Expl Loss: 3.229651962532998e-11, Output Loss: 1.5033386091545253e-07\n",
      "Iteration 878: Total Loss: 3.378211498260498, Expl Loss: 3.227182063247902e-11, Output Loss: 1.5102955330803525e-07\n",
      "Iteration 879: Total Loss: 3.372346878051758, Expl Loss: 3.222855662898816e-11, Output Loss: 1.4949137039366178e-07\n",
      "Iteration 880: Total Loss: 3.369729518890381, Expl Loss: 3.221254513130489e-11, Output Loss: 1.484752658598154e-07\n",
      "Iteration 881: Total Loss: 3.3659772872924805, Expl Loss: 3.2171914438050564e-11, Output Loss: 1.487857872461973e-07\n",
      "Iteration 882: Total Loss: 3.363225221633911, Expl Loss: 3.2136009131544796e-11, Output Loss: 1.496243271503772e-07\n",
      "Iteration 883: Total Loss: 3.3595645427703857, Expl Loss: 3.209971871642736e-11, Output Loss: 1.4959265115521703e-07\n",
      "Iteration 884: Total Loss: 3.3543860912323, Expl Loss: 3.2057367177484863e-11, Output Loss: 1.4864939146264078e-07\n",
      "Iteration 885: Total Loss: 3.348666191101074, Expl Loss: 3.200694223548517e-11, Output Loss: 1.4797208791605954e-07\n",
      "Iteration 886: Total Loss: 3.3470051288604736, Expl Loss: 3.198900866419052e-11, Output Loss: 1.4810447623858636e-07\n",
      "Iteration 887: Total Loss: 3.3446896076202393, Expl Loss: 3.196315087605761e-11, Output Loss: 1.483745819541582e-07\n",
      "Iteration 888: Total Loss: 3.3433761596679688, Expl Loss: 3.194860348498807e-11, Output Loss: 1.4851599416942918e-07\n",
      "Iteration 889: Total Loss: 3.33726167678833, Expl Loss: 3.189204456077732e-11, Output Loss: 1.480571114598206e-07\n",
      "Iteration 890: Total Loss: 3.333120346069336, Expl Loss: 3.1855521692714106e-11, Output Loss: 1.4756828647932707e-07\n",
      "Iteration 891: Total Loss: 3.3316664695739746, Expl Loss: 3.1844062109431803e-11, Output Loss: 1.472603088359392e-07\n",
      "Iteration 892: Total Loss: 3.329941987991333, Expl Loss: 3.1825524854367515e-11, Output Loss: 1.4738959919213812e-07\n",
      "Iteration 893: Total Loss: 3.32629656791687, Expl Loss: 3.178739216291859e-11, Output Loss: 1.475575572840171e-07\n",
      "Iteration 894: Total Loss: 3.322267532348633, Expl Loss: 3.1746816980815495e-11, Output Loss: 1.4758585109575506e-07\n",
      "Iteration 895: Total Loss: 3.318835496902466, Expl Loss: 3.1716181764229745e-11, Output Loss: 1.4721736363298987e-07\n",
      "Iteration 896: Total Loss: 3.314075469970703, Expl Loss: 3.167088466482504e-11, Output Loss: 1.46986877780364e-07\n",
      "Iteration 897: Total Loss: 3.3115227222442627, Expl Loss: 3.1647170994908436e-11, Output Loss: 1.4680566096103576e-07\n",
      "Iteration 898: Total Loss: 3.3095109462738037, Expl Loss: 3.162541062362578e-11, Output Loss: 1.4697009476094536e-07\n",
      "Iteration 899: Total Loss: 3.306560754776001, Expl Loss: 3.159518133233341e-11, Output Loss: 1.4704265538512118e-07\n",
      "Iteration 900: Total Loss: 3.303298234939575, Expl Loss: 3.1556399854304473e-11, Output Loss: 1.476583264548026e-07\n",
      "Iteration 901: Total Loss: 3.3011128902435303, Expl Loss: 3.152963307107015e-11, Output Loss: 1.481497662325637e-07\n",
      "Iteration 902: Total Loss: 3.29742693901062, Expl Loss: 3.1477265238777363e-11, Output Loss: 1.4970044048823183e-07\n",
      "Iteration 903: Total Loss: 3.297525644302368, Expl Loss: 3.1459654326049247e-11, Output Loss: 1.515603003099386e-07\n",
      "Iteration 904: Total Loss: 3.3004648685455322, Expl Loss: 3.144406610089412e-11, Output Loss: 1.5605832004439435e-07\n",
      "Iteration 905: Total Loss: 3.3034722805023193, Expl Loss: 3.140446236393757e-11, Output Loss: 1.630261010632239e-07\n",
      "Iteration 906: Total Loss: 3.3099849224090576, Expl Loss: 3.139275644992168e-11, Output Loss: 1.7070927071927144e-07\n",
      "Iteration 907: Total Loss: 3.3195972442626953, Expl Loss: 3.136586129715013e-11, Output Loss: 1.8301118132058036e-07\n",
      "Iteration 908: Total Loss: 3.3140106201171875, Expl Loss: 3.134262988035985e-11, Output Loss: 1.7974770116779837e-07\n",
      "Iteration 909: Total Loss: 3.3038344383239746, Expl Loss: 3.134717138641996e-11, Output Loss: 1.6911732814151037e-07\n",
      "Iteration 910: Total Loss: 3.2802236080169678, Expl Loss: 3.1307085396337087e-11, Output Loss: 1.4951514515360032e-07\n",
      "Iteration 911: Total Loss: 3.275238275527954, Expl Loss: 3.1283833162865093e-11, Output Loss: 1.4685501525946165e-07\n",
      "Iteration 912: Total Loss: 3.2821085453033447, Expl Loss: 3.124883685146074e-11, Output Loss: 1.5722496016223886e-07\n",
      "Iteration 913: Total Loss: 3.2805614471435547, Expl Loss: 3.124037487034492e-11, Output Loss: 1.5652385343400965e-07\n",
      "Iteration 914: Total Loss: 3.266491174697876, Expl Loss: 3.11957577825428e-11, Output Loss: 1.4691551086798427e-07\n",
      "Iteration 915: Total Loss: 3.260957717895508, Expl Loss: 3.115179295076764e-11, Output Loss: 1.4577842932794738e-07\n",
      "Iteration 916: Total Loss: 3.262477397918701, Expl Loss: 3.1105923392615864e-11, Output Loss: 1.5188507518359984e-07\n",
      "Iteration 917: Total Loss: 3.260920524597168, Expl Loss: 3.1102710684738355e-11, Output Loss: 1.5064962610722432e-07\n",
      "Iteration 918: Total Loss: 3.251984119415283, Expl Loss: 3.107148219272382e-11, Output Loss: 1.448358943889616e-07\n",
      "Iteration 919: Total Loss: 3.2522852420806885, Expl Loss: 3.106592066925984e-11, Output Loss: 1.4569333472991275e-07\n",
      "Iteration 920: Total Loss: 3.2529137134552, Expl Loss: 3.103809570470517e-11, Output Loss: 1.4910416723523667e-07\n",
      "Iteration 921: Total Loss: 3.248716354370117, Expl Loss: 3.10125744529266e-11, Output Loss: 1.4745897658485774e-07\n",
      "Iteration 922: Total Loss: 3.2431719303131104, Expl Loss: 3.0983372117932007e-11, Output Loss: 1.4483471488802024e-07\n",
      "Iteration 923: Total Loss: 3.240877866744995, Expl Loss: 3.093462638825706e-11, Output Loss: 1.474152924174632e-07\n",
      "Iteration 924: Total Loss: 3.2385809421539307, Expl Loss: 3.088692496211465e-11, Output Loss: 1.4988845009611396e-07\n",
      "Iteration 925: Total Loss: 3.238023281097412, Expl Loss: 3.088384062377436e-11, Output Loss: 1.496392769695376e-07\n",
      "Iteration 926: Total Loss: 3.2345216274261475, Expl Loss: 3.0845485887720514e-11, Output Loss: 1.4997323205534485e-07\n",
      "Iteration 927: Total Loss: 3.234616279602051, Expl Loss: 3.0795813815709394e-11, Output Loss: 1.5503505323977151e-07\n",
      "Iteration 928: Total Loss: 3.2381815910339355, Expl Loss: 3.081578395236484e-11, Output Loss: 1.566032636901582e-07\n",
      "Iteration 929: Total Loss: 3.2326548099517822, Expl Loss: 3.075482229997206e-11, Output Loss: 1.5717263579517748e-07\n",
      "Iteration 930: Total Loss: 3.2265429496765137, Expl Loss: 3.073707607881282e-11, Output Loss: 1.528353550384054e-07\n",
      "Iteration 931: Total Loss: 3.2205371856689453, Expl Loss: 3.0699668501776856e-11, Output Loss: 1.5057050006817008e-07\n",
      "Iteration 932: Total Loss: 3.2130532264709473, Expl Loss: 3.066239623317202e-11, Output Loss: 1.468135479854027e-07\n",
      "Iteration 933: Total Loss: 3.2057056427001953, Expl Loss: 3.062354189675709e-11, Output Loss: 1.4335167008994176e-07\n",
      "Iteration 934: Total Loss: 3.199982166290283, Expl Loss: 3.057348124668735e-11, Output Loss: 1.426341498245165e-07\n",
      "Iteration 935: Total Loss: 3.2000515460968018, Expl Loss: 3.0553583968417897e-11, Output Loss: 1.4469308950992854e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 936: Total Loss: 3.1990387439727783, Expl Loss: 3.0523299165974294e-11, Output Loss: 1.4670899872726295e-07\n",
      "Iteration 937: Total Loss: 3.1957809925079346, Expl Loss: 3.050397434645191e-11, Output Loss: 1.4538366599481378e-07\n",
      "Iteration 938: Total Loss: 3.192638635635376, Expl Loss: 3.0499183040211264e-11, Output Loss: 1.4272046655605664e-07\n",
      "Iteration 939: Total Loss: 3.188359260559082, Expl Loss: 3.046966498554404e-11, Output Loss: 1.413927464000153e-07\n",
      "Iteration 940: Total Loss: 3.1869232654571533, Expl Loss: 3.04455280430993e-11, Output Loss: 1.4237041057185706e-07\n",
      "Iteration 941: Total Loss: 3.185356378555298, Expl Loss: 3.0422941943442083e-11, Output Loss: 1.430622802445214e-07\n",
      "Iteration 942: Total Loss: 3.1849591732025146, Expl Loss: 3.042389604135387e-11, Output Loss: 1.4256961833325477e-07\n",
      "Iteration 943: Total Loss: 3.1801517009735107, Expl Loss: 3.038169715807726e-11, Output Loss: 1.4198214159932832e-07\n",
      "Iteration 944: Total Loss: 3.1768269538879395, Expl Loss: 3.034866802309466e-11, Output Loss: 1.4196002950939146e-07\n",
      "Iteration 945: Total Loss: 3.171381950378418, Expl Loss: 3.028984701947124e-11, Output Loss: 1.4239748225008952e-07\n",
      "Iteration 946: Total Loss: 3.171011209487915, Expl Loss: 3.0291491537326465e-11, Output Loss: 1.4186223040724144e-07\n",
      "Iteration 947: Total Loss: 3.16833233833313, Expl Loss: 3.0273287349169564e-11, Output Loss: 1.4100362477620365e-07\n",
      "Iteration 948: Total Loss: 3.1651008129119873, Expl Loss: 3.024618056013395e-11, Output Loss: 1.4048282537260093e-07\n",
      "Iteration 949: Total Loss: 3.16200852394104, Expl Loss: 3.021282529713787e-11, Output Loss: 1.4072610099447047e-07\n",
      "Iteration 950: Total Loss: 3.1599817276000977, Expl Loss: 3.018942387744694e-11, Output Loss: 1.4103945034094068e-07\n",
      "Iteration 951: Total Loss: 3.1547985076904297, Expl Loss: 3.0141181217580026e-11, Output Loss: 1.4068046993997996e-07\n",
      "Iteration 952: Total Loss: 3.1506147384643555, Expl Loss: 3.010400262404289e-11, Output Loss: 1.4021453864643263e-07\n",
      "Iteration 953: Total Loss: 3.146763324737549, Expl Loss: 3.0069117334941e-11, Output Loss: 1.3985157920615165e-07\n",
      "Iteration 954: Total Loss: 3.1451427936553955, Expl Loss: 3.0051811733544653e-11, Output Loss: 1.399618270170322e-07\n",
      "Iteration 955: Total Loss: 3.1415555477142334, Expl Loss: 3.001311352224256e-11, Output Loss: 1.4024416827851383e-07\n",
      "Iteration 956: Total Loss: 3.1385247707366943, Expl Loss: 2.9981100935216887e-11, Output Loss: 1.4041468432424153e-07\n",
      "Iteration 957: Total Loss: 3.1354382038116455, Expl Loss: 2.9945813190268566e-11, Output Loss: 1.4085692612297862e-07\n",
      "Iteration 958: Total Loss: 3.1361634731292725, Expl Loss: 2.9935422196647465e-11, Output Loss: 1.4262133163356339e-07\n",
      "Iteration 959: Total Loss: 3.1365835666656494, Expl Loss: 2.989927055940811e-11, Output Loss: 1.4665658909507329e-07\n",
      "Iteration 960: Total Loss: 3.1473398208618164, Expl Loss: 2.988154515493058e-11, Output Loss: 1.5918533335934626e-07\n",
      "Iteration 961: Total Loss: 3.1672720909118652, Expl Loss: 2.9839363618888726e-11, Output Loss: 1.8333582829654915e-07\n",
      "Iteration 962: Total Loss: 3.241079330444336, Expl Loss: 2.983715705062728e-11, Output Loss: 2.573639221736812e-07\n",
      "Iteration 963: Total Loss: 3.2514166831970215, Expl Loss: 2.980545671382728e-11, Output Loss: 2.708710553633864e-07\n",
      "Iteration 964: Total Loss: 3.2692208290100098, Expl Loss: 2.9804200774030676e-11, Output Loss: 2.888007486490096e-07\n",
      "Iteration 965: Total Loss: 3.133219003677368, Expl Loss: 2.9812246421512256e-11, Output Loss: 1.5199455560832575e-07\n",
      "Iteration 966: Total Loss: 3.173651695251465, Expl Loss: 2.9787432936911884e-11, Output Loss: 1.9490838099045504e-07\n",
      "Iteration 967: Total Loss: 3.241299629211426, Expl Loss: 2.973267118622225e-11, Output Loss: 2.680325223991531e-07\n",
      "Iteration 968: Total Loss: 3.120774269104004, Expl Loss: 2.973173790499217e-11, Output Loss: 1.4760072986064188e-07\n",
      "Iteration 969: Total Loss: 3.178478956222534, Expl Loss: 2.9733111805985146e-11, Output Loss: 2.051676801784197e-07\n",
      "Iteration 970: Total Loss: 3.2044382095336914, Expl Loss: 2.9657901134960696e-11, Output Loss: 2.386482549354696e-07\n",
      "Iteration 971: Total Loss: 3.1117429733276367, Expl Loss: 2.9668056206189064e-11, Output Loss: 1.449375872653036e-07\n",
      "Iteration 972: Total Loss: 3.2064969539642334, Expl Loss: 2.9678183521841817e-11, Output Loss: 2.3867860932114127e-07\n",
      "Iteration 973: Total Loss: 3.153646945953369, Expl Loss: 2.9602435086539813e-11, Output Loss: 1.9340343726526044e-07\n",
      "Iteration 974: Total Loss: 3.1313884258270264, Expl Loss: 2.957348602117271e-11, Output Loss: 1.740398403171639e-07\n",
      "Iteration 975: Total Loss: 3.1782476902008057, Expl Loss: 2.957037045780986e-11, Output Loss: 2.2121071197034325e-07\n",
      "Iteration 976: Total Loss: 3.0969080924987793, Expl Loss: 2.954094607821034e-11, Output Loss: 1.4281347660016763e-07\n",
      "Iteration 977: Total Loss: 3.1397480964660645, Expl Loss: 2.9515646871036694e-11, Output Loss: 1.8818354874383658e-07\n",
      "Iteration 978: Total Loss: 3.1060125827789307, Expl Loss: 2.9535540679859196e-11, Output Loss: 1.5245869633417897e-07\n",
      "Iteration 979: Total Loss: 3.1231637001037598, Expl Loss: 2.953023936491661e-11, Output Loss: 1.7013988440339745e-07\n",
      "Iteration 980: Total Loss: 3.114960193634033, Expl Loss: 2.9447416727279574e-11, Output Loss: 1.7021839937569894e-07\n",
      "Iteration 981: Total Loss: 3.095493793487549, Expl Loss: 2.9440099663657904e-11, Output Loss: 1.5148384591157082e-07\n",
      "Iteration 982: Total Loss: 3.116678476333618, Expl Loss: 2.946426436167826e-11, Output Loss: 1.702521075230834e-07\n",
      "Iteration 983: Total Loss: 3.0827558040618896, Expl Loss: 2.9410286705999766e-11, Output Loss: 1.4172715623317345e-07\n",
      "Iteration 984: Total Loss: 3.1075665950775146, Expl Loss: 2.941975482673165e-11, Output Loss: 1.6559116033931787e-07\n",
      "Iteration 985: Total Loss: 3.0843968391418457, Expl Loss: 2.941528270961058e-11, Output Loss: 1.4286845839706075e-07\n",
      "Iteration 986: Total Loss: 3.096374034881592, Expl Loss: 2.939807425272889e-11, Output Loss: 1.5656650020900997e-07\n",
      "Iteration 987: Total Loss: 3.0814061164855957, Expl Loss: 2.9359830538977505e-11, Output Loss: 1.454232290143409e-07\n",
      "Iteration 988: Total Loss: 3.082411527633667, Expl Loss: 2.933827833451197e-11, Output Loss: 1.4858375152471126e-07\n",
      "Iteration 989: Total Loss: 3.079169988632202, Expl Loss: 2.930869436035266e-11, Output Loss: 1.4830065708792972e-07\n",
      "Iteration 990: Total Loss: 3.066636800765991, Expl Loss: 2.9257769817991885e-11, Output Loss: 1.4085985355904995e-07\n",
      "Iteration 991: Total Loss: 3.068619966506958, Expl Loss: 2.9212146590573695e-11, Output Loss: 1.4740540166258143e-07\n",
      "Iteration 992: Total Loss: 3.0603716373443604, Expl Loss: 2.922018182971442e-11, Output Loss: 1.383535987997675e-07\n",
      "Iteration 993: Total Loss: 3.0641424655914307, Expl Loss: 2.918160504905565e-11, Output Loss: 1.4598201403259736e-07\n",
      "Iteration 994: Total Loss: 3.0532143115997314, Expl Loss: 2.915386682067478e-11, Output Loss: 1.3782752716906543e-07\n",
      "Iteration 995: Total Loss: 3.0543572902679443, Expl Loss: 2.9121396266651445e-11, Output Loss: 1.4221774335965165e-07\n",
      "Iteration 996: Total Loss: 3.0491578578948975, Expl Loss: 2.910149898838199e-11, Output Loss: 1.3900798023769312e-07\n",
      "Iteration 997: Total Loss: 3.046870708465576, Expl Loss: 2.9079015237409855e-11, Output Loss: 1.389690709174829e-07\n",
      "Iteration 998: Total Loss: 3.0430750846862793, Expl Loss: 2.903116462504851e-11, Output Loss: 1.3995868641814013e-07\n",
      "Iteration 999: Total Loss: 3.0395281314849854, Expl Loss: 2.902740547927607e-11, Output Loss: 1.3678754839929752e-07\n",
      "Iteration 1000: Total Loss: 3.039839267730713, Expl Loss: 2.8998669784896514e-11, Output Loss: 1.3997254200148745e-07\n",
      "Iteration 1001: Total Loss: 3.0334792137145996, Expl Loss: 2.8972629850798626e-11, Output Loss: 1.3621632888316526e-07\n",
      "Iteration 1002: Total Loss: 3.0343096256256104, Expl Loss: 2.8956732844864774e-11, Output Loss: 1.386363805977453e-07\n",
      "Iteration 1003: Total Loss: 3.027810573577881, Expl Loss: 2.8915626837378028e-11, Output Loss: 1.362478627697783e-07\n",
      "Iteration 1004: Total Loss: 3.023207902908325, Expl Loss: 2.8865004136902073e-11, Output Loss: 1.3670764076323394e-07\n",
      "Iteration 1005: Total Loss: 3.0211739540100098, Expl Loss: 2.8841028523740597e-11, Output Loss: 1.3707109758342995e-07\n",
      "Iteration 1006: Total Loss: 3.0177934169769287, Expl Loss: 2.8823209444195363e-11, Output Loss: 1.354726464342093e-07\n",
      "Iteration 1007: Total Loss: 3.0173823833465576, Expl Loss: 2.8805225565919912e-11, Output Loss: 1.368599811257809e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1008: Total Loss: 3.0124378204345703, Expl Loss: 2.8771839077901262e-11, Output Loss: 1.3525394138014235e-07\n",
      "Iteration 1009: Total Loss: 3.011397123336792, Expl Loss: 2.875392458856485e-11, Output Loss: 1.3600458714790875e-07\n",
      "Iteration 1010: Total Loss: 3.007758378982544, Expl Loss: 2.8720704633999894e-11, Output Loss: 1.356880972025465e-07\n",
      "Iteration 1011: Total Loss: 3.004257917404175, Expl Loss: 2.869425703988515e-11, Output Loss: 1.3483241900758003e-07\n",
      "Iteration 1012: Total Loss: 3.0045547485351562, Expl Loss: 2.8688228875806132e-11, Output Loss: 1.3573202295447118e-07\n",
      "Iteration 1013: Total Loss: 3.0000717639923096, Expl Loss: 2.8653000111455995e-11, Output Loss: 1.347717244470914e-07\n",
      "Iteration 1014: Total Loss: 2.99710750579834, Expl Loss: 2.862256959224041e-11, Output Loss: 1.3485045258221362e-07\n",
      "Iteration 1015: Total Loss: 2.994553327560425, Expl Loss: 2.8595415965670945e-11, Output Loss: 1.3501170315066702e-07\n",
      "Iteration 1016: Total Loss: 2.9934823513031006, Expl Loss: 2.8592388873205365e-11, Output Loss: 1.3424345013390848e-07\n",
      "Iteration 1017: Total Loss: 2.9937236309051514, Expl Loss: 2.8590426900954036e-11, Output Loss: 1.3468107340486313e-07\n",
      "Iteration 1018: Total Loss: 2.991715669631958, Expl Loss: 2.8573560184597113e-11, Output Loss: 1.343595812386411e-07\n",
      "Iteration 1019: Total Loss: 2.987860679626465, Expl Loss: 2.853976083239118e-11, Output Loss: 1.3388465447405906e-07\n",
      "Iteration 1020: Total Loss: 2.984381914138794, Expl Loss: 2.8502387949824737e-11, Output Loss: 1.3414305044534558e-07\n",
      "Iteration 1021: Total Loss: 2.9803788661956787, Expl Loss: 2.846496476027749e-11, Output Loss: 1.3388259390012536e-07\n",
      "Iteration 1022: Total Loss: 2.9758493900299072, Expl Loss: 2.8422968839647567e-11, Output Loss: 1.335524615342365e-07\n",
      "Iteration 1023: Total Loss: 2.9772067070007324, Expl Loss: 2.8435330479137377e-11, Output Loss: 1.336737085466666e-07\n",
      "Iteration 1024: Total Loss: 2.9732401371002197, Expl Loss: 2.8398455462208538e-11, Output Loss: 1.3339473525775247e-07\n",
      "Iteration 1025: Total Loss: 2.9695310592651367, Expl Loss: 2.8362487705657635e-11, Output Loss: 1.3328232739695522e-07\n",
      "Iteration 1026: Total Loss: 2.9666426181793213, Expl Loss: 2.833331139151518e-11, Output Loss: 1.333115591251044e-07\n",
      "Iteration 1027: Total Loss: 2.9652154445648193, Expl Loss: 2.832164364141576e-11, Output Loss: 1.330512162667219e-07\n",
      "Iteration 1028: Total Loss: 2.96250057220459, Expl Loss: 2.829575115881333e-11, Output Loss: 1.3292552125676593e-07\n",
      "Iteration 1029: Total Loss: 2.958216905593872, Expl Loss: 2.8252320621868776e-11, Output Loss: 1.3298489420776605e-07\n",
      "Iteration 1030: Total Loss: 2.953395128250122, Expl Loss: 2.8206017382848003e-11, Output Loss: 1.3279337451876927e-07\n",
      "Iteration 1031: Total Loss: 2.9516797065734863, Expl Loss: 2.819051762859015e-11, Output Loss: 1.3262807385672204e-07\n",
      "Iteration 1032: Total Loss: 2.9481921195983887, Expl Loss: 2.8155455397693707e-11, Output Loss: 1.3264649112443294e-07\n",
      "Iteration 1033: Total Loss: 2.9459893703460693, Expl Loss: 2.8134038501659298e-11, Output Loss: 1.325854981359953e-07\n",
      "Iteration 1034: Total Loss: 2.9441299438476562, Expl Loss: 2.8117255052029222e-11, Output Loss: 1.3240449447948777e-07\n",
      "Iteration 1035: Total Loss: 2.9427289962768555, Expl Loss: 2.8103439714266543e-11, Output Loss: 1.3238492613254493e-07\n",
      "Iteration 1036: Total Loss: 2.943152904510498, Expl Loss: 2.8107988159220554e-11, Output Loss: 1.323542448972148e-07\n",
      "Iteration 1037: Total Loss: 2.940497636795044, Expl Loss: 2.8082995998102156e-11, Output Loss: 1.321981102364589e-07\n",
      "Iteration 1038: Total Loss: 2.9380857944488525, Expl Loss: 2.8059566822835613e-11, Output Loss: 1.3212908811510715e-07\n",
      "Iteration 1039: Total Loss: 2.932765245437622, Expl Loss: 2.800673581937474e-11, Output Loss: 1.3209186988660804e-07\n",
      "Iteration 1040: Total Loss: 2.9299256801605225, Expl Loss: 2.7979750460982444e-11, Output Loss: 1.3195057135817478e-07\n",
      "Iteration 1041: Total Loss: 2.929008722305298, Expl Loss: 2.7971408175786472e-11, Output Loss: 1.3186792102715117e-07\n",
      "Iteration 1042: Total Loss: 2.9271841049194336, Expl Loss: 2.7953516237855247e-11, Output Loss: 1.3183253599891032e-07\n",
      "Iteration 1043: Total Loss: 2.9271018505096436, Expl Loss: 2.7953788589440975e-11, Output Loss: 1.3172312662845798e-07\n",
      "Iteration 1044: Total Loss: 2.9239144325256348, Expl Loss: 2.792296081854939e-11, Output Loss: 1.3161862000288238e-07\n",
      "Iteration 1045: Total Loss: 2.922255277633667, Expl Loss: 2.7906897279161846e-11, Output Loss: 1.3156551403881167e-07\n",
      "Iteration 1046: Total Loss: 2.9198708534240723, Expl Loss: 2.7883742190204508e-11, Output Loss: 1.3149666244771652e-07\n",
      "Iteration 1047: Total Loss: 2.9192936420440674, Expl Loss: 2.7878815575532734e-11, Output Loss: 1.3141210786216106e-07\n",
      "Iteration 1048: Total Loss: 2.9163241386413574, Expl Loss: 2.785011284089922e-11, Output Loss: 1.3131280240941123e-07\n",
      "Iteration 1049: Total Loss: 2.9160680770874023, Expl Loss: 2.7848123113072276e-11, Output Loss: 1.312557458277297e-07\n",
      "Iteration 1050: Total Loss: 2.9120724201202393, Expl Loss: 2.780872060403894e-11, Output Loss: 1.3120038033775927e-07\n",
      "Iteration 1051: Total Loss: 2.9084668159484863, Expl Loss: 2.7773788477403194e-11, Output Loss: 1.3108790142268845e-07\n",
      "Iteration 1052: Total Loss: 2.9047203063964844, Expl Loss: 2.773730377325645e-11, Output Loss: 1.309900881096837e-07\n",
      "Iteration 1053: Total Loss: 2.903501033782959, Expl Loss: 2.772597602895832e-11, Output Loss: 1.3090350137190399e-07\n",
      "Iteration 1054: Total Loss: 2.9004673957824707, Expl Loss: 2.7696534302124043e-11, Output Loss: 1.308141577283095e-07\n",
      "Iteration 1055: Total Loss: 2.8997769355773926, Expl Loss: 2.7690768081289896e-11, Output Loss: 1.3070008719751058e-07\n",
      "Iteration 1056: Total Loss: 2.896440029144287, Expl Loss: 2.765848834684892e-11, Output Loss: 1.3059106152013555e-07\n",
      "Iteration 1057: Total Loss: 2.894401788711548, Expl Loss: 2.7639092403664023e-11, Output Loss: 1.3049263714037806e-07\n",
      "Iteration 1058: Total Loss: 2.8912882804870605, Expl Loss: 2.7608821479008228e-11, Output Loss: 1.3040606461345305e-07\n",
      "Iteration 1059: Total Loss: 2.890238046646118, Expl Loss: 2.7599374174958058e-11, Output Loss: 1.3030069112573983e-07\n",
      "Iteration 1060: Total Loss: 2.8885276317596436, Expl Loss: 2.7583204817438478e-11, Output Loss: 1.3020722633427795e-07\n",
      "Iteration 1061: Total Loss: 2.888360023498535, Expl Loss: 2.758229408761359e-11, Output Loss: 1.3013087141189317e-07\n",
      "Iteration 1062: Total Loss: 2.883768081665039, Expl Loss: 2.7537156582768674e-11, Output Loss: 1.3005268328925013e-07\n",
      "Iteration 1063: Total Loss: 2.8813533782958984, Expl Loss: 2.751371006026737e-11, Output Loss: 1.2998239640182874e-07\n",
      "Iteration 1064: Total Loss: 2.8778815269470215, Expl Loss: 2.7479796216312025e-11, Output Loss: 1.2990193454243126e-07\n",
      "Iteration 1065: Total Loss: 2.8759238719940186, Expl Loss: 2.7460967527703772e-11, Output Loss: 1.2982721386833873e-07\n",
      "Iteration 1066: Total Loss: 2.8743510246276855, Expl Loss: 2.74460974780677e-11, Output Loss: 1.2974143714927777e-07\n",
      "Iteration 1067: Total Loss: 2.8727500438690186, Expl Loss: 2.7430963750463278e-11, Output Loss: 1.296536851214114e-07\n",
      "Iteration 1068: Total Loss: 2.8704545497894287, Expl Loss: 2.7408977865128747e-11, Output Loss: 1.295569376225103e-07\n",
      "Iteration 1069: Total Loss: 2.8683724403381348, Expl Loss: 2.738895221732207e-11, Output Loss: 1.294772999926863e-07\n",
      "Iteration 1070: Total Loss: 2.8660621643066406, Expl Loss: 2.736688479998417e-11, Output Loss: 1.2937375970523135e-07\n",
      "Iteration 1071: Total Loss: 2.8667027950286865, Expl Loss: 2.7374139413560705e-11, Output Loss: 1.2928890669172688e-07\n",
      "Iteration 1072: Total Loss: 2.865607976913452, Expl Loss: 2.7364279245323253e-11, Output Loss: 1.291802078640103e-07\n",
      "Iteration 1073: Total Loss: 2.86303448677063, Expl Loss: 2.7339255859182288e-11, Output Loss: 1.2910884095163055e-07\n",
      "Iteration 1074: Total Loss: 2.8618545532226562, Expl Loss: 2.7328516186142515e-11, Output Loss: 1.290031548251136e-07\n",
      "Iteration 1075: Total Loss: 2.858196258544922, Expl Loss: 2.7292444346183053e-11, Output Loss: 1.2895179679617286e-07\n",
      "Iteration 1076: Total Loss: 2.8557419776916504, Expl Loss: 2.7268767105459446e-11, Output Loss: 1.288652811126667e-07\n",
      "Iteration 1077: Total Loss: 2.854301691055298, Expl Loss: 2.725462737440676e-11, Output Loss: 1.2883899103144358e-07\n",
      "Iteration 1078: Total Loss: 2.8519396781921387, Expl Loss: 2.7231970151087026e-11, Output Loss: 1.287428119667311e-07\n",
      "Iteration 1079: Total Loss: 2.849966049194336, Expl Loss: 2.7212100628393188e-11, Output Loss: 1.2875617017016339e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1080: Total Loss: 2.84842586517334, Expl Loss: 2.719717680232936e-11, Output Loss: 1.2870806642695243e-07\n",
      "Iteration 1081: Total Loss: 2.8483364582061768, Expl Loss: 2.7194066443136933e-11, Output Loss: 1.2892992629076616e-07\n",
      "Iteration 1082: Total Loss: 2.8459415435791016, Expl Loss: 2.7167818342221928e-11, Output Loss: 1.2915965896809212e-07\n",
      "Iteration 1083: Total Loss: 2.8446295261383057, Expl Loss: 2.7144581721261218e-11, Output Loss: 1.3017130129355792e-07\n",
      "Iteration 1084: Total Loss: 2.8431947231292725, Expl Loss: 2.71166665510858e-11, Output Loss: 1.3152821054518427e-07\n",
      "Iteration 1085: Total Loss: 2.8445286750793457, Expl Loss: 2.7101808644514058e-11, Output Loss: 1.343479709703388e-07\n",
      "Iteration 1086: Total Loss: 2.845486879348755, Expl Loss: 2.70767991361609e-11, Output Loss: 1.378072198576774e-07\n",
      "Iteration 1087: Total Loss: 2.8486998081207275, Expl Loss: 2.706872399838023e-11, Output Loss: 1.4182725749378733e-07\n",
      "Iteration 1088: Total Loss: 2.8489363193511963, Expl Loss: 2.7038897162934283e-11, Output Loss: 1.4504671241866163e-07\n",
      "Iteration 1089: Total Loss: 2.847449779510498, Expl Loss: 2.7039327374356326e-11, Output Loss: 1.4351712707139086e-07\n",
      "Iteration 1090: Total Loss: 2.8402247428894043, Expl Loss: 2.702430813850132e-11, Output Loss: 1.3779410323877528e-07\n",
      "Iteration 1091: Total Loss: 2.8310964107513428, Expl Loss: 2.700309767456055e-11, Output Loss: 1.3078654603759787e-07\n",
      "Iteration 1092: Total Loss: 2.8288474082946777, Expl Loss: 2.701013024353216e-11, Output Loss: 1.2783425518136937e-07\n",
      "Iteration 1093: Total Loss: 2.8254740238189697, Expl Loss: 2.694814857373551e-11, Output Loss: 1.3065913151422137e-07\n",
      "Iteration 1094: Total Loss: 2.828159809112549, Expl Loss: 2.69461779278668e-11, Output Loss: 1.335420876102944e-07\n",
      "Iteration 1095: Total Loss: 2.8251774311065674, Expl Loss: 2.69345448722369e-11, Output Loss: 1.3172282820050896e-07\n",
      "Iteration 1096: Total Loss: 2.819227457046509, Expl Loss: 2.690842340613564e-11, Output Loss: 1.2838505369927589e-07\n",
      "Iteration 1097: Total Loss: 2.82030987739563, Expl Loss: 2.692461878450736e-11, Output Loss: 1.278482102406997e-07\n",
      "Iteration 1098: Total Loss: 2.8186721801757812, Expl Loss: 2.6891112600568867e-11, Output Loss: 1.2956098771610414e-07\n",
      "Iteration 1099: Total Loss: 2.817856788635254, Expl Loss: 2.68786035095836e-11, Output Loss: 1.299965646239798e-07\n",
      "Iteration 1100: Total Loss: 2.813552141189575, Expl Loss: 2.6852017137590778e-11, Output Loss: 1.283505781657368e-07\n",
      "Iteration 1101: Total Loss: 2.8110604286193848, Expl Loss: 2.683520072821466e-11, Output Loss: 1.27540474181842e-07\n",
      "Iteration 1102: Total Loss: 2.809907913208008, Expl Loss: 2.6819015758183795e-11, Output Loss: 1.280064765296629e-07\n",
      "Iteration 1103: Total Loss: 2.8089640140533447, Expl Loss: 2.6807127698202926e-11, Output Loss: 1.2825132955640584e-07\n",
      "Iteration 1104: Total Loss: 2.8058547973632812, Expl Loss: 2.6780092032829828e-11, Output Loss: 1.278458796605264e-07\n",
      "Iteration 1105: Total Loss: 2.8031039237976074, Expl Loss: 2.6757290827461588e-11, Output Loss: 1.2737486088099104e-07\n",
      "Iteration 1106: Total Loss: 2.800443649291992, Expl Loss: 2.672980239926126e-11, Output Loss: 1.2746352240355918e-07\n",
      "Iteration 1107: Total Loss: 2.799757242202759, Expl Loss: 2.6724549656576002e-11, Output Loss: 1.273023713110888e-07\n",
      "Iteration 1108: Total Loss: 2.799922227859497, Expl Loss: 2.6729786786749976e-11, Output Loss: 1.2694363249465823e-07\n",
      "Iteration 1109: Total Loss: 2.7967727184295654, Expl Loss: 2.6697749913595636e-11, Output Loss: 1.2699779006197787e-07\n",
      "Iteration 1110: Total Loss: 2.7945291996002197, Expl Loss: 2.6675566269784845e-11, Output Loss: 1.2697273632511497e-07\n",
      "Iteration 1111: Total Loss: 2.792288303375244, Expl Loss: 2.6654839793693874e-11, Output Loss: 1.2680426664246625e-07\n",
      "Iteration 1112: Total Loss: 2.7893543243408203, Expl Loss: 2.6630270905103615e-11, Output Loss: 1.263272793039505e-07\n",
      "Iteration 1113: Total Loss: 2.788247585296631, Expl Loss: 2.66200759352353e-11, Output Loss: 1.26240081499418e-07\n",
      "Iteration 1114: Total Loss: 2.7858054637908936, Expl Loss: 2.6592492097243792e-11, Output Loss: 1.2655634407110483e-07\n",
      "Iteration 1115: Total Loss: 2.787224531173706, Expl Loss: 2.6607436739989332e-11, Output Loss: 1.264808702217124e-07\n",
      "Iteration 1116: Total Loss: 2.7836976051330566, Expl Loss: 2.657442668696497e-11, Output Loss: 1.2625497447515954e-07\n",
      "Iteration 1117: Total Loss: 2.7817883491516113, Expl Loss: 2.6558645907504008e-11, Output Loss: 1.2592398945798777e-07\n",
      "Iteration 1118: Total Loss: 2.7803919315338135, Expl Loss: 2.6544500972280893e-11, Output Loss: 1.2594192355663836e-07\n",
      "Iteration 1119: Total Loss: 2.778686046600342, Expl Loss: 2.652687965121192e-11, Output Loss: 1.259980422219087e-07\n",
      "Iteration 1120: Total Loss: 2.7774994373321533, Expl Loss: 2.6516327328307554e-11, Output Loss: 1.2586676234604965e-07\n",
      "Iteration 1121: Total Loss: 2.774474859237671, Expl Loss: 2.6487013971010498e-11, Output Loss: 1.257734254522802e-07\n",
      "Iteration 1122: Total Loss: 2.7737529277801514, Expl Loss: 2.6480638862236283e-11, Output Loss: 1.2568908402954548e-07\n",
      "Iteration 1123: Total Loss: 2.77048921585083, Expl Loss: 2.6447458806311275e-11, Output Loss: 1.257433268619934e-07\n",
      "Iteration 1124: Total Loss: 2.767341375350952, Expl Loss: 2.6416971041220982e-11, Output Loss: 1.2564427720462845e-07\n",
      "Iteration 1125: Total Loss: 2.764197826385498, Expl Loss: 2.6386783383292034e-11, Output Loss: 1.2551956274364784e-07\n",
      "Iteration 1126: Total Loss: 2.7609975337982178, Expl Loss: 2.6356160309770615e-11, Output Loss: 1.2538147586838022e-07\n",
      "Iteration 1127: Total Loss: 2.7591490745544434, Expl Loss: 2.6338058470298797e-11, Output Loss: 1.253432344583416e-07\n",
      "Iteration 1128: Total Loss: 2.7594716548919678, Expl Loss: 2.6341508835292515e-11, Output Loss: 1.2532093762729346e-07\n",
      "Iteration 1129: Total Loss: 2.7572181224823, Expl Loss: 2.631947784714761e-11, Output Loss: 1.2527027593023377e-07\n",
      "Iteration 1130: Total Loss: 2.754486560821533, Expl Loss: 2.629280473898099e-11, Output Loss: 1.2520625602974178e-07\n",
      "Iteration 1131: Total Loss: 2.7521843910217285, Expl Loss: 2.6270860487009884e-11, Output Loss: 1.250984951184364e-07\n",
      "Iteration 1132: Total Loss: 2.7523064613342285, Expl Loss: 2.6272170203234246e-11, Output Loss: 1.2508940017141867e-07\n",
      "Iteration 1133: Total Loss: 2.7505691051483154, Expl Loss: 2.6255914109540868e-11, Output Loss: 1.249779018053232e-07\n",
      "Iteration 1134: Total Loss: 2.749720335006714, Expl Loss: 2.6247760909203777e-11, Output Loss: 1.249441652362293e-07\n",
      "Iteration 1135: Total Loss: 2.7466819286346436, Expl Loss: 2.621896103005561e-11, Output Loss: 1.247858847364114e-07\n",
      "Iteration 1136: Total Loss: 2.7440989017486572, Expl Loss: 2.6193660088158488e-11, Output Loss: 1.2473287824832369e-07\n",
      "Iteration 1137: Total Loss: 2.7416279315948486, Expl Loss: 2.617006437943825e-11, Output Loss: 1.2462170673188666e-07\n",
      "Iteration 1138: Total Loss: 2.739410877227783, Expl Loss: 2.6148366458200734e-11, Output Loss: 1.2457419984457374e-07\n",
      "Iteration 1139: Total Loss: 2.73909854888916, Expl Loss: 2.6146305606711273e-11, Output Loss: 1.244681442358342e-07\n",
      "Iteration 1140: Total Loss: 2.7349884510040283, Expl Loss: 2.610606522623904e-11, Output Loss: 1.2438209751053364e-07\n",
      "Iteration 1141: Total Loss: 2.7347896099090576, Expl Loss: 2.6104942860150082e-11, Output Loss: 1.242953970859162e-07\n",
      "Iteration 1142: Total Loss: 2.731107711791992, Expl Loss: 2.606870795618388e-11, Output Loss: 1.24237175214148e-07\n",
      "Iteration 1143: Total Loss: 2.727963924407959, Expl Loss: 2.6037725794902933e-11, Output Loss: 1.241913594185462e-07\n",
      "Iteration 1144: Total Loss: 2.7270617485046387, Expl Loss: 2.6029423408346908e-11, Output Loss: 1.2411940986112313e-07\n",
      "Iteration 1145: Total Loss: 2.7255144119262695, Expl Loss: 2.6014562032328215e-11, Output Loss: 1.2405826055328362e-07\n",
      "Iteration 1146: Total Loss: 2.7248036861419678, Expl Loss: 2.60084107028824e-11, Output Loss: 1.2396263571190502e-07\n",
      "Iteration 1147: Total Loss: 2.722285509109497, Expl Loss: 2.598343241955181e-11, Output Loss: 1.2394235682222643e-07\n",
      "Iteration 1148: Total Loss: 2.719789743423462, Expl Loss: 2.5959146290888135e-11, Output Loss: 1.2387523895540653e-07\n",
      "Iteration 1149: Total Loss: 2.717940092086792, Expl Loss: 2.5939856165835273e-11, Output Loss: 1.2395446447044378e-07\n",
      "Iteration 1150: Total Loss: 2.715151786804199, Expl Loss: 2.591219253056387e-11, Output Loss: 1.2393265080845595e-07\n",
      "Iteration 1151: Total Loss: 2.7143189907073975, Expl Loss: 2.5902214401130053e-11, Output Loss: 1.240976814642636e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1152: Total Loss: 2.7139859199523926, Expl Loss: 2.5898956590442168e-11, Output Loss: 1.240904907717777e-07\n",
      "Iteration 1153: Total Loss: 2.7115049362182617, Expl Loss: 2.5871835923618747e-11, Output Loss: 1.243213887391903e-07\n",
      "Iteration 1154: Total Loss: 2.7086377143859863, Expl Loss: 2.5843299722438928e-11, Output Loss: 1.2430787421635614e-07\n",
      "Iteration 1155: Total Loss: 2.705549478530884, Expl Loss: 2.580974843569006e-11, Output Loss: 1.2457458353765105e-07\n",
      "Iteration 1156: Total Loss: 2.7028567790985107, Expl Loss: 2.5782750934233434e-11, Output Loss: 1.2458178844099166e-07\n",
      "Iteration 1157: Total Loss: 2.7015295028686523, Expl Loss: 2.5767211281335634e-11, Output Loss: 1.2480828104344255e-07\n",
      "Iteration 1158: Total Loss: 2.700087785720825, Expl Loss: 2.5755538327065786e-11, Output Loss: 1.2453391207145614e-07\n",
      "Iteration 1159: Total Loss: 2.696200132369995, Expl Loss: 2.5718651167072615e-11, Output Loss: 1.243351448465546e-07\n",
      "Iteration 1160: Total Loss: 2.694781541824341, Expl Loss: 2.571114675331554e-11, Output Loss: 1.236670215121194e-07\n",
      "Iteration 1161: Total Loss: 2.690845251083374, Expl Loss: 2.5676495651882902e-11, Output Loss: 1.23195704304635e-07\n",
      "Iteration 1162: Total Loss: 2.686495304107666, Expl Loss: 2.5636041900423123e-11, Output Loss: 1.2289110884466936e-07\n",
      "Iteration 1163: Total Loss: 2.685777187347412, Expl Loss: 2.562859299781728e-11, Output Loss: 1.2291782525153394e-07\n",
      "Iteration 1164: Total Loss: 2.6844120025634766, Expl Loss: 2.5612645684902624e-11, Output Loss: 1.2314750108544104e-07\n",
      "Iteration 1165: Total Loss: 2.6815781593322754, Expl Loss: 2.558360294446782e-11, Output Loss: 1.23217859027136e-07\n",
      "Iteration 1166: Total Loss: 2.6788856983184814, Expl Loss: 2.555603818843455e-11, Output Loss: 1.232819926144657e-07\n",
      "Iteration 1167: Total Loss: 2.6779093742370605, Expl Loss: 2.5549408075309366e-11, Output Loss: 1.2296877116568794e-07\n",
      "Iteration 1168: Total Loss: 2.6767985820770264, Expl Loss: 2.5540779560739857e-11, Output Loss: 1.2272077754005295e-07\n",
      "Iteration 1169: Total Loss: 2.674865961074829, Expl Loss: 2.5525435931594842e-11, Output Loss: 1.2232233359554812e-07\n",
      "Iteration 1170: Total Loss: 2.67507004737854, Expl Loss: 2.55292662010298e-11, Output Loss: 1.2214351841066673e-07\n",
      "Iteration 1171: Total Loss: 2.6735358238220215, Expl Loss: 2.5515228818662194e-11, Output Loss: 1.2201320487292833e-07\n",
      "Iteration 1172: Total Loss: 2.6712632179260254, Expl Loss: 2.549290466224985e-11, Output Loss: 1.2197290288895601e-07\n",
      "Iteration 1173: Total Loss: 2.6663920879364014, Expl Loss: 2.544353443212355e-11, Output Loss: 1.2203858545944968e-07\n",
      "Iteration 1174: Total Loss: 2.665235996246338, Expl Loss: 2.54314572872838e-11, Output Loss: 1.2209034139232244e-07\n",
      "Iteration 1175: Total Loss: 2.6644229888916016, Expl Loss: 2.5420089644345722e-11, Output Loss: 1.224142209821366e-07\n",
      "Iteration 1176: Total Loss: 2.6623926162719727, Expl Loss: 2.539744456409032e-11, Output Loss: 1.2264817428331298e-07\n",
      "Iteration 1177: Total Loss: 2.661313772201538, Expl Loss: 2.5379821508297873e-11, Output Loss: 1.2333168797340477e-07\n",
      "Iteration 1178: Total Loss: 2.6596877574920654, Expl Loss: 2.5358062871738696e-11, Output Loss: 1.238816622617378e-07\n",
      "Iteration 1179: Total Loss: 2.6612281799316406, Expl Loss: 2.536252804996586e-11, Output Loss: 1.2497548596002162e-07\n",
      "Iteration 1180: Total Loss: 2.658933639526367, Expl Loss: 2.5330907510445755e-11, Output Loss: 1.2584294495354698e-07\n",
      "Iteration 1181: Total Loss: 2.657323122024536, Expl Loss: 2.530184742277619e-11, Output Loss: 1.2713829278254707e-07\n",
      "Iteration 1182: Total Loss: 2.657059669494629, Expl Loss: 2.52904953923494e-11, Output Loss: 1.2801027082787186e-07\n",
      "Iteration 1183: Total Loss: 2.6569595336914062, Expl Loss: 2.528780830568511e-11, Output Loss: 1.2817874051052058e-07\n",
      "Iteration 1184: Total Loss: 2.6529593467712402, Expl Loss: 2.5258871383382342e-11, Output Loss: 1.2707243968179682e-07\n",
      "Iteration 1185: Total Loss: 2.6525468826293945, Expl Loss: 2.527330775214942e-11, Output Loss: 1.252163599474443e-07\n",
      "Iteration 1186: Total Loss: 2.6489996910095215, Expl Loss: 2.5257020433433475e-11, Output Loss: 1.2329763876550714e-07\n",
      "Iteration 1187: Total Loss: 2.6450893878936768, Expl Loss: 2.522201024424131e-11, Output Loss: 1.2288839457141876e-07\n",
      "Iteration 1188: Total Loss: 2.644493341445923, Expl Loss: 2.520326655708338e-11, Output Loss: 1.2416666095305118e-07\n",
      "Iteration 1189: Total Loss: 2.6426360607147217, Expl Loss: 2.5178022861060967e-11, Output Loss: 1.2483380373851105e-07\n",
      "Iteration 1190: Total Loss: 2.639989137649536, Expl Loss: 2.5147290499960562e-11, Output Loss: 1.252601293799671e-07\n",
      "Iteration 1191: Total Loss: 2.637439489364624, Expl Loss: 2.514108192464004e-11, Output Loss: 1.233313469128916e-07\n",
      "Iteration 1192: Total Loss: 2.6324760913848877, Expl Loss: 2.5109091889019552e-11, Output Loss: 1.2156701245658041e-07\n",
      "Iteration 1193: Total Loss: 2.630558967590332, Expl Loss: 2.5098000067114157e-11, Output Loss: 1.2075894062490988e-07\n",
      "Iteration 1194: Total Loss: 2.630589485168457, Expl Loss: 2.5091633631957322e-11, Output Loss: 1.214262255189169e-07\n",
      "Iteration 1195: Total Loss: 2.6290903091430664, Expl Loss: 2.5065536451984727e-11, Output Loss: 1.2253669012807222e-07\n",
      "Iteration 1196: Total Loss: 2.6290841102600098, Expl Loss: 2.5067814143908684e-11, Output Loss: 1.2230289314629772e-07\n",
      "Iteration 1197: Total Loss: 2.625284194946289, Expl Loss: 2.5035773801307393e-11, Output Loss: 1.2170691832125158e-07\n",
      "Iteration 1198: Total Loss: 2.622296094894409, Expl Loss: 2.5017330221310807e-11, Output Loss: 1.2056298714924196e-07\n",
      "Iteration 1199: Total Loss: 2.6203970909118652, Expl Loss: 2.500192761156761e-11, Output Loss: 1.2020444728477742e-07\n",
      "Iteration 1200: Total Loss: 2.621817111968994, Expl Loss: 2.501242268859727e-11, Output Loss: 1.2057492426720273e-07\n",
      "Iteration 1201: Total Loss: 2.619285821914673, Expl Loss: 2.498385179294793e-11, Output Loss: 1.2090055179214687e-07\n",
      "Iteration 1202: Total Loss: 2.617753505706787, Expl Loss: 2.4967080486382187e-11, Output Loss: 1.2104553093195136e-07\n",
      "Iteration 1203: Total Loss: 2.6139895915985107, Expl Loss: 2.493549984550203e-11, Output Loss: 1.2043976482800645e-07\n",
      "Iteration 1204: Total Loss: 2.6108710765838623, Expl Loss: 2.4908537038514922e-11, Output Loss: 1.2001753191270836e-07\n",
      "Iteration 1205: Total Loss: 2.6098384857177734, Expl Loss: 2.489996230037317e-11, Output Loss: 1.1984224101979635e-07\n",
      "Iteration 1206: Total Loss: 2.6079025268554688, Expl Loss: 2.4878951329632137e-11, Output Loss: 1.2000739957329642e-07\n",
      "Iteration 1207: Total Loss: 2.607219934463501, Expl Loss: 2.4868905545982756e-11, Output Loss: 1.2032944596285233e-07\n",
      "Iteration 1208: Total Loss: 2.6045854091644287, Expl Loss: 2.484336521224595e-11, Output Loss: 1.202491120011473e-07\n",
      "Iteration 1209: Total Loss: 2.603562831878662, Expl Loss: 2.4834157300035464e-11, Output Loss: 1.2014717754027515e-07\n",
      "Iteration 1210: Total Loss: 2.6007728576660156, Expl Loss: 2.481080618732534e-11, Output Loss: 1.1969240176767926e-07\n",
      "Iteration 1211: Total Loss: 2.600240468978882, Expl Loss: 2.4807739196219813e-11, Output Loss: 1.1946644917770755e-07\n",
      "Iteration 1212: Total Loss: 2.5968387126922607, Expl Loss: 2.477490608499e-11, Output Loss: 1.193479732819469e-07\n",
      "Iteration 1213: Total Loss: 2.596099853515625, Expl Loss: 2.4766225528716213e-11, Output Loss: 1.1947726363814581e-07\n",
      "Iteration 1214: Total Loss: 2.594689130783081, Expl Loss: 2.4750115151794816e-11, Output Loss: 1.1967787827416032e-07\n",
      "Iteration 1215: Total Loss: 2.590963840484619, Expl Loss: 2.471075080667795e-11, Output Loss: 1.198887531472792e-07\n",
      "Iteration 1216: Total Loss: 2.588948965072632, Expl Loss: 2.4688607061507106e-11, Output Loss: 1.2008838723431836e-07\n",
      "Iteration 1217: Total Loss: 2.5898702144622803, Expl Loss: 2.4691857933301087e-11, Output Loss: 1.2068433363765507e-07\n",
      "Iteration 1218: Total Loss: 2.5872802734375, Expl Loss: 2.465518414429546e-11, Output Loss: 1.217618148530164e-07\n",
      "Iteration 1219: Total Loss: 2.587561845779419, Expl Loss: 2.4632481818165353e-11, Output Loss: 1.2431385698619124e-07\n",
      "Iteration 1220: Total Loss: 2.5903961658477783, Expl Loss: 2.461444242873867e-11, Output Loss: 1.289521236458313e-07\n",
      "Iteration 1221: Total Loss: 2.593604326248169, Expl Loss: 2.45758725869738e-11, Output Loss: 1.3601700743492984e-07\n",
      "Iteration 1222: Total Loss: 2.6056458950042725, Expl Loss: 2.4578901414162857e-11, Output Loss: 1.4775579870729416e-07\n",
      "Iteration 1223: Total Loss: 2.6087939739227295, Expl Loss: 2.4556334396463875e-11, Output Loss: 1.5316049939428922e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1224: Total Loss: 2.614466905593872, Expl Loss: 2.4553060973264706e-11, Output Loss: 1.591608764783814e-07\n",
      "Iteration 1225: Total Loss: 2.5931973457336426, Expl Loss: 2.453721774375861e-11, Output Loss: 1.3947560262295156e-07\n",
      "Iteration 1226: Total Loss: 2.572748899459839, Expl Loss: 2.450754356397855e-11, Output Loss: 1.2199453180983255e-07\n",
      "Iteration 1227: Total Loss: 2.5753304958343506, Expl Loss: 2.4505765472415675e-11, Output Loss: 1.2475405242184934e-07\n",
      "Iteration 1228: Total Loss: 2.5865259170532227, Expl Loss: 2.449522529257564e-11, Output Loss: 1.370033686498573e-07\n",
      "Iteration 1229: Total Loss: 2.583510160446167, Expl Loss: 2.4485715538480335e-11, Output Loss: 1.349386877791403e-07\n",
      "Iteration 1230: Total Loss: 2.569384813308716, Expl Loss: 2.446413210899223e-11, Output Loss: 1.229714428063744e-07\n",
      "Iteration 1231: Total Loss: 2.567397356033325, Expl Loss: 2.4456471570122318e-11, Output Loss: 1.2175026142813294e-07\n",
      "Iteration 1232: Total Loss: 2.5738654136657715, Expl Loss: 2.4451966493255206e-11, Output Loss: 1.2866865972682717e-07\n",
      "Iteration 1233: Total Loss: 2.5672354698181152, Expl Loss: 2.4419645125450806e-11, Output Loss: 1.2527098647296953e-07\n",
      "Iteration 1234: Total Loss: 2.5583102703094482, Expl Loss: 2.4394857661702574e-11, Output Loss: 1.1882449513223037e-07\n",
      "Iteration 1235: Total Loss: 2.5578176975250244, Expl Loss: 2.4366432482825218e-11, Output Loss: 1.2117462233618426e-07\n",
      "Iteration 1236: Total Loss: 2.558478355407715, Expl Loss: 2.4344757112992887e-11, Output Loss: 1.2400276716562075e-07\n",
      "Iteration 1237: Total Loss: 2.552271842956543, Expl Loss: 2.43187605469819e-11, Output Loss: 1.2039600960633834e-07\n",
      "Iteration 1238: Total Loss: 2.5498857498168945, Expl Loss: 2.431100286359733e-11, Output Loss: 1.1878550765231921e-07\n",
      "Iteration 1239: Total Loss: 2.5516486167907715, Expl Loss: 2.430064136027532e-11, Output Loss: 1.215843923318971e-07\n",
      "Iteration 1240: Total Loss: 2.5497665405273438, Expl Loss: 2.4287407154877094e-11, Output Loss: 1.2102590574158967e-07\n",
      "Iteration 1241: Total Loss: 2.5451667308807373, Expl Loss: 2.4270639317758302e-11, Output Loss: 1.1810267608325375e-07\n",
      "Iteration 1242: Total Loss: 2.54473614692688, Expl Loss: 2.425821869767031e-11, Output Loss: 1.189143148394578e-07\n",
      "Iteration 1243: Total Loss: 2.545560598373413, Expl Loss: 2.4252398700408406e-11, Output Loss: 1.2032069207634777e-07\n",
      "Iteration 1244: Total Loss: 2.541390895843506, Expl Loss: 2.4226553055339828e-11, Output Loss: 1.1873557781427735e-07\n",
      "Iteration 1245: Total Loss: 2.539299249649048, Expl Loss: 2.4216982585922864e-11, Output Loss: 1.1760126028548257e-07\n",
      "Iteration 1246: Total Loss: 2.538085460662842, Expl Loss: 2.419434791400832e-11, Output Loss: 1.1865068216820873e-07\n",
      "Iteration 1247: Total Loss: 2.537675619125366, Expl Loss: 2.418771086198923e-11, Output Loss: 1.1890450224427696e-07\n",
      "Iteration 1248: Total Loss: 2.5341968536376953, Expl Loss: 2.4166854281637562e-11, Output Loss: 1.1751160400308436e-07\n",
      "Iteration 1249: Total Loss: 2.533510446548462, Expl Loss: 2.4161199083105878e-11, Output Loss: 1.1739065541860327e-07\n",
      "Iteration 1250: Total Loss: 2.5323550701141357, Expl Loss: 2.414165221897857e-11, Output Loss: 1.181897459900938e-07\n",
      "Iteration 1251: Total Loss: 2.530974864959717, Expl Loss: 2.4131622047840473e-11, Output Loss: 1.1781260411680705e-07\n",
      "Iteration 1252: Total Loss: 2.5282418727874756, Expl Loss: 2.4111587726416417e-11, Output Loss: 1.170830330465833e-07\n",
      "Iteration 1253: Total Loss: 2.5257961750030518, Expl Loss: 2.4085979738464047e-11, Output Loss: 1.1719814807520379e-07\n",
      "Iteration 1254: Total Loss: 2.525550365447998, Expl Loss: 2.407988565489294e-11, Output Loss: 1.175619388504856e-07\n",
      "Iteration 1255: Total Loss: 2.522296667098999, Expl Loss: 2.4049821162330787e-11, Output Loss: 1.1731462024044959e-07\n",
      "Iteration 1256: Total Loss: 2.522770881652832, Expl Loss: 2.406024164625098e-11, Output Loss: 1.1674663369376503e-07\n",
      "Iteration 1257: Total Loss: 2.5196168422698975, Expl Loss: 2.4028440695489373e-11, Output Loss: 1.167729664075523e-07\n",
      "Iteration 1258: Total Loss: 2.5179224014282227, Expl Loss: 2.400831443372109e-11, Output Loss: 1.1709099823065117e-07\n",
      "Iteration 1259: Total Loss: 2.5152738094329834, Expl Loss: 2.398421565519282e-11, Output Loss: 1.1685221323887163e-07\n",
      "Iteration 1260: Total Loss: 2.513756513595581, Expl Loss: 2.397229810491286e-11, Output Loss: 1.1652686282559443e-07\n",
      "Iteration 1261: Total Loss: 2.5117170810699463, Expl Loss: 2.3952775526914216e-11, Output Loss: 1.1643949449080537e-07\n",
      "Iteration 1262: Total Loss: 2.509451150894165, Expl Loss: 2.392841653986455e-11, Output Loss: 1.1660967658144727e-07\n",
      "Iteration 1263: Total Loss: 2.5089328289031982, Expl Loss: 2.392300940678993e-11, Output Loss: 1.1663207288847843e-07\n",
      "Iteration 1264: Total Loss: 2.5049521923065186, Expl Loss: 2.388599734670649e-11, Output Loss: 1.1635260221964927e-07\n",
      "Iteration 1265: Total Loss: 2.5038626194000244, Expl Loss: 2.3877257809834518e-11, Output Loss: 1.1613685302336307e-07\n",
      "Iteration 1266: Total Loss: 2.503664970397949, Expl Loss: 2.3875170937492918e-11, Output Loss: 1.1614806538773337e-07\n",
      "Iteration 1267: Total Loss: 2.5020697116851807, Expl Loss: 2.3859093520317565e-11, Output Loss: 1.1616044304219031e-07\n",
      "Iteration 1268: Total Loss: 2.5005626678466797, Expl Loss: 2.3843928567690575e-11, Output Loss: 1.16170014052841e-07\n",
      "Iteration 1269: Total Loss: 2.499729633331299, Expl Loss: 2.3837444171337374e-11, Output Loss: 1.1598516636013301e-07\n",
      "Iteration 1270: Total Loss: 2.4976980686187744, Expl Loss: 2.3816839125889722e-11, Output Loss: 1.1601415650375202e-07\n",
      "Iteration 1271: Total Loss: 2.496541738510132, Expl Loss: 2.38040160499553e-11, Output Loss: 1.1614005757110135e-07\n",
      "Iteration 1272: Total Loss: 2.4945127964019775, Expl Loss: 2.377852081902887e-11, Output Loss: 1.16660835658422e-07\n",
      "Iteration 1273: Total Loss: 2.4930505752563477, Expl Loss: 2.3757072697971893e-11, Output Loss: 1.173434256429573e-07\n",
      "Iteration 1274: Total Loss: 2.4936938285827637, Expl Loss: 2.374943297578369e-11, Output Loss: 1.1875062710942075e-07\n",
      "Iteration 1275: Total Loss: 2.4920833110809326, Expl Loss: 2.3713144295389732e-11, Output Loss: 1.2076910138603125e-07\n",
      "Iteration 1276: Total Loss: 2.4962210655212402, Expl Loss: 2.3709841381891472e-11, Output Loss: 1.2523700831934548e-07\n",
      "Iteration 1277: Total Loss: 2.497333526611328, Expl Loss: 2.3675120891519796e-11, Output Loss: 1.298214726830338e-07\n",
      "Iteration 1278: Total Loss: 2.5050761699676514, Expl Loss: 2.367731878616386e-11, Output Loss: 1.373443012653297e-07\n",
      "Iteration 1279: Total Loss: 2.502364158630371, Expl Loss: 2.364743297011973e-11, Output Loss: 1.3762088713065168e-07\n",
      "Iteration 1280: Total Loss: 2.500379800796509, Expl Loss: 2.363662737758787e-11, Output Loss: 1.367170341382007e-07\n",
      "Iteration 1281: Total Loss: 2.4870853424072266, Expl Loss: 2.3629044901274376e-11, Output Loss: 1.241807865426381e-07\n",
      "Iteration 1282: Total Loss: 2.476370334625244, Expl Loss: 2.360528959799435e-11, Output Loss: 1.158413809321246e-07\n",
      "Iteration 1283: Total Loss: 2.4815664291381836, Expl Loss: 2.3636100021651174e-11, Output Loss: 1.1795632559596925e-07\n",
      "Iteration 1284: Total Loss: 2.483116388320923, Expl Loss: 2.359520044625807e-11, Output Loss: 1.2359647882931313e-07\n",
      "Iteration 1285: Total Loss: 2.4814579486846924, Expl Loss: 2.3572603938259995e-11, Output Loss: 1.2419766903803975e-07\n",
      "Iteration 1286: Total Loss: 2.474390983581543, Expl Loss: 2.3569554294389228e-11, Output Loss: 1.1743559014121274e-07\n",
      "Iteration 1287: Total Loss: 2.470106840133667, Expl Loss: 2.3547132993462228e-11, Output Loss: 1.1539368216517687e-07\n",
      "Iteration 1288: Total Loss: 2.471386194229126, Expl Loss: 2.3522975234335775e-11, Output Loss: 1.1908856833997561e-07\n",
      "Iteration 1289: Total Loss: 2.4705939292907715, Expl Loss: 2.3505560345360443e-11, Output Loss: 1.2003810923033598e-07\n",
      "Iteration 1290: Total Loss: 2.4649012088775635, Expl Loss: 2.3478155183886962e-11, Output Loss: 1.1708572600355183e-07\n",
      "Iteration 1291: Total Loss: 2.4610302448272705, Expl Loss: 2.3461286732806563e-11, Output Loss: 1.1490153895010735e-07\n",
      "Iteration 1292: Total Loss: 2.461425542831421, Expl Loss: 2.3447912014806782e-11, Output Loss: 1.166343750469423e-07\n",
      "Iteration 1293: Total Loss: 2.462096691131592, Expl Loss: 2.3438842880474375e-11, Output Loss: 1.1821246204135605e-07\n",
      "Iteration 1294: Total Loss: 2.4605424404144287, Expl Loss: 2.344326469061464e-11, Output Loss: 1.1621595774613525e-07\n",
      "Iteration 1295: Total Loss: 2.453514575958252, Expl Loss: 2.3389869902024074e-11, Output Loss: 1.1452765846797774e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1296: Total Loss: 2.453702211380005, Expl Loss: 2.338426674519667e-11, Output Loss: 1.1527570364933126e-07\n",
      "Iteration 1297: Total Loss: 2.452576160430908, Expl Loss: 2.336345700237885e-11, Output Loss: 1.1623053808307304e-07\n",
      "Iteration 1298: Total Loss: 2.4524409770965576, Expl Loss: 2.3366659301915504e-11, Output Loss: 1.1577510150573289e-07\n",
      "Iteration 1299: Total Loss: 2.4509754180908203, Expl Loss: 2.336666971025636e-11, Output Loss: 1.1430862656425234e-07\n",
      "Iteration 1300: Total Loss: 2.4474384784698486, Expl Loss: 2.333081297600792e-11, Output Loss: 1.1435732005793398e-07\n",
      "Iteration 1301: Total Loss: 2.446627378463745, Expl Loss: 2.331293144641755e-11, Output Loss: 1.1533425947618525e-07\n",
      "Iteration 1302: Total Loss: 2.446779727935791, Expl Loss: 2.3315236893917124e-11, Output Loss: 1.1525608556439693e-07\n",
      "Iteration 1303: Total Loss: 2.4448018074035645, Expl Loss: 2.3303435570110054e-11, Output Loss: 1.1445832370782227e-07\n",
      "Iteration 1304: Total Loss: 2.4439828395843506, Expl Loss: 2.3301114510099197e-11, Output Loss: 1.1387140119722972e-07\n",
      "Iteration 1305: Total Loss: 2.443300485610962, Expl Loss: 2.3290966377764732e-11, Output Loss: 1.1420396361927487e-07\n",
      "Iteration 1306: Total Loss: 2.4421892166137695, Expl Loss: 2.3274973962039702e-11, Output Loss: 1.146919501593402e-07\n",
      "Iteration 1307: Total Loss: 2.4389755725860596, Expl Loss: 2.324637531081475e-11, Output Loss: 1.1433814961492317e-07\n",
      "Iteration 1308: Total Loss: 2.4395134449005127, Expl Loss: 2.3257543460553087e-11, Output Loss: 1.137590217581419e-07\n",
      "Iteration 1309: Total Loss: 2.437127113342285, Expl Loss: 2.3237037294343565e-11, Output Loss: 1.134233826860509e-07\n",
      "Iteration 1310: Total Loss: 2.4341988563537598, Expl Loss: 2.3206219931792837e-11, Output Loss: 1.1357700913094959e-07\n",
      "Iteration 1311: Total Loss: 2.431215286254883, Expl Loss: 2.317335039137003e-11, Output Loss: 1.138804037736918e-07\n",
      "Iteration 1312: Total Loss: 2.4314568042755127, Expl Loss: 2.3177673322272163e-11, Output Loss: 1.1368938146461005e-07\n",
      "Iteration 1313: Total Loss: 2.4305574893951416, Expl Loss: 2.3170649426917933e-11, Output Loss: 1.1349241191283e-07\n",
      "Iteration 1314: Total Loss: 2.4277682304382324, Expl Loss: 2.3145766553378522e-11, Output Loss: 1.1319172443791103e-07\n",
      "Iteration 1315: Total Loss: 2.426274299621582, Expl Loss: 2.3131082119154378e-11, Output Loss: 1.1316604542344066e-07\n",
      "Iteration 1316: Total Loss: 2.422816038131714, Expl Loss: 2.3095480389256906e-11, Output Loss: 1.1326817883627882e-07\n",
      "Iteration 1317: Total Loss: 2.421391725540161, Expl Loss: 2.3080513195106178e-11, Output Loss: 1.1334029892395847e-07\n",
      "Iteration 1318: Total Loss: 2.4201979637145996, Expl Loss: 2.306813767782856e-11, Output Loss: 1.1338415362160958e-07\n",
      "Iteration 1319: Total Loss: 2.423182487487793, Expl Loss: 2.3099409537929994e-11, Output Loss: 1.1324171111937176e-07\n",
      "Iteration 1320: Total Loss: 2.4170613288879395, Expl Loss: 2.303830390348871e-11, Output Loss: 1.13231045872908e-07\n",
      "Iteration 1321: Total Loss: 2.4151012897491455, Expl Loss: 2.3019825629022606e-11, Output Loss: 1.1311880143693998e-07\n",
      "Iteration 1322: Total Loss: 2.413905143737793, Expl Loss: 2.3006154273308432e-11, Output Loss: 1.13289800651728e-07\n",
      "Iteration 1323: Total Loss: 2.4134902954101562, Expl Loss: 2.3001624910312657e-11, Output Loss: 1.1332772942296288e-07\n",
      "Iteration 1324: Total Loss: 2.413057804107666, Expl Loss: 2.2993279155669732e-11, Output Loss: 1.1372991792768516e-07\n",
      "Iteration 1325: Total Loss: 2.411646842956543, Expl Loss: 2.2976967550825123e-11, Output Loss: 1.1395029986260852e-07\n",
      "Iteration 1326: Total Loss: 2.411682367324829, Expl Loss: 2.297019519037491e-11, Output Loss: 1.1466298843743061e-07\n",
      "Iteration 1327: Total Loss: 2.411742687225342, Expl Loss: 2.2965384802176025e-11, Output Loss: 1.1520439358037038e-07\n",
      "Iteration 1328: Total Loss: 2.4109444618225098, Expl Loss: 2.2947050509758427e-11, Output Loss: 1.1623961881923606e-07\n",
      "Iteration 1329: Total Loss: 2.411149740219116, Expl Loss: 2.2940063043597192e-11, Output Loss: 1.1714330128143047e-07\n",
      "Iteration 1330: Total Loss: 2.4101321697235107, Expl Loss: 2.2916096104053096e-11, Output Loss: 1.1852264236722476e-07\n",
      "Iteration 1331: Total Loss: 2.4093899726867676, Expl Loss: 2.289898132223911e-11, Output Loss: 1.194918297642289e-07\n",
      "Iteration 1332: Total Loss: 2.412166118621826, Expl Loss: 2.291167949808326e-11, Output Loss: 1.2099823720745917e-07\n",
      "Iteration 1333: Total Loss: 2.4086267948150635, Expl Loss: 2.2877463812243093e-11, Output Loss: 1.208804718544343e-07\n",
      "Iteration 1334: Total Loss: 2.4060609340667725, Expl Loss: 2.284050032441698e-11, Output Loss: 1.2201087429275503e-07\n",
      "Iteration 1335: Total Loss: 2.4076132774353027, Expl Loss: 2.2862120183098078e-11, Output Loss: 1.2140138494487474e-07\n",
      "Iteration 1336: Total Loss: 2.4048120975494385, Expl Loss: 2.281684563509856e-11, Output Loss: 1.2312767694311333e-07\n",
      "Iteration 1337: Total Loss: 2.4071006774902344, Expl Loss: 2.280769149931583e-11, Output Loss: 1.263316846689122e-07\n",
      "Iteration 1338: Total Loss: 2.407525062561035, Expl Loss: 2.2793947285215665e-11, Output Loss: 1.2813030991765118e-07\n",
      "Iteration 1339: Total Loss: 2.4031527042388916, Expl Loss: 2.2778216812735508e-11, Output Loss: 1.2533112681012426e-07\n",
      "Iteration 1340: Total Loss: 2.3980700969696045, Expl Loss: 2.2771732416382306e-11, Output Loss: 1.2089680012650206e-07\n",
      "Iteration 1341: Total Loss: 2.3911962509155273, Expl Loss: 2.2742583857815468e-11, Output Loss: 1.1693786916566751e-07\n",
      "Iteration 1342: Total Loss: 2.390655279159546, Expl Loss: 2.2738580116032914e-11, Output Loss: 1.1679728117997001e-07\n",
      "Iteration 1343: Total Loss: 2.390779495239258, Expl Loss: 2.2724950393682164e-11, Output Loss: 1.1828450396933476e-07\n",
      "Iteration 1344: Total Loss: 2.3889565467834473, Expl Loss: 2.2721543396775346e-11, Output Loss: 1.168021270814279e-07\n",
      "Iteration 1345: Total Loss: 2.3857858180999756, Expl Loss: 2.2726450929488884e-11, Output Loss: 1.1314086378888533e-07\n",
      "Iteration 1346: Total Loss: 2.381082773208618, Expl Loss: 2.2681289138515304e-11, Output Loss: 1.1295380630826912e-07\n",
      "Iteration 1347: Total Loss: 2.3813254833221436, Expl Loss: 2.2659488868592703e-11, Output Loss: 1.1537673572092899e-07\n",
      "Iteration 1348: Total Loss: 2.3817739486694336, Expl Loss: 2.2658206907943956e-11, Output Loss: 1.1595313509360494e-07\n",
      "Iteration 1349: Total Loss: 2.375847101211548, Expl Loss: 2.262865589353069e-11, Output Loss: 1.1298160984551942e-07\n",
      "Iteration 1350: Total Loss: 2.372605562210083, Expl Loss: 2.261425074978618e-11, Output Loss: 1.1118049769720528e-07\n",
      "Iteration 1351: Total Loss: 2.372478485107422, Expl Loss: 2.2600544699602487e-11, Output Loss: 1.1242411801504204e-07\n",
      "Iteration 1352: Total Loss: 2.3741722106933594, Expl Loss: 2.2607521757422866e-11, Output Loss: 1.1341995076463718e-07\n",
      "Iteration 1353: Total Loss: 2.3748395442962646, Expl Loss: 2.2621732612138068e-11, Output Loss: 1.1266627097938908e-07\n",
      "Iteration 1354: Total Loss: 2.371638536453247, Expl Loss: 2.2599914994980708e-11, Output Loss: 1.1164705426836008e-07\n",
      "Iteration 1355: Total Loss: 2.3699018955230713, Expl Loss: 2.2577023583991718e-11, Output Loss: 1.1219947282370413e-07\n",
      "Iteration 1356: Total Loss: 2.367605447769165, Expl Loss: 2.2550796299758424e-11, Output Loss: 1.1252590326193967e-07\n",
      "Iteration 1357: Total Loss: 2.369751214981079, Expl Loss: 2.2577771249809864e-11, Output Loss: 1.1197435156873325e-07\n",
      "Iteration 1358: Total Loss: 2.365792989730835, Expl Loss: 2.2548242786801787e-11, Output Loss: 1.1096890517592328e-07\n",
      "Iteration 1359: Total Loss: 2.363161563873291, Expl Loss: 2.2522768372557067e-11, Output Loss: 1.1088463480746213e-07\n",
      "Iteration 1360: Total Loss: 2.3612565994262695, Expl Loss: 2.2499052967916988e-11, Output Loss: 1.113513476980188e-07\n",
      "Iteration 1361: Total Loss: 2.3606863021850586, Expl Loss: 2.2493859205829914e-11, Output Loss: 1.1130037336215537e-07\n",
      "Iteration 1362: Total Loss: 2.3585867881774902, Expl Loss: 2.2476378397362495e-11, Output Loss: 1.1094901708474936e-07\n",
      "Iteration 1363: Total Loss: 2.357908010482788, Expl Loss: 2.2471371985410826e-11, Output Loss: 1.1077094796974052e-07\n",
      "Iteration 1364: Total Loss: 2.3555362224578857, Expl Loss: 2.2441885155766172e-11, Output Loss: 1.1134775945720321e-07\n",
      "Iteration 1365: Total Loss: 2.354079246520996, Expl Loss: 2.24212887839359e-11, Output Loss: 1.119504133839655e-07\n",
      "Iteration 1366: Total Loss: 2.353672504425049, Expl Loss: 2.240643434681111e-11, Output Loss: 1.130290385731314e-07\n",
      "Iteration 1367: Total Loss: 2.353926420211792, Expl Loss: 2.239559926398016e-11, Output Loss: 1.1436659264063564e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1368: Total Loss: 2.354703426361084, Expl Loss: 2.2368312063703044e-11, Output Loss: 1.1787213338720903e-07\n",
      "Iteration 1369: Total Loss: 2.3589913845062256, Expl Loss: 2.2362714111046067e-11, Output Loss: 1.2272009541902662e-07\n",
      "Iteration 1370: Total Loss: 2.3638458251953125, Expl Loss: 2.233705755083637e-11, Output Loss: 1.3014010846745805e-07\n",
      "Iteration 1371: Total Loss: 2.3665292263031006, Expl Loss: 2.2323580484151506e-11, Output Loss: 1.341713016245194e-07\n",
      "Iteration 1372: Total Loss: 2.367394208908081, Expl Loss: 2.230664611357902e-11, Output Loss: 1.3672972443146136e-07\n",
      "Iteration 1373: Total Loss: 2.3568785190582275, Expl Loss: 2.231003055908065e-11, Output Loss: 1.258754025457165e-07\n",
      "Iteration 1374: Total Loss: 2.343769073486328, Expl Loss: 2.2284361855806623e-11, Output Loss: 1.1533275312558544e-07\n",
      "Iteration 1375: Total Loss: 2.3435769081115723, Expl Loss: 2.232125421997022e-11, Output Loss: 1.1145163369974398e-07\n",
      "Iteration 1376: Total Loss: 2.3433218002319336, Expl Loss: 2.226656012349615e-11, Output Loss: 1.1666586630099118e-07\n",
      "Iteration 1377: Total Loss: 2.3478267192840576, Expl Loss: 2.2272265629008636e-11, Output Loss: 1.2060019116688636e-07\n",
      "Iteration 1378: Total Loss: 2.3405773639678955, Expl Loss: 2.224202072520498e-11, Output Loss: 1.163754888011681e-07\n",
      "Iteration 1379: Total Loss: 2.3351261615753174, Expl Loss: 2.2238036065380662e-11, Output Loss: 1.1132256361179316e-07\n",
      "Iteration 1380: Total Loss: 2.333250045776367, Expl Loss: 2.221536149482617e-11, Output Loss: 1.1171395897235925e-07\n",
      "Iteration 1381: Total Loss: 2.3353443145751953, Expl Loss: 2.2202847199670472e-11, Output Loss: 1.1505949970569418e-07\n",
      "Iteration 1382: Total Loss: 2.3378334045410156, Expl Loss: 2.2226148005399793e-11, Output Loss: 1.1521852627538465e-07\n",
      "Iteration 1383: Total Loss: 2.3294026851654053, Expl Loss: 2.2181589898195853e-11, Output Loss: 1.1124382126581622e-07\n",
      "Iteration 1384: Total Loss: 2.329122543334961, Expl Loss: 2.21894429913716e-11, Output Loss: 1.1017820611414209e-07\n",
      "Iteration 1385: Total Loss: 2.329401731491089, Expl Loss: 2.2169809391070494e-11, Output Loss: 1.1242072872619246e-07\n",
      "Iteration 1386: Total Loss: 2.3281900882720947, Expl Loss: 2.2151553161209314e-11, Output Loss: 1.1303466607159862e-07\n",
      "Iteration 1387: Total Loss: 2.32610821723938, Expl Loss: 2.2146900632846744e-11, Output Loss: 1.1141835187800098e-07\n",
      "Iteration 1388: Total Loss: 2.321094036102295, Expl Loss: 2.21138315992242e-11, Output Loss: 1.0971090347311474e-07\n",
      "Iteration 1389: Total Loss: 2.321959972381592, Expl Loss: 2.2116095413360348e-11, Output Loss: 1.1035034219730733e-07\n",
      "Iteration 1390: Total Loss: 2.3181862831115723, Expl Loss: 2.206559934769814e-11, Output Loss: 1.1162632773675796e-07\n",
      "Iteration 1391: Total Loss: 2.315514087677002, Expl Loss: 2.2046685657639564e-11, Output Loss: 1.1084548390272175e-07\n",
      "Iteration 1392: Total Loss: 2.313401699066162, Expl Loss: 2.203714988269212e-11, Output Loss: 1.0968688002321869e-07\n",
      "Iteration 1393: Total Loss: 2.3137786388397217, Expl Loss: 2.2043335906607453e-11, Output Loss: 1.0944498995968388e-07\n",
      "Iteration 1394: Total Loss: 2.313002347946167, Expl Loss: 2.2029484139651778e-11, Output Loss: 1.1005405298192272e-07\n",
      "Iteration 1395: Total Loss: 2.3137197494506836, Expl Loss: 2.2032580621056397e-11, Output Loss: 1.1046175529827451e-07\n",
      "Iteration 1396: Total Loss: 2.310082197189331, Expl Loss: 2.2002132754606052e-11, Output Loss: 1.0986892107212043e-07\n",
      "Iteration 1397: Total Loss: 2.307090997695923, Expl Loss: 2.1978665415423038e-11, Output Loss: 1.092246293410426e-07\n",
      "Iteration 1398: Total Loss: 2.305867910385132, Expl Loss: 2.1968399321892207e-11, Output Loss: 1.0902798663892099e-07\n",
      "Iteration 1399: Total Loss: 2.306344747543335, Expl Loss: 2.1969946695232778e-11, Output Loss: 1.0935018934787877e-07\n",
      "Iteration 1400: Total Loss: 2.3073062896728516, Expl Loss: 2.1976018227398697e-11, Output Loss: 1.097045583264844e-07\n",
      "Iteration 1401: Total Loss: 2.30637788772583, Expl Loss: 2.1968869431954197e-11, Output Loss: 1.0949081286071305e-07\n",
      "Iteration 1402: Total Loss: 2.301736354827881, Expl Loss: 2.1925822268897832e-11, Output Loss: 1.0915427850477499e-07\n",
      "Iteration 1403: Total Loss: 2.2988669872283936, Expl Loss: 2.1901822369607693e-11, Output Loss: 1.0868480870840358e-07\n",
      "Iteration 1404: Total Loss: 2.2992334365844727, Expl Loss: 2.1906875619093213e-11, Output Loss: 1.0854603971210963e-07\n",
      "Iteration 1405: Total Loss: 2.297006845474243, Expl Loss: 2.1882971129594253e-11, Output Loss: 1.0870982691812969e-07\n",
      "Iteration 1406: Total Loss: 2.2953455448150635, Expl Loss: 2.1864473773169912e-11, Output Loss: 1.088981065322514e-07\n",
      "Iteration 1407: Total Loss: 2.295447826385498, Expl Loss: 2.186155076411289e-11, Output Loss: 1.0929266380799163e-07\n",
      "Iteration 1408: Total Loss: 2.292820692062378, Expl Loss: 2.1833755289857315e-11, Output Loss: 1.0944504680310274e-07\n",
      "Iteration 1409: Total Loss: 2.294722557067871, Expl Loss: 2.1847346848291593e-11, Output Loss: 1.0998809329976211e-07\n",
      "Iteration 1410: Total Loss: 2.290670156478882, Expl Loss: 2.1800851054964987e-11, Output Loss: 1.1058522630946754e-07\n",
      "Iteration 1411: Total Loss: 2.2913355827331543, Expl Loss: 2.1791443649554765e-11, Output Loss: 1.1219127316053346e-07\n",
      "Iteration 1412: Total Loss: 2.291228771209717, Expl Loss: 2.1770829930489732e-11, Output Loss: 1.141457062203699e-07\n",
      "Iteration 1413: Total Loss: 2.2938244342803955, Expl Loss: 2.1760095461620388e-11, Output Loss: 1.1781505548924542e-07\n",
      "Iteration 1414: Total Loss: 2.2948248386383057, Expl Loss: 2.173757354673178e-11, Output Loss: 1.210675293350505e-07\n",
      "Iteration 1415: Total Loss: 2.3000855445861816, Expl Loss: 2.173649975290015e-11, Output Loss: 1.2643550917346147e-07\n",
      "Iteration 1416: Total Loss: 2.3008313179016113, Expl Loss: 2.1731151600423715e-11, Output Loss: 1.2771629087637848e-07\n",
      "Iteration 1417: Total Loss: 2.294400691986084, Expl Loss: 2.168894924770015e-11, Output Loss: 1.2550601979910425e-07\n",
      "Iteration 1418: Total Loss: 2.2834372520446777, Expl Loss: 2.1671033023640263e-11, Output Loss: 1.1633400731625443e-07\n",
      "Iteration 1419: Total Loss: 2.2738916873931885, Expl Loss: 2.165335966086701e-11, Output Loss: 1.0855581678015369e-07\n",
      "Iteration 1420: Total Loss: 2.2755870819091797, Expl Loss: 2.1655654700025728e-11, Output Loss: 1.1002170197116357e-07\n",
      "Iteration 1421: Total Loss: 2.2796216011047363, Expl Loss: 2.1644613185101136e-11, Output Loss: 1.151603328253259e-07\n",
      "Iteration 1422: Total Loss: 2.278407573699951, Expl Loss: 2.162740299349597e-11, Output Loss: 1.1566725532929922e-07\n",
      "Iteration 1423: Total Loss: 2.272609233856201, Expl Loss: 2.1617211493074606e-11, Output Loss: 1.1088820173199565e-07\n",
      "Iteration 1424: Total Loss: 2.2678027153015137, Expl Loss: 2.1586659543215703e-11, Output Loss: 1.0913685599689416e-07\n",
      "Iteration 1425: Total Loss: 2.268451690673828, Expl Loss: 2.157153448922866e-11, Output Loss: 1.1129843358048674e-07\n",
      "Iteration 1426: Total Loss: 2.2698421478271484, Expl Loss: 2.1575666600548438e-11, Output Loss: 1.1227555063442196e-07\n",
      "Iteration 1427: Total Loss: 2.264211654663086, Expl Loss: 2.154951043997766e-11, Output Loss: 1.0926054017090792e-07\n",
      "Iteration 1428: Total Loss: 2.2650234699249268, Expl Loss: 2.157541506564442e-11, Output Loss: 1.0748185985676173e-07\n",
      "Iteration 1429: Total Loss: 2.2662200927734375, Expl Loss: 2.1575442821220037e-11, Output Loss: 1.0867588429164243e-07\n",
      "Iteration 1430: Total Loss: 2.2623443603515625, Expl Loss: 2.15296062228143e-11, Output Loss: 1.0938383354641701e-07\n",
      "Iteration 1431: Total Loss: 2.260178327560425, Expl Loss: 2.1526521884474015e-11, Output Loss: 1.0752635404287503e-07\n",
      "Iteration 1432: Total Loss: 2.2558226585388184, Expl Loss: 2.149076229474023e-11, Output Loss: 1.067464694415321e-07\n",
      "Iteration 1433: Total Loss: 2.2559497356414795, Expl Loss: 2.1482622972190946e-11, Output Loss: 1.0768740565936241e-07\n",
      "Iteration 1434: Total Loss: 2.2557578086853027, Expl Loss: 2.1478173406475065e-11, Output Loss: 1.0794042282213923e-07\n",
      "Iteration 1435: Total Loss: 2.2526183128356934, Expl Loss: 2.1456697529842472e-11, Output Loss: 1.0694855490100963e-07\n",
      "Iteration 1436: Total Loss: 2.250619411468506, Expl Loss: 2.144138339099655e-11, Output Loss: 1.0648101778087948e-07\n",
      "Iteration 1437: Total Loss: 2.250991106033325, Expl Loss: 2.1438142927543424e-11, Output Loss: 1.0717687359829142e-07\n",
      "Iteration 1438: Total Loss: 2.2497177124023438, Expl Loss: 2.1423184407010076e-11, Output Loss: 1.073991455768919e-07\n",
      "Iteration 1439: Total Loss: 2.250983476638794, Expl Loss: 2.14385852820298e-11, Output Loss: 1.0712514608712809e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1440: Total Loss: 2.24582839012146, Expl Loss: 2.1387875845380044e-11, Output Loss: 1.0704091835123108e-07\n",
      "Iteration 1441: Total Loss: 2.246077299118042, Expl Loss: 2.1375247058474933e-11, Output Loss: 1.0855263354869749e-07\n",
      "Iteration 1442: Total Loss: 2.2474899291992188, Expl Loss: 2.136778427808128e-11, Output Loss: 1.1071166738929605e-07\n",
      "Iteration 1443: Total Loss: 2.2517154216766357, Expl Loss: 2.1363568900034657e-11, Output Loss: 1.153587021462954e-07\n",
      "Iteration 1444: Total Loss: 2.255683183670044, Expl Loss: 2.1346190440252322e-11, Output Loss: 1.210640760973547e-07\n",
      "Iteration 1445: Total Loss: 2.2655575275421143, Expl Loss: 2.1316502382684455e-11, Output Loss: 1.339072213113468e-07\n",
      "Iteration 1446: Total Loss: 2.281090021133423, Expl Loss: 2.1333370833764853e-11, Output Loss: 1.4775307022318884e-07\n",
      "Iteration 1447: Total Loss: 2.2896764278411865, Expl Loss: 2.130110671183516e-11, Output Loss: 1.5956578636178165e-07\n",
      "Iteration 1448: Total Loss: 2.284543514251709, Expl Loss: 2.130297327429531e-11, Output Loss: 1.5424627974880423e-07\n",
      "Iteration 1449: Total Loss: 2.2528347969055176, Expl Loss: 2.1276152714633234e-11, Output Loss: 1.252195573897552e-07\n",
      "Iteration 1450: Total Loss: 2.2351436614990234, Expl Loss: 2.1278602144181313e-11, Output Loss: 1.0728368948775824e-07\n",
      "Iteration 1451: Total Loss: 2.2440316677093506, Expl Loss: 2.1272074379741213e-11, Output Loss: 1.168242818039289e-07\n",
      "Iteration 1452: Total Loss: 2.2542593479156494, Expl Loss: 2.1261768387570434e-11, Output Loss: 1.2808250460238924e-07\n",
      "Iteration 1453: Total Loss: 2.2415378093719482, Expl Loss: 2.1244122780372798e-11, Output Loss: 1.1712557324017325e-07\n",
      "Iteration 1454: Total Loss: 2.2301242351531982, Expl Loss: 2.123914238927327e-11, Output Loss: 1.0620999546517851e-07\n",
      "Iteration 1455: Total Loss: 2.2355844974517822, Expl Loss: 2.122650839819773e-11, Output Loss: 1.1293366952713768e-07\n",
      "Iteration 1456: Total Loss: 2.239149570465088, Expl Loss: 2.121994940873506e-11, Output Loss: 1.1715470549233942e-07\n",
      "Iteration 1457: Total Loss: 2.229279041290283, Expl Loss: 2.1195387459038706e-11, Output Loss: 1.0974024178267427e-07\n",
      "Iteration 1458: Total Loss: 2.2248895168304443, Expl Loss: 2.1183011941761087e-11, Output Loss: 1.0658830973397926e-07\n",
      "Iteration 1459: Total Loss: 2.2304558753967285, Expl Loss: 2.1181417730886665e-11, Output Loss: 1.1231411178869166e-07\n",
      "Iteration 1460: Total Loss: 2.226444959640503, Expl Loss: 2.1148725132258406e-11, Output Loss: 1.1157244017567791e-07\n",
      "Iteration 1461: Total Loss: 2.2197632789611816, Expl Loss: 2.1135836136831898e-11, Output Loss: 1.0617960555237005e-07\n",
      "Iteration 1462: Total Loss: 2.2192795276641846, Expl Loss: 2.1111574294296886e-11, Output Loss: 1.0812208017796365e-07\n",
      "Iteration 1463: Total Loss: 2.224302053451538, Expl Loss: 2.1138970782152988e-11, Output Loss: 1.1040502556625142e-07\n",
      "Iteration 1464: Total Loss: 2.2188944816589355, Expl Loss: 2.112017505329078e-11, Output Loss: 1.0687704588008273e-07\n",
      "Iteration 1465: Total Loss: 2.2154359817504883, Expl Loss: 2.1096922819818786e-11, Output Loss: 1.0574371600569066e-07\n",
      "Iteration 1466: Total Loss: 2.215336322784424, Expl Loss: 2.1070064096240237e-11, Output Loss: 1.083299281390282e-07\n",
      "Iteration 1467: Total Loss: 2.211167335510254, Expl Loss: 2.1038061917555417e-11, Output Loss: 1.0736097522112686e-07\n",
      "Iteration 1468: Total Loss: 2.210890293121338, Expl Loss: 2.1057530719126305e-11, Output Loss: 1.0513723225358262e-07\n",
      "Iteration 1469: Total Loss: 2.2099297046661377, Expl Loss: 2.1037529357448292e-11, Output Loss: 1.0617677048685437e-07\n",
      "Iteration 1470: Total Loss: 2.207939386367798, Expl Loss: 2.100844671837354e-11, Output Loss: 1.0709464959290926e-07\n",
      "Iteration 1471: Total Loss: 2.208186626434326, Expl Loss: 2.1025790483686357e-11, Output Loss: 1.0560745522525394e-07\n",
      "Iteration 1472: Total Loss: 2.205625534057617, Expl Loss: 2.1007763237324006e-11, Output Loss: 1.0484944112931771e-07\n",
      "Iteration 1473: Total Loss: 2.205681324005127, Expl Loss: 2.0998057459475916e-11, Output Loss: 1.0587567800257602e-07\n",
      "Iteration 1474: Total Loss: 2.2032530307769775, Expl Loss: 2.09729438677142e-11, Output Loss: 1.059586196561213e-07\n",
      "Iteration 1475: Total Loss: 2.2012689113616943, Expl Loss: 2.096503179394027e-11, Output Loss: 1.0476590972530175e-07\n",
      "Iteration 1476: Total Loss: 2.199880361557007, Expl Loss: 2.09527898503703e-11, Output Loss: 1.04601433292828e-07\n",
      "Iteration 1477: Total Loss: 2.2007968425750732, Expl Loss: 2.095416548608675e-11, Output Loss: 1.0538020234207579e-07\n",
      "Iteration 1478: Total Loss: 2.198249578475952, Expl Loss: 2.0930233241012175e-11, Output Loss: 1.0522628457465544e-07\n",
      "Iteration 1479: Total Loss: 2.200482130050659, Expl Loss: 2.0959461596858908e-11, Output Loss: 1.0453616994254844e-07\n",
      "Iteration 1480: Total Loss: 2.199176073074341, Expl Loss: 2.0948139056731208e-11, Output Loss: 1.0436231434596266e-07\n",
      "Iteration 1481: Total Loss: 2.1967384815216064, Expl Loss: 2.0919786736239843e-11, Output Loss: 1.047599198500393e-07\n",
      "Iteration 1482: Total Loss: 2.195995569229126, Expl Loss: 2.091144445104387e-11, Output Loss: 1.0485130985671276e-07\n",
      "Iteration 1483: Total Loss: 2.1910672187805176, Expl Loss: 2.0868230754533812e-11, Output Loss: 1.0424425767041612e-07\n",
      "Iteration 1484: Total Loss: 2.1893060207366943, Expl Loss: 2.0853728466274646e-11, Output Loss: 1.0393335969638429e-07\n",
      "Iteration 1485: Total Loss: 2.1880433559417725, Expl Loss: 2.083940658925698e-11, Output Loss: 1.0410294493112815e-07\n",
      "Iteration 1486: Total Loss: 2.18902587890625, Expl Loss: 2.0848458376354628e-11, Output Loss: 1.0418004592338548e-07\n",
      "Iteration 1487: Total Loss: 2.187404155731201, Expl Loss: 2.0832944744308968e-11, Output Loss: 1.0410980166852823e-07\n",
      "Iteration 1488: Total Loss: 2.1861729621887207, Expl Loss: 2.0824007448960735e-11, Output Loss: 1.0377222281476861e-07\n",
      "Iteration 1489: Total Loss: 2.1855266094207764, Expl Loss: 2.0818074694672895e-11, Output Loss: 1.0371913106155262e-07\n",
      "Iteration 1490: Total Loss: 2.183953285217285, Expl Loss: 2.0801147262994313e-11, Output Loss: 1.0383863013885275e-07\n",
      "Iteration 1491: Total Loss: 2.1833887100219727, Expl Loss: 2.0795126037809197e-11, Output Loss: 1.0387613258444617e-07\n",
      "Iteration 1492: Total Loss: 2.1818478107452393, Expl Loss: 2.0779834450368462e-11, Output Loss: 1.0386433757503255e-07\n",
      "Iteration 1493: Total Loss: 2.1800804138183594, Expl Loss: 2.076407969175964e-11, Output Loss: 1.0367252656351411e-07\n",
      "Iteration 1494: Total Loss: 2.1824913024902344, Expl Loss: 2.0789318183611627e-11, Output Loss: 1.0355957869023769e-07\n",
      "Iteration 1495: Total Loss: 2.178713798522949, Expl Loss: 2.0751067530966338e-11, Output Loss: 1.0360719926438833e-07\n",
      "Iteration 1496: Total Loss: 2.1776785850524902, Expl Loss: 2.073980917560725e-11, Output Loss: 1.0369767977636002e-07\n",
      "Iteration 1497: Total Loss: 2.176816463470459, Expl Loss: 2.0727995708735847e-11, Output Loss: 1.0401711847407569e-07\n",
      "Iteration 1498: Total Loss: 2.1758198738098145, Expl Loss: 2.0715104978585863e-11, Output Loss: 1.0430934338501174e-07\n",
      "Iteration 1499: Total Loss: 2.175400733947754, Expl Loss: 2.0702804054417712e-11, Output Loss: 1.0512034265275361e-07\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam([x_adv], lr=args_lr)\n",
    "\n",
    "for i in range(args_num_iter):\n",
    "    if args_beta_growth:\n",
    "        model.change_beta(get_beta(i, args_num_iter))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # calculate loss\n",
    "    adv_expl, adv_acc, class_idx = get_expl(model, x_adv, method, desired_index=org_idx)\n",
    "    loss_expl = F.mse_loss(adv_expl, target_expl)\n",
    "    loss_output = F.mse_loss(adv_acc, org_acc.detach())\n",
    "    total_loss = args_prefactors[0]*loss_expl + args_prefactors[1]*loss_output\n",
    "\n",
    "    # update adversarial example\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # clamp adversarial example\n",
    "    # Note: x_adv.data returns tensor which shares data with x_adv but requires\n",
    "    #       no gradient. Since we do not want to differentiate the clamping,\n",
    "    #       this is what we need\n",
    "    x_adv.data = clamp(x_adv.data, data_mean, data_std)\n",
    "\n",
    "    print(\"Iteration {}: Total Loss: {}, Expl Loss: {}, Output Loss: {}\".format(i, total_loss.item(), loss_expl.item(), loss_output.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with original model (with relu activations)\n",
    "model.change_beta(None)\n",
    "adv_expl, adv_acc, class_idx = get_expl(model, x_adv, method)\n",
    "\n",
    "# save results\n",
    "output_dir = make_dir(args_output_dir)\n",
    "plot_overview([x_target, x, x_adv], [target_expl, org_expl, adv_expl], data_mean, data_std, filename=f\"{output_dir}overview_{args_method}.png\")\n",
    "torch.save(x_adv, f\"{output_dir}x_{args_method}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
