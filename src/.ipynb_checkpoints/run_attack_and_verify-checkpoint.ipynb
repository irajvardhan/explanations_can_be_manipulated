{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no display found. Using non-interactive Agg backend\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from nn.enums import ExplainingMethod\n",
    "from nn.networks import ExplainableNet\n",
    "from nn.utils import get_expl, plot_overview, clamp, load_image, make_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beta(i, num_iter):\n",
    "    \"\"\"\n",
    "    Helper method for beta growth\n",
    "    \"\"\"\n",
    "    start_beta, end_beta = 10.0, 100.0\n",
    "    return start_beta * (end_beta / start_beta) ** (i / num_iter)\n",
    "\n",
    "# def np_img_to_tensor(grayscale_img):\n",
    "#     rgb_img = np.repeat(grayscale_img[..., np.newaxis], 3, -1)\n",
    "#     im = Image.fromarray(rgb_img)\n",
    "#     x = torchvision.transforms.Normalize(mean=data_mean, std=data_std)(torchvision.transforms.ToTensor()(torchvision.transforms.Resize(224)(im)))\n",
    "#     x = x.unsqueeze(0).to(device)\n",
    "#     return x\n",
    "\n",
    "def np_img_to_tensor(input_img,data_mean,data_std, device, num_ch=1):\n",
    "    if num_ch == 1:\n",
    "        rgb_img = np.repeat(input_img[..., np.newaxis], 3, -1)\n",
    "    else:\n",
    "        rgb_img = input_img\n",
    "    im = Image.fromarray(rgb_img)\n",
    "    x = torchvision.transforms.Normalize(mean=data_mean, std=data_std)(torchvision.transforms.ToTensor()(torchvision.transforms.Resize(224)(im)))\n",
    "    x = x.unsqueeze(0).to(device)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args\n",
    "args_cuda = True\n",
    "args_method = 'lrp'\n",
    "args_beta_growth = None\n",
    "args_num_iter = 500\n",
    "args_prefactors = [1e11, 1e6]\n",
    "args_lr = 2* (10**(-3))\n",
    "args_output_dir = '../output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation method ExplainingMethod.lrp will be used\n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# options\n",
    "device = torch.device(\"cuda\" if args_cuda else \"cpu\")\n",
    "method = getattr(ExplainingMethod, args_method)\n",
    "print('Explanation method {} will be used'.format(method))\n",
    "\n",
    "# load model\n",
    "data_mean = np.array([0.0, 0.0, 0.0])\n",
    "data_std = np.array([1.0, 1.0, 1.0])\n",
    "\n",
    "vgg_model = torchvision.models.vgg16(pretrained=True)\n",
    "model = ExplainableNet(vgg_model, data_mean=data_mean, data_std=data_std, beta=1000 if args_beta_growth else None)\n",
    "if method == ExplainingMethod.pattern_attribution:\n",
    "    model.load_state_dict(torch.load('../models/model_vgg16_pattern_small.pth'), strict=False)\n",
    "model = model.eval().to(device)\n",
    "\n",
    "print(vgg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import datasets \n",
    "(x_train, y_train) ,(x_test, y_test) = datasets.fashion_mnist.load_data()\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "\n",
    "x = np_img_to_tensor(x_train[0],data_mean,data_std, device, num_ch=1)\n",
    "x_adv = x.clone().detach().requires_grad_()\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original class of x is \n"
     ]
    }
   ],
   "source": [
    "print('original class of x is ')\n",
    "x_pred = model(x)\n",
    "x_pred_class = torch.argmax(x_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(x_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 184.00 MiB (GPU 0; 10.76 GiB total capacity; 9.59 GiB already allocated; 181.12 MiB free; 184.24 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-5fdb1a32e7be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0morg_expl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morg_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morg_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_expl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0morg_expl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morg_expl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# The class from which we will derive the target explanation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msource_class_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/explanations_can_be_manipulated/src/nn/utils.py\u001b[0m in \u001b[0;36mget_expl\u001b[0;34m(model, x, method, desired_index)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesired_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_summands\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mprefactors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesired_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    147\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         inputs, allow_unused)\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 184.00 MiB (GPU 0; 10.76 GiB total capacity; 9.59 GiB already allocated; 181.12 MiB free; 184.24 MiB cached)"
     ]
    }
   ],
   "source": [
    "org_expl, org_acc, org_idx = get_expl(model, x, method)\n",
    "org_expl = org_expl.detach().cpu()\n",
    "\n",
    "# The class from which we will derive the target explanation\n",
    "source_class_idx = 6\n",
    "# pick index of x_train where the label is that of the source class\n",
    "idx = np.where(y_train == source_class_idx)[0][0]\n",
    "grayscale_img_src = x_train[idx]\n",
    "x_target = np_img_to_tensor(grayscale_img_src, data_mean,data_std, device, num_ch=1)\n",
    "target_expl, _, _ = get_expl(model, x_target, method)\n",
    "target_expl = target_expl.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.data[0].cpu().numpy()\n",
    "org_expl_np = org_expl.cpu().numpy()\n",
    "plt.imshow(org_expl_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(grayscale_img_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_expl_np = target_expl.cpu().numpy()\n",
    "plt.imshow(target_expl_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 368.00 MiB (GPU 0; 10.76 GiB total capacity; 9.60 GiB already allocated; 179.12 MiB free; 174.63 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-60a47212e317>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0madv_expl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_expl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_adv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morg_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mloss_expl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_expl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_expl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mloss_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morg_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/explanations_can_be_manipulated/src/nn/utils.py\u001b[0m in \u001b[0;36mget_expl\u001b[0;34m(model, x, method, desired_index)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mprefactors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_summands\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_summands\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mparallel_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefactors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_summands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# we sum the result and then take the derivative (instead of summing derivatives as in most implementations),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/explanations_can_be_manipulated/src/nn/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/explanations_can_be_manipulated/src/nn/layers/convolutional.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch_env/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m    911\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 368.00 MiB (GPU 0; 10.76 GiB total capacity; 9.60 GiB already allocated; 179.12 MiB free; 174.63 MiB cached)"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam([x_adv], lr=args_lr)\n",
    "\n",
    "for i in range(args_num_iter):\n",
    "    if args_beta_growth:\n",
    "        model.change_beta(get_beta(i, args_num_iter))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # calculate loss\n",
    "    adv_expl, adv_acc, class_idx = get_expl(model, x_adv, method, desired_index=org_idx)\n",
    "    loss_expl = F.mse_loss(adv_expl, target_expl)\n",
    "    loss_output = F.mse_loss(adv_acc, org_acc.detach())\n",
    "    total_loss = args_prefactors[0]*loss_expl + args_prefactors[1]*loss_output\n",
    "\n",
    "    # update adversarial example\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # clamp adversarial example\n",
    "    # Note: x_adv.data returns tensor which shares data with x_adv but requires\n",
    "    #       no gradient. Since we do not want to differentiate the clamping,\n",
    "    #       this is what we need\n",
    "    x_adv.data = clamp(x_adv.data, data_mean, data_std)\n",
    "\n",
    "    print(\"Iteration {}: Total Loss: {}, Expl Loss: {}, Output Loss: {}\".format(i, total_loss.item(), loss_expl.item(), loss_output.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class of x_adv_2 is  tensor([465], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# test with original model (with relu activations)\n",
    "model.change_beta(None)\n",
    "\n",
    "# find the predicted class of x_adv2\n",
    "x_adv_2_pred = model(x_adv)\n",
    "print('predicted class of x_adv_2 is ',torch.argmax(x_adv_2_pred,axis=1))\n",
    "\n",
    "adv_expl, adv_acc, class_idx = get_expl(model, x_adv, method)\n",
    "\n",
    "# save results\n",
    "output_dir = make_dir(args_output_dir)\n",
    "plot_overview([x_target, x, x_adv], [target_expl, org_expl, adv_expl], data_mean, data_std, filename=f\"{output_dir}overview_{args_method}.png\")\n",
    "torch.save(x_adv, f\"{output_dir}x_{args_method}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve the resulting adversarial example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "side = 28\n",
    "x_adv2_big = x_adv.detach().cpu().numpy()\n",
    "\n",
    "im2 = Image.fromarray(x_adv2_big[0][0])\n",
    "x_adv2_small = torchvision.transforms.ToTensor()(torchvision.transforms.Resize(side)(im2))\n",
    "x_adv2_small_np = x_adv2_small.numpy()\n",
    "x_adv2_small_np = x_adv2_small_np.reshape(side, side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the adv_2 adversarial example which produces the target map by the target explanation method\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f15f049d210>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAV8UlEQVR4nO3dXWyc5ZUH8P+Z8fjbsePE+XYhhNAS6BKKgVK2LVl2EbC7DV2p26JVlUq0qVZFaqVeLGIvysVeoNW2VS92K6ULalqxoEoUkQu0W0rZRVCWxaSBBLIkJHETE8dO4jgfjj/m4+yFh5ULfs4Z5vXMO+H5/6TIzhw/M8+8M8ev7fOe5xFVBRF99GXSngAR1QeTnSgSTHaiSDDZiSLBZCeKRFM9H6xZWrQVHfV8yPoQJ97IBY9Leu7O5COsNE1jErM6s+CBSZTsInIngB8ByAL4V1V92Pr6VnTg5uwd4S8oFb0HNGLODylasuMe4/4lY7/ptNS4b7rEc/eOq/W6JBkLQLJZM65F5/2URNL3U428Uvp1MFb1j/EikgXwzwDuArAJwL0isqna+yOi2kryO/tNAN5R1cOqOgvgCQBbF2daRLTYkiT7WgDH5v1/uHzbHxCR7SIyKCKDecwkeDgiSiJJsi/0y94HfsFT1R2qOqCqAzm0JHg4IkoiSbIPA+if9/91AI4nmw4R1UqSZH8VwEYRWS8izQC+AmDX4kyLiBZb1aU3VS2IyP0A/gNzpbdHVfVNf6BRsvDqptXebwW8Mg68uHXfSFYCSlK680prScer99TM1ztpudR+Tcy5e6+nW3JMdlxrWhYMSFRnV9VnADyzSHMhohri5bJEkWCyE0WCyU4UCSY7USSY7ESRYLITRaKu/ewA7B7jTPV108RtpF7N17h/LeST3bcnYStoEtJiX+LsVpsz4bmVJi9++AnN4x53i/N+SXp9ghYK1Q928qDaa0p4ZieKBJOdKBJMdqJIMNmJIsFkJ4oEk50oEvUvvVltrE5JwWyn9FYiTVhKMe/bW+U06Qqt3uMneW7ecWu1S2/av8qMz6xoD8ba3h41x5bGJ+y4U7qzXhevxdR7zdxj7rVr17BcGsIzO1EkmOxEkWCyE0WCyU4UCSY7USSY7ESRYLITRaL+dXZLgtpj0t1IJePU+Bt4J1aTV0fP2W+BmevWm/Fjf9psxku5cKx3zTpzbPuYXcNvf2fcjOvwSDiWcCln9/2U9NoLc3B1Y3lmJ4oEk50oEkx2okgw2YkiwWQnigSTnSgSTHaiSDTWUtKovq/b2zq4pnXPlFlzF2dV4kz3EjM+covdz/7pLfvM+IV8ePyelf3mWEwYRXoAbSdWmvGV/9MTHnvolDlWJ87Z8dlZMy6dHWYcXeG4TM2YQ0unw9cXyHT4epNEyS4iQwDOAygCKKjqQJL7I6LaWYwz+xZVtb9NElHq+Ds7USSSJrsC+JWIvCYi2xf6AhHZLiKDIjKYh/27CBHVTtIf429V1eMisgLAsyLyv6r6wvwvUNUdAHYAwBLpvXT/CkZ0iUt0ZlfV4+WPYwCeAnDTYkyKiBZf1ckuIh0i0vXe5wDuAGDXYYgoNUl+jF8J4CmZWx+7CcC/qeq/u6Os9bRruJb2pVxHd5nrztuF9tLKXjNeuHbSjG9b8ZIZP1EI17qbnDUE9hyz+93zK+zX9Mhl4Rp/x+G15tjuI6vNeMu4vV30+X67z3+6L5wHbWP281q227g24kD4OVed7Kp6GMB11Y4novpi6Y0oEkx2okgw2YkiwWQnigSTnSgSjbWUdMKti01Jy3rW3Lz79p5X0vFG23Cmu8sc+u7nw6UxANj68ZfNeH+T3Qrak5kKxvpW2WPfXrrGjD9/+iozfqB5RTA2mWszx15c5/QGi506mrV7rqUYLr1NXmOX9bKz4descCw8b57ZiSLBZCeKBJOdKBJMdqJIMNmJIsFkJ4oEk50oEvWvs9ewjdV+WGdL54Rb+CbhLXMNTTD3FcvMsdnbT5vxr/X+1oz3Oi9nX6YQjPU3TZhjN+TOmPFPtR0x40Mr+4Kx4Vm7tfel8Q1m/PBp+7iK2G2qn193KBg7MW1fGzE+dlkwlskb11yY90pEHxlMdqJIMNmJIsFkJ4oEk50oEkx2okgw2YkikcKWzTXsWbceNr0yunttgRbs/mWX0c+uTfZjd7eF+80rMVq0779Vwgc+6Zmmv+miGe/LHg3Grmk+bo69uT1cBweA06s7zXiX0ccP2NcQfP3A35hjWybC26hJMZxfPLMTRYLJThQJJjtRJJjsRJFgshNFgslOFAkmO1EkGmvd+CRquPb63P2He8rdXnlvu2jvsRNQp1e+IzdrxnNiH7eLJfstdLoUXp/98Gx4XXcAmCi2m/FPth4z4zmjxp+F/bys9e4BoDdr1/i7JNzHDwBdxnumr+2COXa80+ilz4bzwD2zi8ijIjImIvvm3dYrIs+KyMHyx6Xe/RBRuir5Mf6nAO58320PAHhOVTcCeK78fyJqYG6yq+oLAMbfd/NWADvLn+8EcM8iz4uIFlm1f6BbqaojAFD+GPzlS0S2i8igiAzmEb6ml4hqq+Z/jVfVHao6oKoDObTU+uGIKKDaZB8VkdUAUP44tnhTIqJaqDbZdwHYVv58G4CnF2c6RFQrbp1dRB4HcBuA5SIyDOB7AB4G8AsRuQ/AUQBfqvgRrZqyUct25+nWur3vazXss/dq/Bm7Fu49N+sag+lVdq36xiVv2fftmNbqL9Xw6uhjs0vMeGubvQ5A0TiXZWFf29Bi1OgBIO+cJ6fVjv/mwhXBWMnZJ+Dc5eFfh4tvhMe6r5Sq3hsI3e6NJaLGwctliSLBZCeKBJOdKBJMdqJIMNmJInFptbhaSyZ7baSeBC2yiVtYvXWuM/bLlOkOb/E7fnXOHHvbkv1mvNXZerg7Y18CPaPhsuLGlhPm2DXOls1WCysAZI3j3uq0oDY7rb1e6c5r/X3i+I3B2JETy82xy41tma1p8cxOFAkmO1EkmOxEkWCyE0WCyU4UCSY7USSY7ESRuLTq7B9VTmuvFuyaMIzlogsd9tAc7Fp1uzO39qxdb85ruA11XdNpc+xF5/qE8aJ9DcGsMfXujN0e2+G0FZ90tqr2luC+edlQMDb8Qr85tnf3yWCs6WL4vcIzO1EkmOxEkWCyE0WCyU4UCSY7USSY7ESRYLITRaKx6uw13DbZ7Vf3OMv7mtx+dHvJZCztNsPnNoe3Pv7sX/7OHNvfdNaMjzr15Hanp9yqNhedl7voLMfs1bIzRnO3t3B40XkvTht9+gDQ5dTxv9C9Oxh7Uj5rjpVzk+FgMfzMeGYnigSTnSgSTHaiSDDZiSLBZCeKBJOdKBJMdqJI1L/ObvVHu+urV79uvNhlUUiz3Rst7eHthaW91RxbXNFjxk/c0GnGz9xg97PfsulAMLa977/MseMle+7Tah+XvqxR8wWQN2rlk9psjm12eu29NesnE2wnnXPWle/JzJrxdueyjJ6m8PjS1RfMsdoT3icAp8LH2z2zi8ijIjImIvvm3faQiLwrInvK/+727oeI0lXJj/E/BXDnArf/UFU3l/89s7jTIqLF5ia7qr4AYLwOcyGiGkryB7r7ReSN8o/5S0NfJCLbRWRQRAbzsH/HIqLaqTbZfwxgA4DNAEYAfD/0haq6Q1UHVHUgh5YqH46Ikqoq2VV1VFWLqloC8BMANy3utIhosVWV7CKyet5/vwhgX+hriagxuIVIEXkcwG0AlovIMIDvAbhNRDZjbjfoIQDfrOjRBBBjjXO3r3vFsmCo1GH/ijCzzK4nTy23D8XFleHvi1Mr7Rr/8j8aM+NfXvffZvzKllEzvqppIhgrwi745p1atFdnH8r3mvGe7MVg7PImu57srVmfd67L+O1keP31Zc5j39Vu7w3fIvZxOVuaMuOtEj7ut60/aI49suSqYEyz4fepm+yqeu8CNz/ijSOixsLLZYkiwWQnigSTnSgSTHaiSDDZiSJR1xZXyTYhsyxcqjn55xvM8VN/cS4Y27xq2Bz7sTb78v72rN2y2JmdDsZKzpLHvU6Zpz9nb13sLalslc8Ozq4yx/7mzCfM+F8tDy95DPitoN6xsSzP2vtNXyiFXxMA+GTrsWCsS+ylnocL9mLT02o/71Znie11TeHX7NqO4+bYQ61Xh4PGkuo8sxNFgslOFAkmO1EkmOxEkWCyE0WCyU4UCSY7USTqWmcvtTdj+rqPBeNtXz5hjn/4yl3BmLekcc7ZpPei0+pptYp6tWSvTdSLT5bs9t0NuZPBWF9T+NoEAHjl6OVm/MCZ8HbQAPCN9S+acavF9ajTHnuqYLc8n8rbS3BvaA23FnvXNnhanS2Z+zLh5w0AZ0vh6zrOFtvMsWrU0q2mX57ZiSLBZCeKBJOdKBJMdqJIMNmJIsFkJ4oEk50oEnWts+c7Be9+LlxT/tt1v7PHG7Xw44Vuc2xf9rwZb3f6slslXKfvydjfM3NO7/TuWXuZ67GCsUUvgHMarsN7z/vr17xkxv/lpT8x4/8w9AUz3rI8vKTysiX2tRE39h0145/tCm9VDfjXGFi87aLbnTp7s/F+AYBJI9zubAc9uSqcQ6Uc+9mJosdkJ4oEk50oEkx2okgw2YkiwWQnigSTnSgSda2zQ4HsVLgOeGza7m9ekwtvoztdsnvCvVr1EmNdeABol5lgbK1Tz50oNZvxvdPhrYUBIOv04k8U24OxkvP9/DPt9vbAl205Zcb3T6014x9vHQnGNjbbW1F71z7MaHj7b8C+/sA6ZpVYovb75bwz955M+P1k7VEAAOfWh1/TorH0gXtmF5F+EXleRPaLyJsi8u3y7b0i8qyIHCx/XOrdFxGlp5If4wsAvquqVwP4NIBvicgmAA8AeE5VNwJ4rvx/ImpQbrKr6oiq7i5/fh7AfgBrAWwFsLP8ZTsB3FOrSRJRch/qD3QicjmA6wG8AmClqo4Ac98QACy4WJmIbBeRQREZLE7a10ITUe1UnOwi0gngSQDfUdWKOwxUdYeqDqjqQLbD3qiPiGqnomQXkRzmEv0xVf1l+eZREVldjq8GEF7Kk4hS55beREQAPAJgv6r+YF5oF4BtAB4uf3zau6/sLNA5HF7sdt/EGnP8iuZwu6ZXrmh12kwPz9hLJp8vhttQu5zHbnHaIb2lqHua7GWJO4wyjve8O5z4Nc328t43tLxrxmeN53beWUL77bz9mnhLbI/mw23Po3l7meqpoj23mZKdOj25cGsvAFzTFt5i/FTeLhNPrwq331qHtJI6+60Avgpgr4jsKd/2IOaS/Bcich+AowC+VMF9EVFK3GRX1ReB4A4Jty/udIioVni5LFEkmOxEkWCyE0WCyU4UCSY7USTq2uLaNFnA8lfDW+Ueuspu9dy75UIwtqkz3EoJAGPOlswnZ+3aZpuxvG97NlznBvwW1a6sXZP1auXnS+EtfqfFrhefdmr8SVtBrRZbry256JyLvOsTcmIvB22ZKtptySNTdp3+bM7edtl6T3jvxZaxcGuv9VbhmZ0oEkx2okgw2YkiwWQnigSTnSgSTHaiSDDZiSJR1zq7zsyidOj3wfiGx+zx+0Y3BWOvb7F74T+z9ogZ9/qPC6Xw98UzeXsFnpmsXU/udOLTam/h69Xx7fu2H9u7b68Wbl0j4NXBuzL2OgGevLHUdE7sOnlPzl5DoCVjLxV9rmD32g9dXBaMvfzWlebYjb8OL+82ci78evHMThQJJjtRJJjsRJFgshNFgslOFAkmO1EkmOxEkajzls0KzYfrk6UDh83ha06Gt2wuvbzKHPvKLdeb8eKWCTN+/arwOt8b2u1tjbudfnVvXfklGXu8tX76Wacf/fBUnxkfn7XHn5zuNONT+XAdf6aQ7O0nEt6DAACKpfD24NOz9vUF+by9HXR+yh7fdtius3cNhef+idfD73MAwIGhYEimw9cm8MxOFAkmO1EkmOxEkWCyE0WCyU4UCSY7USSY7ESRqGR/9n4APwOwCkAJwA5V/ZGIPATgGwBOlr/0QVV9xn1EDffbqrPMd+mMUX+cOGuOXXO0x4zrf/aa8ZElVwRj76wN99kDwGxXuN4LAOK0oxda7fHN58M12+ZJ+87bRu017zMzdt92U8FZE78UjndV34Y/xztVGfcvaj8vqH3tAwrhnnIAkEn72gidDI8vnj1nP7Z1vxp+L1RyVUMBwHdVdbeIdAF4TUSeLcd+qKr/VPXMiKhuKtmffQTASPnz8yKyH8DaWk+MiBbXh/qdXUQuB3A9gFfKN90vIm+IyKMisjQwZruIDIrIYB72j4xEVDsVJ7uIdAJ4EsB3VPUcgB8D2ABgM+bO/N9faJyq7lDVAVUdyMG+XpiIaqeiZBeRHOYS/TFV/SUAqOqoqhZVtQTgJwBuqt00iSgpN9lFRAA8AmC/qv5g3u2r533ZFwHsW/zpEdFiqeSv8bcC+CqAvSKyp3zbgwDuFZHNABTAEIBvVvSIRmkAYpeYtBQeK3ZHIkrjdgsrnLh19905+zBKU8JOYuf+YbQNa9GuZ+pMsr+j2E2mDrHPNd7c/bsPv5/ceTtzs0rIlYw3n5uVIwlU8tf4FwEsdNT8mjoRNQxeQUcUCSY7USSY7ESRYLITRYLJThQJJjtRJOq7lLTHrS9W3x7rkaxTqDfqqqUpu50xMa/mm4RXL/YkqUc7S0H7D139dRnufbtvB/u+JZO0f3fx8cxOFAkmO1EkmOxEkWCyE0WCyU4UCSY7USSY7ESREGvp2UV/MJGTAH4/76blAOz9jtPTqHNr1HkBnFu1FnNul6nqgvtw1zXZP/DgIoOqOpDaBAyNOrdGnRfAuVWrXnPjj/FEkWCyE0Ui7WTfkfLjWxp1bo06L4Bzq1Zd5pbq7+xEVD9pn9mJqE6Y7ESRSCXZReROEXlbRN4RkQfSmEOIiAyJyF4R2SMigynP5VERGRORffNu6xWRZ0XkYPnjgnvspTS3h0Tk3fKx2yMid6c0t34ReV5E9ovImyLy7fLtqR47Y151OW51/51dRLIADgD4MwDDAF4FcK+qvlXXiQSIyBCAAVVN/QIMEfkcgAsAfqaq15Zv+0cA46r6cPkb5VJV/bsGmdtDAC6kvY13ebei1fO3GQdwD4CvIcVjZ8zrr1GH45bGmf0mAO+o6mFVnQXwBICtKcyj4anqCwDG33fzVgA7y5/vxNybpe4Cc2sIqjqiqrvLn58H8N4246keO2NedZFGsq8FcGze/4fRWPu9K4BfichrIrI97cksYKWqjgBzbx4AK1Kez/u523jX0/u2GW+YY1fN9udJpZHsCy0c1kj1v1tV9VMA7gLwrfKPq1SZirbxrpcFthlvCNVuf55UGsk+DKB/3v/XATiewjwWpKrHyx/HADyFxtuKevS9HXTLH8dSns//a6RtvBfaZhwNcOzS3P48jWR/FcBGEVkvIs0AvgJgVwrz+AAR6Sj/4QQi0gHgDjTeVtS7AGwrf74NwNMpzuUPNMo23qFtxpHysUt9+3NVrfs/AHdj7i/yhwD8fRpzCMzrCgCvl/+9mfbcADyOuR/r8pj7ieg+AMsAPAfgYPljbwPN7ecA9gJ4A3OJtTqluf0x5n41fAPAnvK/u9M+dsa86nLceLksUSR4BR1RJJjsRJFgshNFgslOFAkmO1EkmOxEkWCyE0Xi/wAwWt46O2ZnrAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('This is the adv_2 adversarial example which produces the target map by the target explanation method')\n",
    "plt.imshow(x_adv2_small_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating directory  ../data//adversary/fmnist/adv2/cwl2/conf_0/lrp/from_5/\n",
      "storing results in  ../data//adversary/fmnist/adv2/cwl2/conf_0/lrp/from_5/\n"
     ]
    }
   ],
   "source": [
    "role = 'adversary'\n",
    "dataset = 'fmnist'\n",
    "output_dir = '../data/'\n",
    "attack_method = 'cwl2/conf_0'\n",
    "exp_method = 'lrp'\n",
    "adv_src_class_idx = 5\n",
    "output_dir = output_dir + '/' + role + '/' + dataset + '/' + 'adv2/' + attack_method + '/' + exp_method + '/from_' + str(adv_src_class_idx) + '/'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    print('creating directory ',output_dir)\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print('storing results in ',output_dir)\n",
    "#np.save(output_dir+'x_adv2.npy', x_adv2_small_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
