{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no display found. Using non-interactive Agg backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from nn.enums import ExplainingMethod\n",
    "from nn.networks import ExplainableNet\n",
    "from nn.utils import get_expl, plot_overview, clamp, load_image, make_dir\n",
    "import keras\n",
    "from keras import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beta(i, num_iter):\n",
    "    \"\"\"\n",
    "    Helper method for beta growth\n",
    "    \"\"\"\n",
    "    start_beta, end_beta = 10.0, 100.0\n",
    "    return start_beta * (end_beta / start_beta) ** (i / num_iter)\n",
    "\n",
    "def np_img_to_tensor(grayscale_img):\n",
    "    rgb_img = np.repeat(grayscale_img[..., np.newaxis], 3, -1)\n",
    "    im = Image.fromarray(rgb_img)\n",
    "    x = torchvision.transforms.Normalize(mean=data_mean, std=data_std)(torchvision.transforms.ToTensor()(torchvision.transforms.Resize(224)(im)))\n",
    "    x = x.unsqueeze(0).to(device)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_cuda = True\n",
    "\n",
    "# choices:['lrp', 'guided_backprop', 'gradient', 'integrated_grad','pattern_attribution', 'grad_times_input']\n",
    "args_method = 'lrp'\n",
    "args_beta_growth = None\n",
    "args_img = '../data/collie4.jpeg'\n",
    "args_target_img = '../data/tiger_cat.jpeg'\n",
    "args_num_iter = 1500\n",
    "args_prefactors = [1e11, 1e6]\n",
    "args_lr = 0.0002\n",
    "args_output_dir = '../output/'\n",
    "args_role = 'defender'\n",
    "args_dataset = 'fmnist'\n",
    "args_root_dir = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation method ExplainingMethod.lrp will be used\n"
     ]
    }
   ],
   "source": [
    "# options\n",
    "device = torch.device(\"cuda\" if args_cuda else \"cpu\")\n",
    "method = getattr(ExplainingMethod, args_method)\n",
    "print('Explanation method {} will be used'.format(method))\n",
    "\n",
    "# load model\n",
    "data_mean = np.array([0.0, 0.0, 0.0])\n",
    "data_std = np.array([1.0, 1.0, 1.0])\n",
    "\n",
    "vgg_model = torchvision.models.vgg16(pretrained=True)\n",
    "model = ExplainableNet(vgg_model, data_mean=data_mean, data_std=data_std, beta=1000 if args_beta_growth else None)\n",
    "if method == ExplainingMethod.pattern_attribution:\n",
    "    model.load_state_dict(torch.load('../models/model_vgg16_pattern_small.pth'), strict=False)\n",
    "model = model.eval().to(device)\n",
    "\n",
    "#print(vgg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x1, _) ,(_, _) = keras.datasets.fashion_mnist.load_data()\n",
    "x2 = np.load(adv_dir+'/x_adv_ar.npy')\n",
    "x2 = (x2*255).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1 = x1[0]\n",
    "rgb_img = np.repeat(gs1[..., np.newaxis], 3, -1)\n",
    "im = Image.fromarray(rgb_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs2 = x2[0]\n",
    "rgb_img2 = np.repeat(gs2[..., np.newaxis], 3, -1)\n",
    "im2 = Image.fromarray(rgb_img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(gs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(gs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for sample 100/1000\n",
      "Running for sample 200/1000\n",
      "Running for sample 300/1000\n",
      "Running for sample 400/1000\n",
      "Running for sample 500/1000\n",
      "Running for sample 600/1000\n",
      "Running for sample 700/1000\n",
      "Running for sample 800/1000\n",
      "Running for sample 900/1000\n",
      "Running for sample 1000/1000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    " \n",
    "input_is_adv = True\n",
    "if not input_is_adv:\n",
    "    (x_train, y_train) ,(x_test, y_test) = datasets.fashion_mnist.load_data()\n",
    "    # print(x_train.shape) ##(60000, 28, 28)\n",
    "    args_class_idx = 6\n",
    "    indices = np.where(y_train==args_class_idx)[0]\n",
    "    \n",
    "else:\n",
    "    adv_dir = '../../xai-adv/data/postndss/defender/fmnist/target_next/cwl2/conf_0/'\n",
    "    x_train = np.load(adv_dir+'/x_adv_ar.npy')\n",
    "    x_train = (x_train*255).astype(np.uint8)\n",
    "    indices = np.array([i for i in range(x_train.shape[0])])\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "\n",
    "num_samples = indices.shape[0]\n",
    "# expls will store explanations for all the samples\n",
    "expls = np.zeros((num_samples,28,28))\n",
    "\n",
    "for i,idx in enumerate(indices):\n",
    "    if (i+1)%100 == 0:\n",
    "        print('Running for sample {}/{}'.format(i+1,num_samples))\n",
    "    x = np_img_to_tensor(x_train[idx])\n",
    "    x_adv = x.clone().detach().requires_grad_()\n",
    "    \n",
    "    # obtain the explanation\n",
    "    if not input_is_adv:\n",
    "        org_expl, org_acc, org_idx = get_expl(model, x, method)\n",
    "        org_expl = org_expl.detach().cpu()\n",
    "    else:\n",
    "        desired_index = random.randint(0,1000)\n",
    "        org_expl, org_acc, org_idx = get_expl(model, x, method, desired_index)\n",
    "        org_expl = org_expl.detach().cpu()\n",
    "    \n",
    "    # convert explanation to numpy and subsequently downsize it to 28x28\n",
    "    org_expl_np = org_expl.numpy()\n",
    "    org_expl_np = org_expl_np.reshape(224, 224)\n",
    "    im2 = Image.fromarray(org_expl_np)\n",
    "    org_expl2 = torchvision.transforms.ToTensor()(torchvision.transforms.Resize(28)(im2))\n",
    "    org_expl_np2 = org_expl2.numpy()\n",
    "    org_expl_np2 = org_expl_np2.reshape(28,28)\n",
    "    \n",
    "    expls[i] = org_expl_np2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/raj_vardhan/anaconda3/envs/torch_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "# store the results\n",
    "output_dir = args_root_dir + '/' + args_role + '/' + args_dataset + '/' + args_method + '/' + str(args_class_idx) + '/'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    print('creating directory ',output_dir)\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print('storing results in ',output_dir)\n",
    "np.save(output_dir+'expls.npy', expls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
